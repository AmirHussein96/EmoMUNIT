{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Data: .wav -> Pitch contour (f0s), Harmonic spectral envelope (sps), Aperiodic spectral envelope (aps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from ops import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# matplotlib.rcParams['figure.figsize'] = (16, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 0\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder: Style_Encoder, Content_Encoder, MLP, Decoder, Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Style_Encoder(inputs, style_dim=16, reuse=False, scope='style_encoder'):                                                            # [1, 24, 128] = [batch_size, feature_channel, time]\n",
    "\n",
    "    inputs = tf.transpose(inputs, perm=[0, 2, 1], name='input_transpose')                                                               # [1, 128, 24] = [batch_size, time, feature_channel]\n",
    "\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "\n",
    "        h1 = conv1d_layer(inputs=inputs, filters=128, kernel_size=15, strides=1, name='h1_conv')                                        # [1, 128, 128]\n",
    "        h1_gates = conv1d_layer(inputs=inputs, filters=128, kernel_size=15, strides=1, name='h1_conv_gates')\n",
    "        h1_glu = gated_linear_layer(inputs=h1, gates=h1_gates, name='h1_glu')\n",
    "\n",
    "        # Downsample\n",
    "        d1 = downsample1d_block_withoutIN(inputs=h1_glu, filters=256, kernel_size=5, strides=2, name_prefix='downsample1d_block1')      # [1, 64, 256]\n",
    "        d2 = downsample1d_block_withoutIN(inputs=d1, filters=512, kernel_size=5, strides=2, name_prefix='downsample1d_block2')          # [1, 32, 512]\n",
    "\n",
    "        d3 = downsample1d_block_withoutIN(inputs=d2, filters=512, kernel_size=3, strides=2, name_prefix='downsample1d_block3')          # [1, 16, 512]\n",
    "        d4 = downsample1d_block_withoutIN(inputs=d3, filters=512, kernel_size=3, strides=2, name_prefix='downsample1d_block4')          # [1, 8, 512]\n",
    "\n",
    "        # Global Average Pooling\n",
    "        p1 = adaptive_avg_pooling(d4)                                                                                                   # [1, 1, 512]\n",
    "        style = conv1d_layer(inputs=p1, filters=style_dim, kernel_size=1, strides=1, name='SE_logit')                                   # [1, 1, 16]\n",
    "\n",
    "        return style                                                                                                                    # [1, 1, 16]\n",
    "\n",
    "\n",
    "def Content_Encoder(inputs, reuse=False, scope='content_encoder'):\n",
    "    # IN removes the original feature mean and variance that represent important style information\n",
    "    inputs = tf.transpose(inputs, perm=[0, 2, 1], name='input_transpose')                                                               # [1, 24, 128] = [batch_size, time, feature_channel]\n",
    "\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "\n",
    "        h1 = conv1d_layer(inputs=inputs, filters=128, kernel_size=15, strides=1, name='h1_conv')                                        # [1, 128, 128]\n",
    "        h1_norm = instance_norm_layer(inputs=h1, name='h1_norm')\n",
    "        h1_gates = conv1d_layer(inputs=inputs, filters=128, kernel_size=15, strides=1, name='h1_gates')\n",
    "        h1_norm_gates = instance_norm_layer(inputs=h1_gates, name='h1_norm_gates')\n",
    "        h1_glu = gated_linear_layer(inputs=h1_norm, gates=h1_norm_gates, name='h1_glu')\n",
    "\n",
    "        # downsample\n",
    "        d1 = downsample1d_block(inputs=h1_glu, filters=256, kernel_size=5, strides=2, name_prefix='downsample1d_block1')                # [1, 64, 256]\n",
    "        d2 = downsample1d_block(inputs=d1, filters=512, kernel_size=5, strides=2, name_prefix='downsample1d_block2')                    # [1, 32, 512]\n",
    "               \n",
    "        # Residual blocks\n",
    "        r1 = residual1d_block(inputs=d2, filters = 512, kernel_size=3, strides=1, name_prefix='residual1d_block1')                      # [1, 32, 512]\n",
    "        r2 = residual1d_block(inputs=r1, filters = 512, kernel_size=3, strides=1, name_prefix='residual1d_block2')\n",
    "        r3 = residual1d_block(inputs=r2, filters = 512, kernel_size=3, strides=1, name_prefix='residual1d_block3')\n",
    "        content = residual1d_block(inputs=r3, filters=512, kernel_size=3, strides=1, name_prefix='residual1d_block4')\n",
    "\n",
    "        return content                                                                                                                  # [1, 32, 512]\n",
    "\n",
    "\n",
    "def MLP(style, reuse=False, scope='MLP'):                                                                                               # [1, 1, 16]\n",
    "\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "\n",
    "        x1 = linear(style, 512, scope='linear_1')                                                                                       # [1, 1, 512]\n",
    "        x1_gates = linear(x1, 512, scope='linear_1_gates')\n",
    "        x1_glu = gated_linear_layer(inputs=x1, gates=x1_gates, name='x1_glu')\n",
    "\n",
    "        x2 = linear(x1_glu, 512, scope='linear_2')\n",
    "        x2_gates = linear(x2, 512, scope='linear_2_gates')\n",
    "        x2_glu = gated_linear_layer(inputs=x2, gates=x2_gates, name='x2_glu')\n",
    "\n",
    "        mu = linear(x2_glu, 512, scope='mu')\n",
    "        sigma = linear(x2_glu, 512, scope='sigma')\n",
    "\n",
    "        mu = tf.reshape(mu, shape=[-1, 1, 512])                                                                                         # [1, 1, 512]\n",
    "        sigma = tf.reshape(sigma, shape=[-1, 1, 512])                                                                                   # [1, 1, 512]\n",
    "\n",
    "        return mu, sigma                                                                                                                # [1, 1, 512]\n",
    "\n",
    "\n",
    "def Decoder(content, style, reuse=False, scope=\"decoder\"):\n",
    "\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "\n",
    "        mu, sigma = MLP(style, reuse)                                                                                                   # [1, 1, 512]\n",
    "        x = content                                                                                                                     # [1, 32, 512]\n",
    "\n",
    "        # Adaptive Residual blocks\n",
    "        r1 = residual1d_block_adaptive(inputs=x, filters=512, mu=mu, sigma=sigma, kernel_size=3, strides=1, name_prefix='residual1d_block1')        # [1, 32, 512]\n",
    "        r2 = residual1d_block_adaptive(inputs=r1, filters=512, mu=mu, sigma=sigma, kernel_size=3, strides=1, name_prefix='residual1d_block2')\n",
    "        r3 = residual1d_block_adaptive(inputs=r2, filters=512, mu=mu, sigma=sigma, kernel_size=3, strides=1, name_prefix='residual1d_block3')\n",
    "\n",
    "        # Upsample\n",
    "        u1 = upsample1d_block(inputs=r3, filters=512, kernel_size=5, strides=1, shuffle_size=2, name_prefix='upsample1d_block1')        # [1, 64, 512]\n",
    "        u2 = upsample1d_block(inputs=u1, filters=256, kernel_size=5, strides=1, shuffle_size=2, name_prefix='upsample1d_block2')        # [1, 128, 256]\n",
    "\n",
    "        # Output\n",
    "        o1 = conv1d_layer(inputs=u2, filters=24, kernel_size=15, strides=1, name='o1_conv')                                             # [1, 128, 24]\n",
    "        o2 = tf.transpose(o1, perm=[0, 2, 1], name='output_transpose')                                                                  # [1, 24, 128]\n",
    "\n",
    "        return o2                                                                                                                       # [1, 24, 128] = [batch_size, feature_channel, time]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator(inputs, reuse=False, scope='discriminator'):\n",
    "\n",
    "    # inputs = [batch_size, num_features, time]\n",
    "    # add channel for 2D convolution [batch_size, num_features, time, 1]\n",
    "    inputs = tf.expand_dims(inputs, -1)                                                                                                 # [1, 24, 128, 1]\n",
    "\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "\n",
    "        h1 = conv2d_layer(inputs=inputs, filters=128, kernel_size=[3, 3], strides=[1, 2], name='h1_conv')                               # [1, 24, 64, 128]\n",
    "        h1_gates = conv2d_layer(inputs=inputs, filters=128, kernel_size=[3, 3], strides=[1, 2], name='h1_conv_gates')\n",
    "        h1_glu = gated_linear_layer(inputs=h1, gates=h1_gates, name='h1_glu')\n",
    "\n",
    "        # Downsample\n",
    "        d1 = downsample2d_block(inputs=h1_glu, filters=256, kernel_size=[3, 3], strides=[2, 2], name_prefix='downsample2d_block1')      # [1, 12, 32, 256]\n",
    "        d2 = downsample2d_block(inputs=d1, filters=512, kernel_size=[3, 3], strides=[2, 2], name_prefix='downsample2d_block2')          # [1, 6, 16, 512]\n",
    "        d3 = downsample2d_block(inputs=d2, filters=1024, kernel_size=[6, 3], strides=[1, 2], name_prefix='downsample2d_block3')         # [1, 6, 8, 1024]\n",
    "\n",
    "        # Output\n",
    "        o1 = tf.layers.dense(inputs=d3, units=1, activation=tf.nn.sigmoid)\n",
    "\n",
    "        return [o1]                                                                                                                       # [1, 6, 8, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# Model\n",
    "##################################################################################\n",
    "\n",
    "def Encoder_A(x_A, reuse=False):\n",
    "    style_A = Style_Encoder(x_A, reuse=reuse, scope='style_encoder_A')\n",
    "    content_A = Content_Encoder(x_A, reuse=reuse, scope='content_encoder_A')\n",
    "\n",
    "    return content_A, style_A\n",
    "\n",
    "def Encoder_B(x_B, reuse=False):\n",
    "    style_B = Style_Encoder(x_B, reuse=reuse, scope='style_encoder_B')\n",
    "    content_B = Content_Encoder(x_B, reuse=reuse, scope='content_encoder_B')\n",
    "\n",
    "    return content_B, style_B\n",
    "\n",
    "def Decoder_A(content_B, style_A, reuse=False):\n",
    "    x_ba = Decoder(content=content_B, style=style_A, reuse=reuse, scope='decoder_A')\n",
    "\n",
    "    return x_ba\n",
    "\n",
    "def Decoder_B(content_A, style_B, reuse=False):\n",
    "    x_ab = Decoder(content=content_A, style=style_B, reuse=reuse, scope='decoder_B')\n",
    "\n",
    "    return x_ab\n",
    "\n",
    "def discriminate_real(x_A, x_B):\n",
    "    real_A_logit = Discriminator(x_A, scope=\"discriminator_A\")\n",
    "    real_B_logit = Discriminator(x_B, scope=\"discriminator_B\")\n",
    "\n",
    "    return real_A_logit, real_B_logit\n",
    "\n",
    "def discriminate_fake(x_ba, x_ab):\n",
    "    fake_A_logit = Discriminator(x_ba, reuse=True, scope=\"discriminator_A\")\n",
    "    fake_B_logit = Discriminator(x_ab, reuse=True, scope=\"discriminator_B\")\n",
    "\n",
    "    return fake_A_logit, fake_B_logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module: EmoMUNIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmoMUNIT(object):\n",
    "    def __init__(self, sess):\n",
    "        \n",
    "        self.train_A_dir = './../../../Database/Emotion/ang_neu/ang'\n",
    "        self.train_B_dir = './../../../Database/Emotion/ang_neu/neu'\n",
    "        self.validation_A_dir = './../../../Database/Emotion/ang_neu/val_ang'\n",
    "        self.validation_B_dir = './../../../Database/Emotion/ang_neu/val_neu'\n",
    "#         self.max_samples = 1000\n",
    "        \n",
    "        self.batch_size = 1\n",
    "        self.style_dim = 16\n",
    "        \n",
    "        self.Encoder_A = Encoder_A\n",
    "        self.Encoder_B = Encoder_B\n",
    "        self.Decoder_A = Decoder_A\n",
    "        self.Decoder_B = Decoder_B\n",
    "        self.discriminate_real = discriminate_real\n",
    "        self.discriminate_fake = discriminate_fake\n",
    "        \n",
    "        self.recon_x_cyc_w = 0.0\n",
    "        self.gan_type = 'lsgan'\n",
    "        \n",
    "        self.gan_w = 1.0\n",
    "        \n",
    "        self.recon_x_w = 1.0\n",
    "        self.recon_s_w = 1.0\n",
    "        self.recon_c_w = 1.0\n",
    "        self.recon_x_cyc_w = 0.0\n",
    "               \n",
    "        self.audio_len = 128    # = n_frames, time_length\n",
    "        self.audio_ch = 24      # = num_mcep, num_features\n",
    "        \n",
    "        self.direction = 'A2B'\n",
    "        \n",
    "        self.model_name = 'EmoMUNIT'\n",
    "        self.gan_type = 'lsgan'\n",
    "        self.dataset_name = 'ang2neu'\n",
    "        self.log_dir = 'logs'\n",
    "        self.sample_dir = 'samples'\n",
    "        self.checkpoint_dir = 'checkpoint'\n",
    "        self.result_dir = 'results'\n",
    "        \n",
    "        self.sess = sess\n",
    "        self.epoch = 1000\n",
    "        self.iteration = 1000\n",
    "        self.init_lr_D = 0.00005\n",
    "        self.init_lr_G = 0.0001\n",
    "        \n",
    "        self.sample_freq = 1000\n",
    "        self.save_freq = 1000\n",
    "        \n",
    "        self.sampling_rate = 16000\n",
    "        self.frame_period = 5.0\n",
    "        self.num_mcep = 24\n",
    "        \n",
    "    \n",
    "    def build_model(self):\n",
    "        self.lr_D = tf.placeholder(tf.float32, name='learning_rate_D')\n",
    "        self.lr_G = tf.placeholder(tf.float32, name='learning_rate_G')\n",
    "        \n",
    "        # Iterate from train_data_A and train_data_A\n",
    "        self.domain_A = tf.placeholder(tf.float32, shape=[self.batch_size, self.audio_ch, self.audio_len], name='domain_a')\n",
    "        self.domain_B = tf.placeholder(tf.float32, shape=[self.batch_size, self.audio_ch, self.audio_len], name='domain_b')\n",
    "    \n",
    "        self.style_a = tf.placeholder(tf.float32, shape=[self.batch_size, 1, self.style_dim], name='style_a')\n",
    "        self.style_b = tf.placeholder(tf.float32, shape=[self.batch_size, 1, self.style_dim], name='style_b')  \n",
    "    \n",
    "        # encode\n",
    "        content_a, style_a_prime = self.Encoder_A(self.domain_A)\n",
    "        content_b, style_b_prime = self.Encoder_B(self.domain_B)\n",
    "\n",
    "        # decode (within domain)\n",
    "        x_aa = self.Decoder_A(content_B=content_a, style_A=style_a_prime)\n",
    "        x_bb = self.Decoder_B(content_A=content_b, style_B=style_b_prime)\n",
    "    \n",
    "        # decode (cross domain)\n",
    "        x_ba = self.Decoder_A(content_B=content_b, style_A=self.style_a, reuse=True)\n",
    "        x_ab = self.Decoder_B(content_A=content_a, style_B=self.style_b, reuse=True)   \n",
    "    \n",
    "        # encode again\n",
    "        content_b_, style_a_ = self.Encoder_A(x_ba, reuse=True)\n",
    "        content_a_, style_b_ = self.Encoder_B(x_ab, reuse=True)    \n",
    "    \n",
    "        # decode again (if needed)\n",
    "        if self.recon_x_cyc_w > 0 :\n",
    "            x_aba = self.Decoder_A(content_B=content_a_, style_A=style_a_prime, reuse=True)\n",
    "            x_bab = self.Decoder_B(content_A=content_b_, style_B=style_b_prime, reuse=True)\n",
    "\n",
    "            cyc_recon_A = L1_loss(x_aba, self.domain_A)\n",
    "            cyc_recon_B = L1_loss(x_bab, self.domain_B)\n",
    "\n",
    "        else :\n",
    "            cyc_recon_A = 0.0\n",
    "            cyc_recon_B = 0.0    \n",
    "      \n",
    "        real_A_logit, real_B_logit = self.discriminate_real(self.domain_A, self.domain_B)\n",
    "        fake_A_logit, fake_B_logit = self.discriminate_fake(x_ba, x_ab)   \n",
    "    \n",
    "    \n",
    "        \"\"\" Define Loss \"\"\"\n",
    "        # Adversarial Loss\n",
    "        G_ad_loss_a = generator_loss(self.gan_type, fake_A_logit)\n",
    "        G_ad_loss_b = generator_loss(self.gan_type, fake_B_logit)\n",
    "    \n",
    "        # Discrimination Loss (real/fake)\n",
    "        D_ad_loss_a = discriminator_loss(self.gan_type, real_A_logit, fake_A_logit)\n",
    "        D_ad_loss_b = discriminator_loss(self.gan_type, real_B_logit, fake_B_logit)\n",
    "    \n",
    "        # Reconstruction Loss\n",
    "        recon_A = L1_loss(x_aa, self.domain_A) # reconstruction\n",
    "        recon_B = L1_loss(x_bb, self.domain_B) # reconstruction   \n",
    "    \n",
    "        # Semi-CycleGAN Loss\n",
    "        # For style, encourages diverse outputs given different style codes\n",
    "        recon_style_A = L1_loss(style_a_, self.style_a)\n",
    "        recon_style_B = L1_loss(style_b_, self.style_b)\n",
    "    \n",
    "        # For content, encourages the translated image to preserve semantic content of the input image\n",
    "        recon_content_A = L1_loss(content_a_, content_a)\n",
    "        recon_content_B = L1_loss(content_b_, content_b)   \n",
    "    \n",
    "        # Attacker Loss\n",
    "        Generator_A_loss = self.gan_w * G_ad_loss_a + \\\n",
    "                                   self.recon_x_w * recon_A + \\\n",
    "                                   self.recon_s_w * recon_style_A + \\\n",
    "                                   self.recon_c_w * recon_content_A + \\\n",
    "                                   self.recon_x_cyc_w * cyc_recon_A\n",
    "\n",
    "        Generator_B_loss = self.gan_w * G_ad_loss_b + \\\n",
    "                           self.recon_x_w * recon_B + \\\n",
    "                           self.recon_s_w * recon_style_B + \\\n",
    "                           self.recon_c_w * recon_content_B + \\\n",
    "                           self.recon_x_cyc_w * cyc_recon_B   \n",
    "    \n",
    "        # Defender Loss\n",
    "        Discriminator_A_loss = self.gan_w * D_ad_loss_a\n",
    "        Discriminator_B_loss = self.gan_w * D_ad_loss_b\n",
    "    \n",
    "        # Total Loss\n",
    "        self.Generator_loss = Generator_A_loss + Generator_B_loss\n",
    "        self.Discriminator_loss = Discriminator_A_loss + Discriminator_B_loss\n",
    "    \n",
    "    \n",
    "        \"\"\" Training Variables \"\"\"\n",
    "        t_vars = tf.trainable_variables()\n",
    "        G_vars = [var for var in t_vars if 'decoder' in var.name or 'encoder' in var.name]\n",
    "        D_vars = [var for var in t_vars if 'discriminator' in var.name]\n",
    "    \n",
    "        self.G_optim = tf.train.AdamOptimizer(self.lr_G, beta1=0.5, beta2=0.999).minimize(self.Generator_loss, var_list=G_vars)\n",
    "        self.D_optim = tf.train.AdamOptimizer(self.lr_D, beta1=0.5, beta2=0.999).minimize(self.Discriminator_loss, var_list=D_vars)\n",
    "    \n",
    "        \"\"\"\" Summary \"\"\"\n",
    "        self.all_G_loss = tf.summary.scalar(\"Generator_loss\", self.Generator_loss)\n",
    "        self.all_D_loss = tf.summary.scalar(\"Discriminator_loss\", self.Discriminator_loss)\n",
    "        self.R_A_loss = tf.summary.scalar(\"Reconstruction_A_loss\", recon_A)\n",
    "        self.R_B_loss = tf.summary.scalar(\"Reconstruction_B_loss\", recon_B)\n",
    "        self.G_A_loss = tf.summary.scalar(\"G_A_loss\", Generator_A_loss)\n",
    "        self.G_B_loss = tf.summary.scalar(\"G_B_loss\", Generator_B_loss)\n",
    "        self.D_A_loss = tf.summary.scalar(\"D_A_loss\", Discriminator_A_loss)\n",
    "        self.D_B_loss = tf.summary.scalar(\"D_B_loss\", Discriminator_B_loss)\n",
    "\n",
    "        self.G_loss = tf.summary.merge([self.R_A_loss, self.R_B_loss, self.G_A_loss, self.G_B_loss, self.all_G_loss])\n",
    "        self.D_loss = tf.summary.merge([self.D_A_loss, self.D_B_loss, self.all_D_loss])\n",
    "    \n",
    "    \n",
    "        \"\"\" Speech: real and fake \"\"\"\n",
    "        self.real_A = self.domain_A\n",
    "        self.real_B = self.domain_B\n",
    "\n",
    "        self.fake_A = x_ba\n",
    "        self.fake_B = x_ab \n",
    "    \n",
    "        \"\"\" Test Variables \"\"\"\n",
    "        self.test_domain_A = tf.placeholder(tf.float32, [1, self.audio_ch, None], name='test_domain_a') # [1 24 None]\n",
    "        self.test_domain_B = tf.placeholder(tf.float32, [1, self.audio_ch, None], name='test_domain_b') # [1 24 None]\n",
    "        \n",
    "        self.test_style_a = tf.placeholder(tf.float32, [1, 1, self.style_dim], name='test_style_a')   # [1 1 16]\n",
    "        self.test_style_b = tf.placeholder(tf.float32, [1, 1, self.style_dim], name='test_style_b')   # [1 1 16]\n",
    "        \n",
    "        test_content_a, test_style_a = self.Encoder_A(self.test_domain_A, reuse=True)\n",
    "        test_content_b, test_style_b = self.Encoder_B(self.test_domain_B, reuse=True)\n",
    "\n",
    "        self.test_fake_A = self.Decoder_A(content_B=test_content_b, style_A=self.test_style_a, reuse=True)\n",
    "        self.test_fake_B = self.Decoder_B(content_A=test_content_a, style_B=self.test_style_b, reuse=True)\n",
    "\n",
    "        self.test_recon_A = self.Decoder_A(content_B=test_content_a, style_A=test_style_a, reuse=True)\n",
    "        self.test_recon_B = self.Decoder_B(content_A=test_content_b, style_B=test_style_b, reuse=True)\n",
    "        \n",
    "        \n",
    "        \"\"\" Guided Speech Translation \"\"\"\n",
    "        self.content_audio = tf.placeholder(tf.float32, [1, self.audio_ch, self.audio_len], name='content_audio')\n",
    "        self.style_audio = tf.placeholder(tf.float32, [1, self.audio_ch, self.audio_len], name='guide_style_audio_ch')\n",
    "\n",
    "        if self.direction == 'A2B' :\n",
    "            guide_content_A, guide_style_A = self.Encoder_A(self.content_audio, reuse=True)\n",
    "            guide_content_B, guide_style_B = self.Encoder_B(self.style_audio, reuse=True)\n",
    "\n",
    "        else :\n",
    "            guide_content_B, guide_style_B = self.Encoder_B(self.content_audio, reuse=True)\n",
    "            guide_content_A, guide_style_A = self.Encoder_A(self.style_audio, reuse=True)\n",
    "\n",
    "        self.guide_fake_A = self.Decoder_A(content_B=guide_content_B, style_A=guide_style_A, reuse=True)\n",
    "        self.guide_fake_B = self.Decoder_B(content_A=guide_content_A, style_B=guide_style_B, reuse=True)\n",
    "    \n",
    "    \n",
    "    def data_prepare(self, f0s_A, f0s_B, coded_sps_norm_A, coded_sps_norm_B):\n",
    "        \n",
    "        train_data_A = sample_train_data03(sps=list(coded_sps_norm_A), f0s=list(f0s_A), n_frames=self.audio_len)\n",
    "        train_data_B = sample_train_data03(sps=list(coded_sps_norm_B), f0s=list(f0s_B), n_frames=self.audio_len)\n",
    "\n",
    "        minlen = min(len(train_data_A), len(train_data_B))\n",
    "        np.random.shuffle(train_data_A)\n",
    "        np.random.shuffle(train_data_B)\n",
    "        train_data_A = np.array(train_data_A[0:minlen])\n",
    "        train_data_B = np.array(train_data_B[0:minlen])\n",
    "\n",
    "        return train_data_A, train_data_B\n",
    "    \n",
    "    \n",
    "    def train(self):\n",
    "        # initialize all variables\n",
    "        tf.global_variables_initializer().run()\n",
    "        \n",
    "        # saver to save model\n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "        # summary writer\n",
    "        self.writer = tf.summary.FileWriter(self.log_dir + '/' + self.model_dir, self.sess.graph)\n",
    "        \n",
    "        # restore check-point if it exits\n",
    "        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n",
    "        if could_load:\n",
    "            start_epoch = (int)(checkpoint_counter / self.iteration)\n",
    "            start_batch_id = checkpoint_counter - start_epoch * self.iteration\n",
    "            counter = checkpoint_counter\n",
    "            print(\" [*] Load SUCCESS\")\n",
    "        else:\n",
    "            start_epoch = 0\n",
    "            start_batch_id = 0\n",
    "            counter = 1\n",
    "            print(\" [!] Load FAILED...\")\n",
    "            \n",
    "        # check sample_dir    \n",
    "        check_folder(self.sample_dir)\n",
    "        \n",
    "        \n",
    "        '''Training loop for epoch'''\n",
    "        \n",
    "        # load data and extract features\n",
    "        f0s_A, coded_sps_norm_A, log_f0s_mean_A, log_f0s_std_A, coded_sps_mean_A, coded_sps_std_A = vocoder_extract(self.train_A_dir)\n",
    "        f0s_B, coded_sps_norm_B, log_f0s_mean_B, log_f0s_std_B, coded_sps_mean_B, coded_sps_std_B = vocoder_extract(self.train_B_dir)\n",
    "        \n",
    "        # load validation data\n",
    "        wavs_val_A = load_wavs(wav_dir=self.validation_A_dir, sr=self.sampling_rate)\n",
    "        wavs_val_B = load_wavs(wav_dir=self.validation_B_dir, sr=self.sampling_rate)\n",
    "\n",
    "        start_time = time.time()\n",
    "        for epoch in range(start_epoch, self.epoch):\n",
    "            \n",
    "            train_data_A, train_data_B = self.data_prepare(f0s_A, f0s_B, coded_sps_norm_A, coded_sps_norm_B)\n",
    "            print('Epoch[%d]: Input data sampled from %d A and %d B audio files: train_data_A' %(epoch, len(f0s_A), len(f0s_B)), np.shape(train_data_A), 'train_data_B', np.shape(train_data_B))\n",
    "\n",
    "            lr_D, lr_G = self.init_lr_D * pow(0.995, epoch), self.init_lr_G * pow(0.995, epoch)\n",
    "            for idx in range(start_batch_id, self.iteration):\n",
    "                style_a = np.random.normal(loc=0.0, scale=1.0, size=[self.batch_size, 1, self.style_dim])\n",
    "                style_b = np.random.normal(loc=0.0, scale=1.0, size=[self.batch_size, 1, self.style_dim])\n",
    "                \n",
    "                idx_A = idx%len(train_data_A)\n",
    "                idx_B = idx%len(train_data_B)\n",
    "                domain_A = train_data_A[idx_A:idx_A+1].astype('float32')\n",
    "                domain_B = train_data_B[idx_B:idx_B+1].astype('float32')\n",
    "                \n",
    "                train_feed_dict = {\n",
    "                    self.style_a : style_a,\n",
    "                    self.style_b : style_b,\n",
    "                    self.lr_D : lr_D,\n",
    "                    self.lr_G : lr_G,\n",
    "                    self.domain_A : domain_A,\n",
    "                    self.domain_B : domain_B\n",
    "                }\n",
    "                \n",
    "                # Update D\n",
    "                _, d_loss, summary_str = self.sess.run([self.D_optim, self.Discriminator_loss, self.D_loss], feed_dict = train_feed_dict)\n",
    "                self.writer.add_summary(summary_str, counter)\n",
    "            \n",
    "                # Update G\n",
    "                batch_A_audios, batch_B_audios, fake_A, fake_B, _, g_loss, summary_str = \\\n",
    "                self.sess.run([self.real_A, self.real_B, self.fake_A, self.fake_B, self.G_optim, \\\n",
    "                               self.Generator_loss, self.G_loss], feed_dict = train_feed_dict)\n",
    "                self.writer.add_summary(summary_str, counter)           \n",
    "            \n",
    "                # display training status\n",
    "                counter += 1\n",
    "                print(\"Epoch: [%2d] [%6d/%6d] time: %4.4f d_loss: %.8f, g_loss: %.8f\" \\\n",
    "                      % (epoch, idx, self.iteration, time.time() - start_time, d_loss, g_loss), end='\\r')\n",
    "            \n",
    "                # save generated samples\n",
    "                if np.mod(counter+1, self.sample_freq) == 0:\n",
    "                    # A2B\n",
    "                    idx_val_A = (counter//self.sample_freq)%len(wavs_val_A)\n",
    "                    wav = wavs_val_A[idx_val_A]\n",
    "                    wav = wav_padding(wav = wav, sr = self.sampling_rate, frame_period = self.frame_period, multiple = 4)\n",
    "                    # f0 conversion\n",
    "                    f0, timeaxis, sp, ap = world_decompose(wav = wav, fs = self.sampling_rate, frame_period = self.frame_period)\n",
    "                    f0_converted = pitch_conversion(f0 = f0, mean_log_src = log_f0s_mean_A, std_log_src = log_f0s_std_A, mean_log_target = log_f0s_mean_B, std_log_target = log_f0s_std_B)\n",
    "                    # sp normalization\n",
    "                    coded_sp = world_encode_spectral_envelop(sp = sp, fs = self.sampling_rate, dim = self.num_mcep)\n",
    "                    coded_sp_transposed = coded_sp.T\n",
    "                    coded_sp_norm = (coded_sp_transposed - coded_sps_mean_A) / coded_sps_std_A\n",
    "                    # random sampled style\n",
    "                    test_style_b = np.random.normal(loc=0.0, scale=1.0, size=[1, 1, self.style_dim])\n",
    "                    # sp conversion (A2B)\n",
    "                    coded_sp_converted_norm = self.sess.run(self.test_fake_B, feed_dict = {self.test_domain_A: np.array([coded_sp_norm]), self.test_style_b : test_style_b})\n",
    "                    coded_sp_converted_norm_recon = self.sess.run(self.test_recon_A, feed_dict = {self.test_domain_A: np.array([coded_sp_norm])})\n",
    "                    # [1,24,None]\n",
    "                    # de-normalization\n",
    "                    coded_sp_converted = coded_sp_converted_norm[0] * coded_sps_std_B + coded_sps_mean_B\n",
    "                    coded_sp_converted = coded_sp_converted.T\n",
    "                    coded_sp_converted = np.ascontiguousarray(coded_sp_converted)\n",
    "                    coded_sp_converted_recon = coded_sp_converted_norm_recon[0] * coded_sps_std_A + coded_sps_mean_A\n",
    "                    coded_sp_converted_recon = coded_sp_converted_recon.T\n",
    "                    coded_sp_converted_recon = np.ascontiguousarray(coded_sp_converted_recon)\n",
    "                    # combine converted f0, sp and ap\n",
    "                    decoded_sp_converted = world_decode_spectral_envelop(coded_sp = coded_sp_converted, fs = self.sampling_rate)\n",
    "                    decoded_sp_converted_recon = world_decode_spectral_envelop(coded_sp = coded_sp_converted_recon, fs = self.sampling_rate)                   \n",
    "                    wav_transformed = world_speech_synthesis(f0 = f0_converted, decoded_sp = decoded_sp_converted, ap = ap, fs = self.sampling_rate, frame_period = self.frame_period)\n",
    "                    wav_transformed_recon = world_speech_synthesis(f0 = f0, decoded_sp = decoded_sp_converted_recon, ap = ap, fs = self.sampling_rate, frame_period = self.frame_period)\n",
    "                    # write .wav file\n",
    "                    path_A2B = './{}/fake_A2B_id{:03d}_iter{:03d}K.wav'.format(self.sample_dir, idx_val_A, counter//1000)\n",
    "                    path_A2A = './{}/recon_A2A_id{:03d}_iter{:03d}K.wav'.format(self.sample_dir, idx_val_A, counter//1000)\n",
    "                    save_audio(wav=wav_transformed, path=path_A2B, sr=self.sampling_rate)\n",
    "                    save_audio(wav=wav_transformed_recon, path=path_A2A, sr=self.sampling_rate)\n",
    "                    \n",
    "                \n",
    "                # save checkpoints\n",
    "                if np.mod(counter+1, self.save_freq) == 0 :\n",
    "                    self.save(self.checkpoint_dir, counter)\n",
    "        \n",
    "            # After an epoch, start_batch_id reset to zero\n",
    "            # non-zero value is only for the first epoch after loading pre-trained model\n",
    "            start_batch_id = 0\n",
    "\n",
    "            # save model for final step\n",
    "            self.save(self.checkpoint_dir, counter)\n",
    "            \n",
    "        print(\" [*] Training finished!\")\n",
    "        \n",
    "    \n",
    "    def test(self):\n",
    "        # initialize all variables\n",
    "        tf.global_variables_initializer().run()\n",
    "               \n",
    "        # saver to save model\n",
    "        self.saver = tf.train.Saver()\n",
    "    \n",
    "        # load check-point if it exits\n",
    "        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n",
    "    \n",
    "        if could_load :\n",
    "            print(\" [*] Load SUCCESS\")\n",
    "        else :\n",
    "            print(\" [!] Load FAILED...\")\n",
    "    \n",
    "        # check result_dir\n",
    "        check_folder(self.result_dir)\n",
    "        \n",
    "        # write html for visual comparison\n",
    "        \n",
    "        \n",
    "        # Get statistic from train_A, train_B\n",
    "        _, _, log_f0s_mean_A, log_f0s_std_A, coded_sps_A_mean, coded_sps_A_std = vocoder_extract(self.train_A_dir)\n",
    "        _, _, log_f0s_mean_B, log_f0s_std_B, coded_sps_B_mean, coded_sps_B_std = vocoder_extract(self.train_B_dir) \n",
    "        print('std_log_src:', log_f0s_std_A, 'std_log_target', log_f0s_std_B)\n",
    "        \n",
    "        \n",
    "        # A2B\n",
    "        test_files_A = os.listdir(self.validation_A_dir)\n",
    "        for i in range(len(test_files_A)):\n",
    "            file = test_files_A[i]\n",
    "            filepath = os.path.join(self.validation_A_dir, file)\n",
    "            wav, _ = librosa.load(filepath, sr = self.sampling_rate, mono = True)\n",
    "            wav = wav_padding(wav = wav, sr = self.sampling_rate, frame_period = self.frame_period, multiple = 4)\n",
    "            f0, timeaxis, sp, ap = world_decompose(wav = wav, fs = self.sampling_rate, frame_period = self.frame_period)\n",
    "            \n",
    "            # f0 conversion\n",
    "            f0_converted = pitch_conversion(f0 = f0, mean_log_src = log_f0s_mean_A, std_log_src = log_f0s_std_A, mean_log_target = log_f0s_mean_B, std_log_target = log_f0s_std_B)\n",
    "\n",
    "            # sp normalization\n",
    "            coded_sp = world_encode_spectral_envelop(sp = sp, fs = self.sampling_rate, dim = self.num_mcep)\n",
    "            coded_sp_transposed = coded_sp.T\n",
    "            coded_sp_norm = (coded_sp_transposed - coded_sps_A_mean) / coded_sps_A_std\n",
    "            \n",
    "            # random sampled style\n",
    "            test_style_b = np.random.normal(loc=0.0, scale=1.0, size=[1, 1, self.style_dim])\n",
    "            \n",
    "            # sp conversion (A2B)\n",
    "            coded_sp_converted_norm = self.sess.run(self.test_fake_B, feed_dict = {self.test_domain_A: np.array([coded_sp_norm]), self.test_style_b : test_style_b})\n",
    "            # [1,24,None]\n",
    "            \n",
    "            # print('coded_sp_converted_norm', np.shape(coded_sp_converted_norm[0]), 'coded_sps_B_mean', np.shape(coded_sps_B_mean), 'coded_sps_B_std:', np.shape(coded_sps_B_std))          \n",
    "            coded_sp_converted = coded_sp_converted_norm[0] * coded_sps_B_std + coded_sps_B_mean\n",
    "            coded_sp_converted = coded_sp_converted.T\n",
    "            coded_sp_converted = np.ascontiguousarray(coded_sp_converted)\n",
    "            decoded_sp_converted = world_decode_spectral_envelop(coded_sp = coded_sp_converted, fs = self.sampling_rate)\n",
    "            wav_transformed = world_speech_synthesis(f0 = f0_converted, decoded_sp = decoded_sp_converted, ap = ap, fs = self.sampling_rate, frame_period = self.frame_period)\n",
    "            librosa.output.write_wav(os.path.join(self.result_dir, os.path.basename(file)), wav_transformed, self.sampling_rate)\n",
    "            \n",
    "            print('converting test samples: [%d/%d]' %(i+1, len(test_files_A)), end='\\r')\n",
    "            \n",
    "        print(\" [*] Testing finished!\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def model_dir(self):\n",
    "        return \"{}_{}_{}\".format(self.model_name, self.dataset_name, self.gan_type)\n",
    "    \n",
    "    \n",
    "    def load(self, checkpoint_dir):\n",
    "        import re\n",
    "        print(\" [*] Reading checkpoints...\")\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir)\n",
    "\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n",
    "            counter = int(next(re.finditer(\"(\\d+)(?!.*\\d)\", ckpt_name)).group(0))\n",
    "            print(\" [*] Success to read {}\".format(ckpt_name))\n",
    "            return True, counter\n",
    "        else:\n",
    "            print(\" [*] Failed to find a checkpoint\")\n",
    "            return False, 0\n",
    "        \n",
    "        \n",
    "    def save(self, checkpoint_dir, step):\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir)\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "\n",
    "        self.saver.save(self.sess, os.path.join(checkpoint_dir, self.model_name + '.model'), global_step=step)        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Reading checkpoints...\n",
      " [*] Failed to find a checkpoint\n",
      " [!] Load FAILED...\n",
      "Epoch[0]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter000K.wav shape: (29120,)ss: 14.12851143\n",
      "saved file at ./samples/recon_A2A_id000_iter000K.wav shape: (29120,)\n",
      "Epoch[1]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter001K.wav shape: (114880,)s: 12.49997902\n",
      "saved file at ./samples/recon_A2A_id001_iter001K.wav shape: (114880,)\n",
      "Epoch[2]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter002K.wav shape: (49600,)ss: 10.73179626\n",
      "saved file at ./samples/recon_A2A_id002_iter002K.wav shape: (49600,)\n",
      "Epoch[3]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter003K.wav shape: (35840,)ss: 9.954175958\n",
      "saved file at ./samples/recon_A2A_id003_iter003K.wav shape: (35840,)\n",
      "Epoch[4]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter004K.wav shape: (60480,)oss: 10.16918945\n",
      "saved file at ./samples/recon_A2A_id004_iter004K.wav shape: (60480,)\n",
      "Epoch[5]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter005K.wav shape: (39680,)oss: 8.646703722\n",
      "saved file at ./samples/recon_A2A_id005_iter005K.wav shape: (39680,)\n",
      "Epoch[6]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter006K.wav shape: (98240,)oss: 8.746485717\n",
      "saved file at ./samples/recon_A2A_id006_iter006K.wav shape: (98240,)\n",
      "Epoch[7]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter007K.wav shape: (32640,)oss: 9.006448750\n",
      "saved file at ./samples/recon_A2A_id007_iter007K.wav shape: (32640,)\n",
      "Epoch[8]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter008K.wav shape: (56640,)oss: 8.923213961\n",
      "saved file at ./samples/recon_A2A_id008_iter008K.wav shape: (56640,)\n",
      "Epoch[9]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter009K.wav shape: (19840,)oss: 8.040840154\n",
      "saved file at ./samples/recon_A2A_id009_iter009K.wav shape: (19840,)\n",
      "Epoch[10]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter010K.wav shape: (40960,)oss: 8.382098201\n",
      "saved file at ./samples/recon_A2A_id010_iter010K.wav shape: (40960,)\n",
      "Epoch[11]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter011K.wav shape: (45760,)oss: 7.716891294\n",
      "saved file at ./samples/recon_A2A_id011_iter011K.wav shape: (45760,)\n",
      "Epoch[12]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter012K.wav shape: (80640,)oss: 7.968355662\n",
      "saved file at ./samples/recon_A2A_id012_iter012K.wav shape: (80640,)\n",
      "Epoch[13]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter013K.wav shape: (26880,)oss: 7.031815053\n",
      "saved file at ./samples/recon_A2A_id013_iter013K.wav shape: (26880,)\n",
      "Epoch[14]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter014K.wav shape: (41920,)oss: 10.02032852\n",
      "saved file at ./samples/recon_A2A_id014_iter014K.wav shape: (41920,)\n",
      "Epoch[15]: Input data sampled from 128 A and 128 B audio files: train_data_A (456, 24, 128) train_data_B (456, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter015K.wav shape: (83200,)oss: 7.128800394\n",
      "saved file at ./samples/recon_A2A_id015_iter015K.wav shape: (83200,)\n",
      "Epoch[16]: Input data sampled from 128 A and 128 B audio files: train_data_A (456, 24, 128) train_data_B (456, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter016K.wav shape: (150400,)ss: 7.20406914\n",
      "saved file at ./samples/recon_A2A_id016_iter016K.wav shape: (150400,)\n",
      "Epoch[17]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter017K.wav shape: (78720,)oss: 6.450128563\n",
      "saved file at ./samples/recon_A2A_id017_iter017K.wav shape: (78720,)\n",
      "Epoch[18]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter018K.wav shape: (303360,)ss: 7.170797357\n",
      "saved file at ./samples/recon_A2A_id018_iter018K.wav shape: (303360,)\n",
      "Epoch[19]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter019K.wav shape: (29120,)oss: 6.22014618\n",
      "saved file at ./samples/recon_A2A_id000_iter019K.wav shape: (29120,)\n",
      "Epoch[20]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter020K.wav shape: (114880,)ss: 6.96563053\n",
      "saved file at ./samples/recon_A2A_id001_iter020K.wav shape: (114880,)\n",
      "Epoch[21]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter021K.wav shape: (49600,)oss: 6.61996174\n",
      "saved file at ./samples/recon_A2A_id002_iter021K.wav shape: (49600,)\n",
      "Epoch[22]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter022K.wav shape: (35840,)oss: 6.81186628\n",
      "saved file at ./samples/recon_A2A_id003_iter022K.wav shape: (35840,)\n",
      "Epoch[23]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter023K.wav shape: (60480,)oss: 6.045147907\n",
      "saved file at ./samples/recon_A2A_id004_iter023K.wav shape: (60480,)\n",
      "Epoch[24]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter024K.wav shape: (39680,)oss: 6.54909039\n",
      "saved file at ./samples/recon_A2A_id005_iter024K.wav shape: (39680,)\n",
      "Epoch[25]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter025K.wav shape: (98240,)oss: 7.09666443\n",
      "saved file at ./samples/recon_A2A_id006_iter025K.wav shape: (98240,)\n",
      "Epoch[26]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter026K.wav shape: (32640,)oss: 6.062404630\n",
      "saved file at ./samples/recon_A2A_id007_iter026K.wav shape: (32640,)\n",
      "Epoch[27]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter027K.wav shape: (56640,)oss: 6.38932228\n",
      "saved file at ./samples/recon_A2A_id008_iter027K.wav shape: (56640,)\n",
      "Epoch[28]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter028K.wav shape: (19840,)oss: 6.01198864\n",
      "saved file at ./samples/recon_A2A_id009_iter028K.wav shape: (19840,)\n",
      "Epoch[29]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter029K.wav shape: (40960,)oss: 6.19900465\n",
      "saved file at ./samples/recon_A2A_id010_iter029K.wav shape: (40960,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[30]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter030K.wav shape: (45760,)oss: 6.61424065\n",
      "saved file at ./samples/recon_A2A_id011_iter030K.wav shape: (45760,)\n",
      "Epoch[31]: Input data sampled from 128 A and 128 B audio files: train_data_A (457, 24, 128) train_data_B (457, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter031K.wav shape: (80640,)oss: 6.29172516\n",
      "saved file at ./samples/recon_A2A_id012_iter031K.wav shape: (80640,)\n",
      "Epoch[32]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter032K.wav shape: (26880,)oss: 6.18160439\n",
      "saved file at ./samples/recon_A2A_id013_iter032K.wav shape: (26880,)\n",
      "Epoch[33]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter033K.wav shape: (41920,)oss: 5.86509705\n",
      "saved file at ./samples/recon_A2A_id014_iter033K.wav shape: (41920,)\n",
      "Epoch[34]: Input data sampled from 128 A and 128 B audio files: train_data_A (441, 24, 128) train_data_B (441, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter034K.wav shape: (83200,)oss: 6.06940174\n",
      "saved file at ./samples/recon_A2A_id015_iter034K.wav shape: (83200,)\n",
      "Epoch[35]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter035K.wav shape: (150400,)ss: 6.355468754\n",
      "saved file at ./samples/recon_A2A_id016_iter035K.wav shape: (150400,)\n",
      "Epoch[36]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter036K.wav shape: (78720,)oss: 6.45300817\n",
      "saved file at ./samples/recon_A2A_id017_iter036K.wav shape: (78720,)\n",
      "Epoch[37]: Input data sampled from 128 A and 128 B audio files: train_data_A (461, 24, 128) train_data_B (461, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter037K.wav shape: (303360,)ss: 5.71715546\n",
      "saved file at ./samples/recon_A2A_id018_iter037K.wav shape: (303360,)\n",
      "Epoch[38]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter038K.wav shape: (29120,)oss: 7.06947613\n",
      "saved file at ./samples/recon_A2A_id000_iter038K.wav shape: (29120,)\n",
      "Epoch[39]: Input data sampled from 128 A and 128 B audio files: train_data_A (458, 24, 128) train_data_B (458, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter039K.wav shape: (114880,)ss: 6.473927021\n",
      "saved file at ./samples/recon_A2A_id001_iter039K.wav shape: (114880,)\n",
      "Epoch[40]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter040K.wav shape: (49600,)oss: 6.06404495\n",
      "saved file at ./samples/recon_A2A_id002_iter040K.wav shape: (49600,)\n",
      "Epoch[41]: Input data sampled from 128 A and 128 B audio files: train_data_A (456, 24, 128) train_data_B (456, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter041K.wav shape: (35840,)oss: 5.29550982\n",
      "saved file at ./samples/recon_A2A_id003_iter041K.wav shape: (35840,)\n",
      "Epoch[42]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter042K.wav shape: (60480,)oss: 5.64662123\n",
      "saved file at ./samples/recon_A2A_id004_iter042K.wav shape: (60480,)\n",
      "Epoch[43]: Input data sampled from 128 A and 128 B audio files: train_data_A (437, 24, 128) train_data_B (437, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter043K.wav shape: (39680,)oss: 6.05809736\n",
      "saved file at ./samples/recon_A2A_id005_iter043K.wav shape: (39680,)\n",
      "Epoch[44]: Input data sampled from 128 A and 128 B audio files: train_data_A (436, 24, 128) train_data_B (436, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter044K.wav shape: (98240,)oss: 5.77690172\n",
      "saved file at ./samples/recon_A2A_id006_iter044K.wav shape: (98240,)\n",
      "Epoch[45]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter045K.wav shape: (32640,)oss: 5.99706936\n",
      "saved file at ./samples/recon_A2A_id007_iter045K.wav shape: (32640,)\n",
      "Epoch[46]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter046K.wav shape: (56640,)oss: 5.79941082\n",
      "saved file at ./samples/recon_A2A_id008_iter046K.wav shape: (56640,)\n",
      "Epoch[47]: Input data sampled from 128 A and 128 B audio files: train_data_A (459, 24, 128) train_data_B (459, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter047K.wav shape: (19840,)oss: 5.818222526\n",
      "saved file at ./samples/recon_A2A_id009_iter047K.wav shape: (19840,)\n",
      "Epoch[48]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter048K.wav shape: (40960,)oss: 5.93819237\n",
      "saved file at ./samples/recon_A2A_id010_iter048K.wav shape: (40960,)\n",
      "Epoch[49]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter049K.wav shape: (45760,)loss: 5.25589466\n",
      "saved file at ./samples/recon_A2A_id011_iter049K.wav shape: (45760,)\n",
      "Epoch[50]: Input data sampled from 128 A and 128 B audio files: train_data_A (460, 24, 128) train_data_B (460, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter050K.wav shape: (80640,)loss: 5.980241302\n",
      "saved file at ./samples/recon_A2A_id012_iter050K.wav shape: (80640,)\n",
      "Epoch[51]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter051K.wav shape: (26880,)loss: 5.25750732\n",
      "saved file at ./samples/recon_A2A_id013_iter051K.wav shape: (26880,)\n",
      "Epoch[52]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter052K.wav shape: (41920,)loss: 5.662652975\n",
      "saved file at ./samples/recon_A2A_id014_iter052K.wav shape: (41920,)\n",
      "Epoch[53]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter053K.wav shape: (83200,)loss: 5.49809027\n",
      "saved file at ./samples/recon_A2A_id015_iter053K.wav shape: (83200,)\n",
      "Epoch[54]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter054K.wav shape: (150400,)oss: 5.88359594\n",
      "saved file at ./samples/recon_A2A_id016_iter054K.wav shape: (150400,)\n",
      "Epoch[55]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter055K.wav shape: (78720,)loss: 5.89373493\n",
      "saved file at ./samples/recon_A2A_id017_iter055K.wav shape: (78720,)\n",
      "Epoch[56]: Input data sampled from 128 A and 128 B audio files: train_data_A (457, 24, 128) train_data_B (457, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter056K.wav shape: (303360,)oss: 5.32600117\n",
      "saved file at ./samples/recon_A2A_id018_iter056K.wav shape: (303360,)\n",
      "Epoch[57]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter057K.wav shape: (29120,)loss: 5.46010447\n",
      "saved file at ./samples/recon_A2A_id000_iter057K.wav shape: (29120,)\n",
      "Epoch[58]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter058K.wav shape: (114880,)oss: 5.24237299\n",
      "saved file at ./samples/recon_A2A_id001_iter058K.wav shape: (114880,)\n",
      "Epoch[59]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter059K.wav shape: (49600,)loss: 5.56786346\n",
      "saved file at ./samples/recon_A2A_id002_iter059K.wav shape: (49600,)\n",
      "Epoch[60]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter060K.wav shape: (35840,)loss: 5.11069250\n",
      "saved file at ./samples/recon_A2A_id003_iter060K.wav shape: (35840,)\n",
      "Epoch[61]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter061K.wav shape: (60480,)loss: 5.21129990\n",
      "saved file at ./samples/recon_A2A_id004_iter061K.wav shape: (60480,)\n",
      "Epoch[62]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter062K.wav shape: (39680,)loss: 5.33488274\n",
      "saved file at ./samples/recon_A2A_id005_iter062K.wav shape: (39680,)\n",
      "Epoch[63]: Input data sampled from 128 A and 128 B audio files: train_data_A (442, 24, 128) train_data_B (442, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter063K.wav shape: (98240,)loss: 5.17792368\n",
      "saved file at ./samples/recon_A2A_id006_iter063K.wav shape: (98240,)\n",
      "Epoch[64]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter064K.wav shape: (32640,)loss: 5.94427586\n",
      "saved file at ./samples/recon_A2A_id007_iter064K.wav shape: (32640,)\n",
      "Epoch[65]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter065K.wav shape: (56640,)loss: 5.03825283\n",
      "saved file at ./samples/recon_A2A_id008_iter065K.wav shape: (56640,)\n",
      "Epoch[66]: Input data sampled from 128 A and 128 B audio files: train_data_A (442, 24, 128) train_data_B (442, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter066K.wav shape: (19840,)loss: 6.53847075\n",
      "saved file at ./samples/recon_A2A_id009_iter066K.wav shape: (19840,)\n",
      "Epoch[67]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter067K.wav shape: (40960,)loss: 5.01869869\n",
      "saved file at ./samples/recon_A2A_id010_iter067K.wav shape: (40960,)\n",
      "Epoch[68]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter068K.wav shape: (45760,)loss: 5.37971687\n",
      "saved file at ./samples/recon_A2A_id011_iter068K.wav shape: (45760,)\n",
      "Epoch[69]: Input data sampled from 128 A and 128 B audio files: train_data_A (442, 24, 128) train_data_B (442, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter069K.wav shape: (80640,)loss: 5.40711594\n",
      "saved file at ./samples/recon_A2A_id012_iter069K.wav shape: (80640,)\n",
      "Epoch[70]: Input data sampled from 128 A and 128 B audio files: train_data_A (438, 24, 128) train_data_B (438, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter070K.wav shape: (26880,)loss: 5.165631298\n",
      "saved file at ./samples/recon_A2A_id013_iter070K.wav shape: (26880,)\n",
      "Epoch[71]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter071K.wav shape: (41920,)loss: 5.36605453\n",
      "saved file at ./samples/recon_A2A_id014_iter071K.wav shape: (41920,)\n",
      "Epoch[72]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter072K.wav shape: (83200,)loss: 5.64081860\n",
      "saved file at ./samples/recon_A2A_id015_iter072K.wav shape: (83200,)\n",
      "Epoch[73]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter073K.wav shape: (150400,)oss: 5.45411205\n",
      "saved file at ./samples/recon_A2A_id016_iter073K.wav shape: (150400,)\n",
      "Epoch[74]: Input data sampled from 128 A and 128 B audio files: train_data_A (458, 24, 128) train_data_B (458, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter074K.wav shape: (78720,)loss: 5.16445732\n",
      "saved file at ./samples/recon_A2A_id017_iter074K.wav shape: (78720,)\n",
      "Epoch[75]: Input data sampled from 128 A and 128 B audio files: train_data_A (442, 24, 128) train_data_B (442, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter075K.wav shape: (303360,)oss: 5.12072611\n",
      "saved file at ./samples/recon_A2A_id018_iter075K.wav shape: (303360,)\n",
      "Epoch[76]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter076K.wav shape: (29120,)loss: 5.78892803\n",
      "saved file at ./samples/recon_A2A_id000_iter076K.wav shape: (29120,)\n",
      "Epoch[77]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter077K.wav shape: (114880,)oss: 5.24151611\n",
      "saved file at ./samples/recon_A2A_id001_iter077K.wav shape: (114880,)\n",
      "Epoch[78]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter078K.wav shape: (49600,)loss: 5.11250114\n",
      "saved file at ./samples/recon_A2A_id002_iter078K.wav shape: (49600,)\n",
      "Epoch[79]: Input data sampled from 128 A and 128 B audio files: train_data_A (438, 24, 128) train_data_B (438, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter079K.wav shape: (35840,)loss: 5.61734867\n",
      "saved file at ./samples/recon_A2A_id003_iter079K.wav shape: (35840,)\n",
      "Epoch[80]: Input data sampled from 128 A and 128 B audio files: train_data_A (437, 24, 128) train_data_B (437, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter080K.wav shape: (60480,)loss: 4.99212885\n",
      "saved file at ./samples/recon_A2A_id004_iter080K.wav shape: (60480,)\n",
      "Epoch[81]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter081K.wav shape: (39680,)loss: 5.178070072\n",
      "saved file at ./samples/recon_A2A_id005_iter081K.wav shape: (39680,)\n",
      "Epoch[82]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter082K.wav shape: (98240,)loss: 5.41918373\n",
      "saved file at ./samples/recon_A2A_id006_iter082K.wav shape: (98240,)\n",
      "Epoch[83]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter083K.wav shape: (32640,)loss: 5.17130756\n",
      "saved file at ./samples/recon_A2A_id007_iter083K.wav shape: (32640,)\n",
      "Epoch[84]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter084K.wav shape: (56640,)loss: 4.98433685\n",
      "saved file at ./samples/recon_A2A_id008_iter084K.wav shape: (56640,)\n",
      "Epoch[85]: Input data sampled from 128 A and 128 B audio files: train_data_A (438, 24, 128) train_data_B (438, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter085K.wav shape: (19840,)loss: 4.87228203\n",
      "saved file at ./samples/recon_A2A_id009_iter085K.wav shape: (19840,)\n",
      "Epoch[86]: Input data sampled from 128 A and 128 B audio files: train_data_A (457, 24, 128) train_data_B (457, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter086K.wav shape: (40960,)loss: 4.95011997\n",
      "saved file at ./samples/recon_A2A_id010_iter086K.wav shape: (40960,)\n",
      "Epoch[87]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter087K.wav shape: (45760,)loss: 4.99283504\n",
      "saved file at ./samples/recon_A2A_id011_iter087K.wav shape: (45760,)\n",
      "Epoch[88]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter088K.wav shape: (80640,)loss: 4.94550753\n",
      "saved file at ./samples/recon_A2A_id012_iter088K.wav shape: (80640,)\n",
      "Epoch[89]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter089K.wav shape: (26880,)loss: 5.15713215\n",
      "saved file at ./samples/recon_A2A_id013_iter089K.wav shape: (26880,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[90]: Input data sampled from 128 A and 128 B audio files: train_data_A (463, 24, 128) train_data_B (463, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter090K.wav shape: (41920,)loss: 4.63266468\n",
      "saved file at ./samples/recon_A2A_id014_iter090K.wav shape: (41920,)\n",
      "Epoch[91]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter091K.wav shape: (83200,)loss: 5.07719040\n",
      "saved file at ./samples/recon_A2A_id015_iter091K.wav shape: (83200,)\n",
      "Epoch[92]: Input data sampled from 128 A and 128 B audio files: train_data_A (456, 24, 128) train_data_B (456, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter092K.wav shape: (150400,)oss: 4.50657415\n",
      "saved file at ./samples/recon_A2A_id016_iter092K.wav shape: (150400,)\n",
      "Epoch[93]: Input data sampled from 128 A and 128 B audio files: train_data_A (442, 24, 128) train_data_B (442, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter093K.wav shape: (78720,)loss: 5.18778944\n",
      "saved file at ./samples/recon_A2A_id017_iter093K.wav shape: (78720,)\n",
      "Epoch[94]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter094K.wav shape: (303360,)oss: 4.691050054\n",
      "saved file at ./samples/recon_A2A_id018_iter094K.wav shape: (303360,)\n",
      "Epoch[95]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter095K.wav shape: (29120,)loss: 4.93680668\n",
      "saved file at ./samples/recon_A2A_id000_iter095K.wav shape: (29120,)\n",
      "Epoch[96]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter096K.wav shape: (114880,)oss: 4.66069269\n",
      "saved file at ./samples/recon_A2A_id001_iter096K.wav shape: (114880,)\n",
      "Epoch[97]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter097K.wav shape: (49600,)loss: 4.83528137\n",
      "saved file at ./samples/recon_A2A_id002_iter097K.wav shape: (49600,)\n",
      "Epoch[98]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter098K.wav shape: (35840,)loss: 5.23016167\n",
      "saved file at ./samples/recon_A2A_id003_iter098K.wav shape: (35840,)\n",
      "Epoch[99]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter099K.wav shape: (60480,)loss: 5.31444502\n",
      "saved file at ./samples/recon_A2A_id004_iter099K.wav shape: (60480,)\n",
      "Epoch[100]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter100K.wav shape: (39680,)_loss: 4.521970757\n",
      "saved file at ./samples/recon_A2A_id005_iter100K.wav shape: (39680,)\n",
      "Epoch[101]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter101K.wav shape: (98240,)_loss: 5.18677044\n",
      "saved file at ./samples/recon_A2A_id006_iter101K.wav shape: (98240,)\n",
      "Epoch[102]: Input data sampled from 128 A and 128 B audio files: train_data_A (462, 24, 128) train_data_B (462, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter102K.wav shape: (32640,)_loss: 4.81301403\n",
      "saved file at ./samples/recon_A2A_id007_iter102K.wav shape: (32640,)\n",
      "Epoch[103]: Input data sampled from 128 A and 128 B audio files: train_data_A (441, 24, 128) train_data_B (441, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter103K.wav shape: (56640,)_loss: 5.06357670\n",
      "saved file at ./samples/recon_A2A_id008_iter103K.wav shape: (56640,)\n",
      "Epoch[104]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter104K.wav shape: (19840,)_loss: 4.84793186\n",
      "saved file at ./samples/recon_A2A_id009_iter104K.wav shape: (19840,)\n",
      "Epoch[105]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter105K.wav shape: (40960,)_loss: 4.65811062\n",
      "saved file at ./samples/recon_A2A_id010_iter105K.wav shape: (40960,)\n",
      "Epoch[106]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter106K.wav shape: (45760,)_loss: 4.66998196\n",
      "saved file at ./samples/recon_A2A_id011_iter106K.wav shape: (45760,)\n",
      "Epoch[107]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter107K.wav shape: (80640,)_loss: 5.295117868\n",
      "saved file at ./samples/recon_A2A_id012_iter107K.wav shape: (80640,)\n",
      "Epoch[108]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter108K.wav shape: (26880,)_loss: 4.647053722\n",
      "saved file at ./samples/recon_A2A_id013_iter108K.wav shape: (26880,)\n",
      "Epoch[109]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter109K.wav shape: (41920,)_loss: 4.64843464\n",
      "saved file at ./samples/recon_A2A_id014_iter109K.wav shape: (41920,)\n",
      "Epoch[110]: Input data sampled from 128 A and 128 B audio files: train_data_A (437, 24, 128) train_data_B (437, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter110K.wav shape: (83200,)_loss: 4.64421082\n",
      "saved file at ./samples/recon_A2A_id015_iter110K.wav shape: (83200,)\n",
      "Epoch[111]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter111K.wav shape: (150400,)loss: 4.52997303\n",
      "saved file at ./samples/recon_A2A_id016_iter111K.wav shape: (150400,)\n",
      "Epoch[112]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter112K.wav shape: (78720,)_loss: 4.59671831\n",
      "saved file at ./samples/recon_A2A_id017_iter112K.wav shape: (78720,)\n",
      "Epoch[113]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter113K.wav shape: (303360,)loss: 4.71233749\n",
      "saved file at ./samples/recon_A2A_id018_iter113K.wav shape: (303360,)\n",
      "Epoch[114]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter114K.wav shape: (29120,)_loss: 4.64818668\n",
      "saved file at ./samples/recon_A2A_id000_iter114K.wav shape: (29120,)\n",
      "Epoch[115]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter115K.wav shape: (114880,)loss: 5.06767178\n",
      "saved file at ./samples/recon_A2A_id001_iter115K.wav shape: (114880,)\n",
      "Epoch[116]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter116K.wav shape: (49600,)_loss: 4.501776709\n",
      "saved file at ./samples/recon_A2A_id002_iter116K.wav shape: (49600,)\n",
      "Epoch[117]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter117K.wav shape: (35840,)_loss: 4.66824436\n",
      "saved file at ./samples/recon_A2A_id003_iter117K.wav shape: (35840,)\n",
      "Epoch[118]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter118K.wav shape: (60480,)_loss: 4.68367290\n",
      "saved file at ./samples/recon_A2A_id004_iter118K.wav shape: (60480,)\n",
      "Epoch[119]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter119K.wav shape: (39680,)_loss: 4.62166977\n",
      "saved file at ./samples/recon_A2A_id005_iter119K.wav shape: (39680,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[120]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter120K.wav shape: (98240,)_loss: 4.54077625\n",
      "saved file at ./samples/recon_A2A_id006_iter120K.wav shape: (98240,)\n",
      "Epoch[121]: Input data sampled from 128 A and 128 B audio files: train_data_A (441, 24, 128) train_data_B (441, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter121K.wav shape: (32640,)_loss: 4.44831753\n",
      "saved file at ./samples/recon_A2A_id007_iter121K.wav shape: (32640,)\n",
      "Epoch[122]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter122K.wav shape: (56640,)_loss: 4.89382029\n",
      "saved file at ./samples/recon_A2A_id008_iter122K.wav shape: (56640,)\n",
      "Epoch[123]: Input data sampled from 128 A and 128 B audio files: train_data_A (456, 24, 128) train_data_B (456, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter123K.wav shape: (19840,)_loss: 4.265113836\n",
      "saved file at ./samples/recon_A2A_id009_iter123K.wav shape: (19840,)\n",
      "Epoch[124]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter124K.wav shape: (40960,)_loss: 4.38938427\n",
      "saved file at ./samples/recon_A2A_id010_iter124K.wav shape: (40960,)\n",
      "Epoch[125]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter125K.wav shape: (45760,)_loss: 4.68049526\n",
      "saved file at ./samples/recon_A2A_id011_iter125K.wav shape: (45760,)\n",
      "Epoch[126]: Input data sampled from 128 A and 128 B audio files: train_data_A (456, 24, 128) train_data_B (456, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter126K.wav shape: (80640,)_loss: 4.879858490\n",
      "saved file at ./samples/recon_A2A_id012_iter126K.wav shape: (80640,)\n",
      "Epoch[127]: Input data sampled from 128 A and 128 B audio files: train_data_A (458, 24, 128) train_data_B (458, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter127K.wav shape: (26880,)_loss: 4.51330090\n",
      "saved file at ./samples/recon_A2A_id013_iter127K.wav shape: (26880,)\n",
      "Epoch[128]: Input data sampled from 128 A and 128 B audio files: train_data_A (457, 24, 128) train_data_B (457, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter128K.wav shape: (41920,)_loss: 4.67452621\n",
      "saved file at ./samples/recon_A2A_id014_iter128K.wav shape: (41920,)\n",
      "Epoch[129]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter129K.wav shape: (83200,)_loss: 4.48394775\n",
      "saved file at ./samples/recon_A2A_id015_iter129K.wav shape: (83200,)\n",
      "Epoch[130]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter130K.wav shape: (150400,)loss: 4.61618996\n",
      "saved file at ./samples/recon_A2A_id016_iter130K.wav shape: (150400,)\n",
      "Epoch[131]: Input data sampled from 128 A and 128 B audio files: train_data_A (456, 24, 128) train_data_B (456, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter131K.wav shape: (78720,)_loss: 4.31778431\n",
      "saved file at ./samples/recon_A2A_id017_iter131K.wav shape: (78720,)\n",
      "Epoch[132]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter132K.wav shape: (303360,)loss: 4.54573917\n",
      "saved file at ./samples/recon_A2A_id018_iter132K.wav shape: (303360,)\n",
      "Epoch[133]: Input data sampled from 128 A and 128 B audio files: train_data_A (457, 24, 128) train_data_B (457, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter133K.wav shape: (29120,)_loss: 4.65082169\n",
      "saved file at ./samples/recon_A2A_id000_iter133K.wav shape: (29120,)\n",
      "Epoch[134]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter134K.wav shape: (114880,)loss: 4.54239750\n",
      "saved file at ./samples/recon_A2A_id001_iter134K.wav shape: (114880,)\n",
      "Epoch[135]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter135K.wav shape: (49600,)_loss: 4.620166789\n",
      "saved file at ./samples/recon_A2A_id002_iter135K.wav shape: (49600,)\n",
      "Epoch[136]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter136K.wav shape: (35840,)_loss: 4.56914473\n",
      "saved file at ./samples/recon_A2A_id003_iter136K.wav shape: (35840,)\n",
      "Epoch[137]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter137K.wav shape: (60480,)_loss: 4.75759077\n",
      "saved file at ./samples/recon_A2A_id004_iter137K.wav shape: (60480,)\n",
      "Epoch[138]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter138K.wav shape: (39680,)_loss: 4.37554455\n",
      "saved file at ./samples/recon_A2A_id005_iter138K.wav shape: (39680,)\n",
      "Epoch[139]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter139K.wav shape: (98240,)_loss: 4.41152334\n",
      "saved file at ./samples/recon_A2A_id006_iter139K.wav shape: (98240,)\n",
      "Epoch[140]: Input data sampled from 128 A and 128 B audio files: train_data_A (440, 24, 128) train_data_B (440, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter140K.wav shape: (32640,)_loss: 5.01263714\n",
      "saved file at ./samples/recon_A2A_id007_iter140K.wav shape: (32640,)\n",
      "Epoch[141]: Input data sampled from 128 A and 128 B audio files: train_data_A (439, 24, 128) train_data_B (439, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter141K.wav shape: (56640,)_loss: 4.74166536\n",
      "saved file at ./samples/recon_A2A_id008_iter141K.wav shape: (56640,)\n",
      "Epoch[142]: Input data sampled from 128 A and 128 B audio files: train_data_A (434, 24, 128) train_data_B (434, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter142K.wav shape: (19840,)_loss: 4.32635212\n",
      "saved file at ./samples/recon_A2A_id009_iter142K.wav shape: (19840,)\n",
      "Epoch[143]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter143K.wav shape: (40960,)_loss: 4.42421532\n",
      "saved file at ./samples/recon_A2A_id010_iter143K.wav shape: (40960,)\n",
      "Epoch[144]: Input data sampled from 128 A and 128 B audio files: train_data_A (440, 24, 128) train_data_B (440, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter144K.wav shape: (45760,)_loss: 4.88509274\n",
      "saved file at ./samples/recon_A2A_id011_iter144K.wav shape: (45760,)\n",
      "Epoch[145]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter145K.wav shape: (80640,)_loss: 4.34307098\n",
      "saved file at ./samples/recon_A2A_id012_iter145K.wav shape: (80640,)\n",
      "Epoch[146]: Input data sampled from 128 A and 128 B audio files: train_data_A (457, 24, 128) train_data_B (457, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter146K.wav shape: (26880,)_loss: 4.30182838\n",
      "saved file at ./samples/recon_A2A_id013_iter146K.wav shape: (26880,)\n",
      "Epoch[147]: Input data sampled from 128 A and 128 B audio files: train_data_A (458, 24, 128) train_data_B (458, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter147K.wav shape: (41920,)_loss: 4.39626980\n",
      "saved file at ./samples/recon_A2A_id014_iter147K.wav shape: (41920,)\n",
      "Epoch[148]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter148K.wav shape: (83200,)_loss: 4.22898102\n",
      "saved file at ./samples/recon_A2A_id015_iter148K.wav shape: (83200,)\n",
      "Epoch[149]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter149K.wav shape: (150400,)loss: 4.419451243\n",
      "saved file at ./samples/recon_A2A_id016_iter149K.wav shape: (150400,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[150]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter150K.wav shape: (78720,)_loss: 4.63348770\n",
      "saved file at ./samples/recon_A2A_id017_iter150K.wav shape: (78720,)\n",
      "Epoch[151]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter151K.wav shape: (303360,)loss: 4.49332619\n",
      "saved file at ./samples/recon_A2A_id018_iter151K.wav shape: (303360,)\n",
      "Epoch[152]: Input data sampled from 128 A and 128 B audio files: train_data_A (460, 24, 128) train_data_B (460, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter152K.wav shape: (29120,)_loss: 4.24010372\n",
      "saved file at ./samples/recon_A2A_id000_iter152K.wav shape: (29120,)\n",
      "Epoch[153]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter153K.wav shape: (114880,)loss: 4.55308008\n",
      "saved file at ./samples/recon_A2A_id001_iter153K.wav shape: (114880,)\n",
      "Epoch[154]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter154K.wav shape: (49600,)_loss: 4.48319626\n",
      "saved file at ./samples/recon_A2A_id002_iter154K.wav shape: (49600,)\n",
      "Epoch[155]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter155K.wav shape: (35840,)_loss: 4.47124863\n",
      "saved file at ./samples/recon_A2A_id003_iter155K.wav shape: (35840,)\n",
      "Epoch[156]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter156K.wav shape: (60480,)_loss: 4.83209848\n",
      "saved file at ./samples/recon_A2A_id004_iter156K.wav shape: (60480,)\n",
      "Epoch[157]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter157K.wav shape: (39680,)_loss: 4.50314045\n",
      "saved file at ./samples/recon_A2A_id005_iter157K.wav shape: (39680,)\n",
      "Epoch[158]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter158K.wav shape: (98240,)_loss: 4.37963486\n",
      "saved file at ./samples/recon_A2A_id006_iter158K.wav shape: (98240,)\n",
      "Epoch[159]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter159K.wav shape: (32640,)_loss: 4.40952349\n",
      "saved file at ./samples/recon_A2A_id007_iter159K.wav shape: (32640,)\n",
      "Epoch[160]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter160K.wav shape: (56640,)_loss: 4.52665186\n",
      "saved file at ./samples/recon_A2A_id008_iter160K.wav shape: (56640,)\n",
      "Epoch[161]: Input data sampled from 128 A and 128 B audio files: train_data_A (442, 24, 128) train_data_B (442, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter161K.wav shape: (19840,)_loss: 4.44557571\n",
      "saved file at ./samples/recon_A2A_id009_iter161K.wav shape: (19840,)\n",
      "Epoch[162]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter162K.wav shape: (40960,)_loss: 4.36660671\n",
      "saved file at ./samples/recon_A2A_id010_iter162K.wav shape: (40960,)\n",
      "Epoch[163]: Input data sampled from 128 A and 128 B audio files: train_data_A (458, 24, 128) train_data_B (458, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter163K.wav shape: (45760,)_loss: 4.52882099\n",
      "saved file at ./samples/recon_A2A_id011_iter163K.wav shape: (45760,)\n",
      "Epoch[164]: Input data sampled from 128 A and 128 B audio files: train_data_A (438, 24, 128) train_data_B (438, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter164K.wav shape: (80640,)_loss: 4.35617828\n",
      "saved file at ./samples/recon_A2A_id012_iter164K.wav shape: (80640,)\n",
      "Epoch[165]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter165K.wav shape: (26880,)_loss: 4.16691113\n",
      "saved file at ./samples/recon_A2A_id013_iter165K.wav shape: (26880,)\n",
      "Epoch[166]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter166K.wav shape: (41920,)_loss: 4.34554386\n",
      "saved file at ./samples/recon_A2A_id014_iter166K.wav shape: (41920,)\n",
      "Epoch[167]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter167K.wav shape: (83200,)_loss: 4.22945261\n",
      "saved file at ./samples/recon_A2A_id015_iter167K.wav shape: (83200,)\n",
      "Epoch[168]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter168K.wav shape: (150400,)loss: 4.27538919\n",
      "saved file at ./samples/recon_A2A_id016_iter168K.wav shape: (150400,)\n",
      "Epoch[169]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter169K.wav shape: (78720,)_loss: 4.38239002\n",
      "saved file at ./samples/recon_A2A_id017_iter169K.wav shape: (78720,)\n",
      "Epoch[170]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter170K.wav shape: (303360,)loss: 4.74943924\n",
      "saved file at ./samples/recon_A2A_id018_iter170K.wav shape: (303360,)\n",
      "Epoch[171]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter171K.wav shape: (29120,)_loss: 4.24591017\n",
      "saved file at ./samples/recon_A2A_id000_iter171K.wav shape: (29120,)\n",
      "Epoch[172]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter172K.wav shape: (114880,)loss: 4.41918755\n",
      "saved file at ./samples/recon_A2A_id001_iter172K.wav shape: (114880,)\n",
      "Epoch[173]: Input data sampled from 128 A and 128 B audio files: train_data_A (442, 24, 128) train_data_B (442, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter173K.wav shape: (49600,)_loss: 4.38729477\n",
      "saved file at ./samples/recon_A2A_id002_iter173K.wav shape: (49600,)\n",
      "Epoch[174]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter174K.wav shape: (35840,)_loss: 4.30385494\n",
      "saved file at ./samples/recon_A2A_id003_iter174K.wav shape: (35840,)\n",
      "Epoch[175]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter175K.wav shape: (60480,)_loss: 4.41710091\n",
      "saved file at ./samples/recon_A2A_id004_iter175K.wav shape: (60480,)\n",
      "Epoch[176]: Input data sampled from 128 A and 128 B audio files: train_data_A (456, 24, 128) train_data_B (456, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter176K.wav shape: (39680,)_loss: 4.17000198\n",
      "saved file at ./samples/recon_A2A_id005_iter176K.wav shape: (39680,)\n",
      "Epoch[177]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter177K.wav shape: (98240,)_loss: 4.37338734\n",
      "saved file at ./samples/recon_A2A_id006_iter177K.wav shape: (98240,)\n",
      "Epoch[178]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter178K.wav shape: (32640,)_loss: 4.41160297\n",
      "saved file at ./samples/recon_A2A_id007_iter178K.wav shape: (32640,)\n",
      "Epoch[179]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter179K.wav shape: (56640,)_loss: 4.30033636\n",
      "saved file at ./samples/recon_A2A_id008_iter179K.wav shape: (56640,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[180]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter180K.wav shape: (19840,)_loss: 4.05309391\n",
      "saved file at ./samples/recon_A2A_id009_iter180K.wav shape: (19840,)\n",
      "Epoch[181]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter181K.wav shape: (40960,)_loss: 4.17257023\n",
      "saved file at ./samples/recon_A2A_id010_iter181K.wav shape: (40960,)\n",
      "Epoch[182]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter182K.wav shape: (45760,)_loss: 4.34066725\n",
      "saved file at ./samples/recon_A2A_id011_iter182K.wav shape: (45760,)\n",
      "Epoch[183]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter183K.wav shape: (80640,)_loss: 4.28607988\n",
      "saved file at ./samples/recon_A2A_id012_iter183K.wav shape: (80640,)\n",
      "Epoch[184]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter184K.wav shape: (26880,)_loss: 4.17432594\n",
      "saved file at ./samples/recon_A2A_id013_iter184K.wav shape: (26880,)\n",
      "Epoch[185]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter185K.wav shape: (41920,)_loss: 4.25363445\n",
      "saved file at ./samples/recon_A2A_id014_iter185K.wav shape: (41920,)\n",
      "Epoch[186]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter186K.wav shape: (83200,)_loss: 4.26299524\n",
      "saved file at ./samples/recon_A2A_id015_iter186K.wav shape: (83200,)\n",
      "Epoch[187]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter187K.wav shape: (150400,)loss: 4.03555489\n",
      "saved file at ./samples/recon_A2A_id016_iter187K.wav shape: (150400,)\n",
      "Epoch[188]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter188K.wav shape: (78720,)_loss: 4.08610821\n",
      "saved file at ./samples/recon_A2A_id017_iter188K.wav shape: (78720,)\n",
      "Epoch[189]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter189K.wav shape: (303360,)loss: 4.27284622\n",
      "saved file at ./samples/recon_A2A_id018_iter189K.wav shape: (303360,)\n",
      "Epoch[190]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter190K.wav shape: (29120,)_loss: 4.28495169\n",
      "saved file at ./samples/recon_A2A_id000_iter190K.wav shape: (29120,)\n",
      "Epoch[191]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter191K.wav shape: (114880,)loss: 4.05996275\n",
      "saved file at ./samples/recon_A2A_id001_iter191K.wav shape: (114880,)\n",
      "Epoch[192]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter192K.wav shape: (49600,)_loss: 4.21674824\n",
      "saved file at ./samples/recon_A2A_id002_iter192K.wav shape: (49600,)\n",
      "Epoch[193]: Input data sampled from 128 A and 128 B audio files: train_data_A (460, 24, 128) train_data_B (460, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter193K.wav shape: (35840,)_loss: 4.22380781\n",
      "saved file at ./samples/recon_A2A_id003_iter193K.wav shape: (35840,)\n",
      "Epoch[194]: Input data sampled from 128 A and 128 B audio files: train_data_A (440, 24, 128) train_data_B (440, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter194K.wav shape: (60480,)_loss: 4.35707760\n",
      "saved file at ./samples/recon_A2A_id004_iter194K.wav shape: (60480,)\n",
      "Epoch[195]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter195K.wav shape: (39680,)_loss: 4.17957735\n",
      "saved file at ./samples/recon_A2A_id005_iter195K.wav shape: (39680,)\n",
      "Epoch[196]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter196K.wav shape: (98240,)_loss: 4.15568256\n",
      "saved file at ./samples/recon_A2A_id006_iter196K.wav shape: (98240,)\n",
      "Epoch[197]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter197K.wav shape: (32640,)_loss: 4.17198563\n",
      "saved file at ./samples/recon_A2A_id007_iter197K.wav shape: (32640,)\n",
      "Epoch[198]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter198K.wav shape: (56640,)_loss: 4.07885504\n",
      "saved file at ./samples/recon_A2A_id008_iter198K.wav shape: (56640,)\n",
      "Epoch[199]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter199K.wav shape: (19840,)_loss: 4.23172903\n",
      "saved file at ./samples/recon_A2A_id009_iter199K.wav shape: (19840,)\n",
      "Epoch[200]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter200K.wav shape: (40960,)_loss: 3.89289427\n",
      "saved file at ./samples/recon_A2A_id010_iter200K.wav shape: (40960,)\n",
      "Epoch[201]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter201K.wav shape: (45760,)_loss: 3.96538830\n",
      "saved file at ./samples/recon_A2A_id011_iter201K.wav shape: (45760,)\n",
      "Epoch[202]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter202K.wav shape: (80640,)_loss: 4.15008354\n",
      "saved file at ./samples/recon_A2A_id012_iter202K.wav shape: (80640,)\n",
      "Epoch[203]: Input data sampled from 128 A and 128 B audio files: train_data_A (440, 24, 128) train_data_B (440, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter203K.wav shape: (26880,)_loss: 4.02241898\n",
      "saved file at ./samples/recon_A2A_id013_iter203K.wav shape: (26880,)\n",
      "Epoch[204]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter204K.wav shape: (41920,)_loss: 4.19768906\n",
      "saved file at ./samples/recon_A2A_id014_iter204K.wav shape: (41920,)\n",
      "Epoch[205]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter205K.wav shape: (83200,)_loss: 4.10446930\n",
      "saved file at ./samples/recon_A2A_id015_iter205K.wav shape: (83200,)\n",
      "Epoch[206]: Input data sampled from 128 A and 128 B audio files: train_data_A (461, 24, 128) train_data_B (461, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter206K.wav shape: (150400,)loss: 4.08950377\n",
      "saved file at ./samples/recon_A2A_id016_iter206K.wav shape: (150400,)\n",
      "Epoch[207]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter207K.wav shape: (78720,)_loss: 4.15868187\n",
      "saved file at ./samples/recon_A2A_id017_iter207K.wav shape: (78720,)\n",
      "Epoch[208]: Input data sampled from 128 A and 128 B audio files: train_data_A (442, 24, 128) train_data_B (442, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter208K.wav shape: (303360,)loss: 4.11585236\n",
      "saved file at ./samples/recon_A2A_id018_iter208K.wav shape: (303360,)\n",
      "Epoch[209]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter209K.wav shape: (29120,)_loss: 3.97915959\n",
      "saved file at ./samples/recon_A2A_id000_iter209K.wav shape: (29120,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[210]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter210K.wav shape: (114880,)loss: 4.18228292\n",
      "saved file at ./samples/recon_A2A_id001_iter210K.wav shape: (114880,)\n",
      "Epoch[211]: Input data sampled from 128 A and 128 B audio files: train_data_A (458, 24, 128) train_data_B (458, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter211K.wav shape: (49600,)_loss: 4.03309536\n",
      "saved file at ./samples/recon_A2A_id002_iter211K.wav shape: (49600,)\n",
      "Epoch[212]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter212K.wav shape: (35840,)_loss: 4.19563484\n",
      "saved file at ./samples/recon_A2A_id003_iter212K.wav shape: (35840,)\n",
      "Epoch[213]: Input data sampled from 128 A and 128 B audio files: train_data_A (442, 24, 128) train_data_B (442, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter213K.wav shape: (60480,)_loss: 4.03758144\n",
      "saved file at ./samples/recon_A2A_id004_iter213K.wav shape: (60480,)\n",
      "Epoch[214]: Input data sampled from 128 A and 128 B audio files: train_data_A (441, 24, 128) train_data_B (441, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter214K.wav shape: (39680,)_loss: 4.05620432\n",
      "saved file at ./samples/recon_A2A_id005_iter214K.wav shape: (39680,)\n",
      "Epoch[215]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter215K.wav shape: (98240,)_loss: 4.13357401\n",
      "saved file at ./samples/recon_A2A_id006_iter215K.wav shape: (98240,)\n",
      "Epoch[216]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter216K.wav shape: (32640,)_loss: 4.15235138\n",
      "saved file at ./samples/recon_A2A_id007_iter216K.wav shape: (32640,)\n",
      "Epoch[217]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter217K.wav shape: (56640,)_loss: 4.14762259\n",
      "saved file at ./samples/recon_A2A_id008_iter217K.wav shape: (56640,)\n",
      "Epoch[218]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter218K.wav shape: (19840,)_loss: 4.07936573\n",
      "saved file at ./samples/recon_A2A_id009_iter218K.wav shape: (19840,)\n",
      "Epoch[219]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter219K.wav shape: (40960,)_loss: 4.18065357\n",
      "saved file at ./samples/recon_A2A_id010_iter219K.wav shape: (40960,)\n",
      "Epoch[220]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter220K.wav shape: (45760,)_loss: 4.33203363\n",
      "saved file at ./samples/recon_A2A_id011_iter220K.wav shape: (45760,)\n",
      "Epoch[221]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter221K.wav shape: (80640,)_loss: 4.19279528\n",
      "saved file at ./samples/recon_A2A_id012_iter221K.wav shape: (80640,)\n",
      "Epoch[222]: Input data sampled from 128 A and 128 B audio files: train_data_A (440, 24, 128) train_data_B (440, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter222K.wav shape: (26880,)_loss: 4.33021402\n",
      "saved file at ./samples/recon_A2A_id013_iter222K.wav shape: (26880,)\n",
      "Epoch[223]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter223K.wav shape: (41920,)_loss: 3.98867178\n",
      "saved file at ./samples/recon_A2A_id014_iter223K.wav shape: (41920,)\n",
      "Epoch[224]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter224K.wav shape: (83200,)_loss: 3.97058678\n",
      "saved file at ./samples/recon_A2A_id015_iter224K.wav shape: (83200,)\n",
      "Epoch[225]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter225K.wav shape: (150400,)loss: 4.23971176\n",
      "saved file at ./samples/recon_A2A_id016_iter225K.wav shape: (150400,)\n",
      "Epoch[226]: Input data sampled from 128 A and 128 B audio files: train_data_A (440, 24, 128) train_data_B (440, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter226K.wav shape: (78720,)_loss: 4.03783798\n",
      "saved file at ./samples/recon_A2A_id017_iter226K.wav shape: (78720,)\n",
      "Epoch[227]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter227K.wav shape: (303360,)loss: 4.07959652\n",
      "saved file at ./samples/recon_A2A_id018_iter227K.wav shape: (303360,)\n",
      "Epoch[228]: Input data sampled from 128 A and 128 B audio files: train_data_A (456, 24, 128) train_data_B (456, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter228K.wav shape: (29120,)_loss: 3.98326039\n",
      "saved file at ./samples/recon_A2A_id000_iter228K.wav shape: (29120,)\n",
      "Epoch[229]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter229K.wav shape: (114880,)loss: 3.86319304\n",
      "saved file at ./samples/recon_A2A_id001_iter229K.wav shape: (114880,)\n",
      "Epoch[230]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter230K.wav shape: (49600,)_loss: 3.93047357\n",
      "saved file at ./samples/recon_A2A_id002_iter230K.wav shape: (49600,)\n",
      "Epoch[231]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter231K.wav shape: (35840,)_loss: 4.03338814\n",
      "saved file at ./samples/recon_A2A_id003_iter231K.wav shape: (35840,)\n",
      "Epoch[232]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter232K.wav shape: (60480,)_loss: 3.84789896\n",
      "saved file at ./samples/recon_A2A_id004_iter232K.wav shape: (60480,)\n",
      "Epoch[233]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter233K.wav shape: (39680,)_loss: 4.10957909\n",
      "saved file at ./samples/recon_A2A_id005_iter233K.wav shape: (39680,)\n",
      "Epoch[234]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter234K.wav shape: (98240,)_loss: 4.03416729\n",
      "saved file at ./samples/recon_A2A_id006_iter234K.wav shape: (98240,)\n",
      "Epoch[235]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter235K.wav shape: (32640,)_loss: 3.93404293\n",
      "saved file at ./samples/recon_A2A_id007_iter235K.wav shape: (32640,)\n",
      "Epoch[236]: Input data sampled from 128 A and 128 B audio files: train_data_A (438, 24, 128) train_data_B (438, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter236K.wav shape: (56640,)_loss: 4.23669672\n",
      "saved file at ./samples/recon_A2A_id008_iter236K.wav shape: (56640,)\n",
      "Epoch[237]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter237K.wav shape: (19840,)_loss: 4.00654650\n",
      "saved file at ./samples/recon_A2A_id009_iter237K.wav shape: (19840,)\n",
      "Epoch[238]: Input data sampled from 128 A and 128 B audio files: train_data_A (460, 24, 128) train_data_B (460, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter238K.wav shape: (40960,)_loss: 3.98050928\n",
      "saved file at ./samples/recon_A2A_id010_iter238K.wav shape: (40960,)\n",
      "Epoch[239]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter239K.wav shape: (45760,)_loss: 3.93450046\n",
      "saved file at ./samples/recon_A2A_id011_iter239K.wav shape: (45760,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[240]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter240K.wav shape: (80640,)_loss: 4.00778580\n",
      "saved file at ./samples/recon_A2A_id012_iter240K.wav shape: (80640,)\n",
      "Epoch[241]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter241K.wav shape: (26880,)_loss: 3.73577785\n",
      "saved file at ./samples/recon_A2A_id013_iter241K.wav shape: (26880,)\n",
      "Epoch[242]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter242K.wav shape: (41920,)_loss: 3.81028080\n",
      "saved file at ./samples/recon_A2A_id014_iter242K.wav shape: (41920,)\n",
      "Epoch[243]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter243K.wav shape: (83200,)_loss: 3.91869307\n",
      "saved file at ./samples/recon_A2A_id015_iter243K.wav shape: (83200,)\n",
      "Epoch[244]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter244K.wav shape: (150400,)loss: 3.89441371\n",
      "saved file at ./samples/recon_A2A_id016_iter244K.wav shape: (150400,)\n",
      "Epoch[245]: Input data sampled from 128 A and 128 B audio files: train_data_A (438, 24, 128) train_data_B (438, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter245K.wav shape: (78720,)_loss: 3.95998859\n",
      "saved file at ./samples/recon_A2A_id017_iter245K.wav shape: (78720,)\n",
      "Epoch[246]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter246K.wav shape: (303360,)loss: 4.03738785\n",
      "saved file at ./samples/recon_A2A_id018_iter246K.wav shape: (303360,)\n",
      "Epoch[247]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter247K.wav shape: (29120,)_loss: 3.87777567\n",
      "saved file at ./samples/recon_A2A_id000_iter247K.wav shape: (29120,)\n",
      "Epoch[248]: Input data sampled from 128 A and 128 B audio files: train_data_A (458, 24, 128) train_data_B (458, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter248K.wav shape: (114880,)loss: 3.89621997\n",
      "saved file at ./samples/recon_A2A_id001_iter248K.wav shape: (114880,)\n",
      "Epoch[249]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter249K.wav shape: (49600,)_loss: 3.90456963\n",
      "saved file at ./samples/recon_A2A_id002_iter249K.wav shape: (49600,)\n",
      "Epoch[250]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter250K.wav shape: (35840,)_loss: 4.16578102\n",
      "saved file at ./samples/recon_A2A_id003_iter250K.wav shape: (35840,)\n",
      "Epoch[251]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter251K.wav shape: (60480,)_loss: 4.19683790\n",
      "saved file at ./samples/recon_A2A_id004_iter251K.wav shape: (60480,)\n",
      "Epoch[252]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter252K.wav shape: (39680,)_loss: 3.95746040\n",
      "saved file at ./samples/recon_A2A_id005_iter252K.wav shape: (39680,)\n",
      "Epoch[253]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter253K.wav shape: (98240,)_loss: 4.01890516\n",
      "saved file at ./samples/recon_A2A_id006_iter253K.wav shape: (98240,)\n",
      "Epoch[254]: Input data sampled from 128 A and 128 B audio files: train_data_A (457, 24, 128) train_data_B (457, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter254K.wav shape: (32640,)_loss: 3.94709969\n",
      "saved file at ./samples/recon_A2A_id007_iter254K.wav shape: (32640,)\n",
      "Epoch[255]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter255K.wav shape: (56640,)_loss: 4.08068848\n",
      "saved file at ./samples/recon_A2A_id008_iter255K.wav shape: (56640,)\n",
      "Epoch[256]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter256K.wav shape: (19840,)_loss: 3.92101383\n",
      "saved file at ./samples/recon_A2A_id009_iter256K.wav shape: (19840,)\n",
      "Epoch[257]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter257K.wav shape: (40960,)_loss: 3.87583256\n",
      "saved file at ./samples/recon_A2A_id010_iter257K.wav shape: (40960,)\n",
      "Epoch[258]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter258K.wav shape: (45760,)_loss: 3.91998696\n",
      "saved file at ./samples/recon_A2A_id011_iter258K.wav shape: (45760,)\n",
      "Epoch[259]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter259K.wav shape: (80640,)_loss: 3.85334277\n",
      "saved file at ./samples/recon_A2A_id012_iter259K.wav shape: (80640,)\n",
      "Epoch[260]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter260K.wav shape: (26880,)_loss: 3.92548394\n",
      "saved file at ./samples/recon_A2A_id013_iter260K.wav shape: (26880,)\n",
      "Epoch[261]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter261K.wav shape: (41920,)_loss: 3.92842770\n",
      "saved file at ./samples/recon_A2A_id014_iter261K.wav shape: (41920,)\n",
      "Epoch[262]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter262K.wav shape: (83200,)_loss: 3.84395361\n",
      "saved file at ./samples/recon_A2A_id015_iter262K.wav shape: (83200,)\n",
      "Epoch[263]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter263K.wav shape: (150400,)loss: 3.87884426\n",
      "saved file at ./samples/recon_A2A_id016_iter263K.wav shape: (150400,)\n",
      "Epoch[264]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter264K.wav shape: (78720,)_loss: 3.83852696\n",
      "saved file at ./samples/recon_A2A_id017_iter264K.wav shape: (78720,)\n",
      "Epoch[265]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter265K.wav shape: (303360,)loss: 3.93788528\n",
      "saved file at ./samples/recon_A2A_id018_iter265K.wav shape: (303360,)\n",
      "Epoch[266]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter266K.wav shape: (29120,)_loss: 3.86146164\n",
      "saved file at ./samples/recon_A2A_id000_iter266K.wav shape: (29120,)\n",
      "Epoch[267]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter267K.wav shape: (114880,)loss: 3.97787356\n",
      "saved file at ./samples/recon_A2A_id001_iter267K.wav shape: (114880,)\n",
      "Epoch[268]: Input data sampled from 128 A and 128 B audio files: train_data_A (459, 24, 128) train_data_B (459, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter268K.wav shape: (49600,)_loss: 4.05378723\n",
      "saved file at ./samples/recon_A2A_id002_iter268K.wav shape: (49600,)\n",
      "Epoch[269]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter269K.wav shape: (35840,)_loss: 3.76181173\n",
      "saved file at ./samples/recon_A2A_id003_iter269K.wav shape: (35840,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[270]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter270K.wav shape: (60480,)_loss: 3.82585359\n",
      "saved file at ./samples/recon_A2A_id004_iter270K.wav shape: (60480,)\n",
      "Epoch[271]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter271K.wav shape: (39680,)_loss: 3.96801853\n",
      "saved file at ./samples/recon_A2A_id005_iter271K.wav shape: (39680,)\n",
      "Epoch[272]: Input data sampled from 128 A and 128 B audio files: train_data_A (442, 24, 128) train_data_B (442, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter272K.wav shape: (98240,)_loss: 3.80972624\n",
      "saved file at ./samples/recon_A2A_id006_iter272K.wav shape: (98240,)\n",
      "Epoch[273]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter273K.wav shape: (32640,)_loss: 3.85277700\n",
      "saved file at ./samples/recon_A2A_id007_iter273K.wav shape: (32640,)\n",
      "Epoch[274]: Input data sampled from 128 A and 128 B audio files: train_data_A (456, 24, 128) train_data_B (456, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter274K.wav shape: (56640,)_loss: 3.92503738\n",
      "saved file at ./samples/recon_A2A_id008_iter274K.wav shape: (56640,)\n",
      "Epoch[275]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter275K.wav shape: (19840,)_loss: 3.91249752\n",
      "saved file at ./samples/recon_A2A_id009_iter275K.wav shape: (19840,)\n",
      "Epoch[276]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter276K.wav shape: (40960,)_loss: 3.85535932\n",
      "saved file at ./samples/recon_A2A_id010_iter276K.wav shape: (40960,)\n",
      "Epoch[277]: Input data sampled from 128 A and 128 B audio files: train_data_A (441, 24, 128) train_data_B (441, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter277K.wav shape: (45760,)_loss: 4.02089214\n",
      "saved file at ./samples/recon_A2A_id011_iter277K.wav shape: (45760,)\n",
      "Epoch[278]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter278K.wav shape: (80640,)_loss: 3.85651302\n",
      "saved file at ./samples/recon_A2A_id012_iter278K.wav shape: (80640,)\n",
      "Epoch[279]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter279K.wav shape: (26880,)_loss: 4.11010027\n",
      "saved file at ./samples/recon_A2A_id013_iter279K.wav shape: (26880,)\n",
      "Epoch[280]: Input data sampled from 128 A and 128 B audio files: train_data_A (434, 24, 128) train_data_B (434, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter280K.wav shape: (41920,)_loss: 3.81339407\n",
      "saved file at ./samples/recon_A2A_id014_iter280K.wav shape: (41920,)\n",
      "Epoch[281]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter281K.wav shape: (83200,)_loss: 3.81951380\n",
      "saved file at ./samples/recon_A2A_id015_iter281K.wav shape: (83200,)\n",
      "Epoch[282]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter282K.wav shape: (150400,)loss: 3.83819342\n",
      "saved file at ./samples/recon_A2A_id016_iter282K.wav shape: (150400,)\n",
      "Epoch[283]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter283K.wav shape: (78720,)_loss: 3.86440635\n",
      "saved file at ./samples/recon_A2A_id017_iter283K.wav shape: (78720,)\n",
      "Epoch[284]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter284K.wav shape: (303360,)loss: 3.74917412\n",
      "saved file at ./samples/recon_A2A_id018_iter284K.wav shape: (303360,)\n",
      "Epoch[285]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter285K.wav shape: (29120,)_loss: 3.70998240\n",
      "saved file at ./samples/recon_A2A_id000_iter285K.wav shape: (29120,)\n",
      "Epoch[286]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter286K.wav shape: (114880,)loss: 3.75636673\n",
      "saved file at ./samples/recon_A2A_id001_iter286K.wav shape: (114880,)\n",
      "Epoch[287]: Input data sampled from 128 A and 128 B audio files: train_data_A (458, 24, 128) train_data_B (458, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter287K.wav shape: (49600,)_loss: 3.80350828\n",
      "saved file at ./samples/recon_A2A_id002_iter287K.wav shape: (49600,)\n",
      "Epoch[288]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter288K.wav shape: (35840,)_loss: 3.96391463\n",
      "saved file at ./samples/recon_A2A_id003_iter288K.wav shape: (35840,)\n",
      "Epoch[289]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter289K.wav shape: (60480,)_loss: 3.70285964\n",
      "saved file at ./samples/recon_A2A_id004_iter289K.wav shape: (60480,)\n",
      "Epoch[290]: Input data sampled from 128 A and 128 B audio files: train_data_A (435, 24, 128) train_data_B (435, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter290K.wav shape: (39680,)_loss: 3.80911183\n",
      "saved file at ./samples/recon_A2A_id005_iter290K.wav shape: (39680,)\n",
      "Epoch[291]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter291K.wav shape: (98240,)_loss: 3.96780419\n",
      "saved file at ./samples/recon_A2A_id006_iter291K.wav shape: (98240,)\n",
      "Epoch[292]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter292K.wav shape: (32640,)_loss: 3.63597775\n",
      "saved file at ./samples/recon_A2A_id007_iter292K.wav shape: (32640,)\n",
      "Epoch[293]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter293K.wav shape: (56640,)_loss: 3.73023987\n",
      "saved file at ./samples/recon_A2A_id008_iter293K.wav shape: (56640,)\n",
      "Epoch[294]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter294K.wav shape: (19840,)_loss: 3.73507977\n",
      "saved file at ./samples/recon_A2A_id009_iter294K.wav shape: (19840,)\n",
      "Epoch[295]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter295K.wav shape: (40960,)_loss: 3.83056641\n",
      "saved file at ./samples/recon_A2A_id010_iter295K.wav shape: (40960,)\n",
      "Epoch[296]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter296K.wav shape: (45760,)_loss: 3.73299313\n",
      "saved file at ./samples/recon_A2A_id011_iter296K.wav shape: (45760,)\n",
      "Epoch[297]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter297K.wav shape: (80640,)_loss: 3.70642757\n",
      "saved file at ./samples/recon_A2A_id012_iter297K.wav shape: (80640,)\n",
      "Epoch[298]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter298K.wav shape: (26880,)_loss: 3.69783545\n",
      "saved file at ./samples/recon_A2A_id013_iter298K.wav shape: (26880,)\n",
      "Epoch[299]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter299K.wav shape: (41920,)_loss: 3.82486248\n",
      "saved file at ./samples/recon_A2A_id014_iter299K.wav shape: (41920,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[300]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter300K.wav shape: (83200,)_loss: 3.75123119\n",
      "saved file at ./samples/recon_A2A_id015_iter300K.wav shape: (83200,)\n",
      "Epoch[301]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter301K.wav shape: (150400,)loss: 3.65883827\n",
      "saved file at ./samples/recon_A2A_id016_iter301K.wav shape: (150400,)\n",
      "Epoch[302]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter302K.wav shape: (78720,)_loss: 3.75640249\n",
      "saved file at ./samples/recon_A2A_id017_iter302K.wav shape: (78720,)\n",
      "Epoch[303]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter303K.wav shape: (303360,)loss: 3.83663654\n",
      "saved file at ./samples/recon_A2A_id018_iter303K.wav shape: (303360,)\n",
      "Epoch[304]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter304K.wav shape: (29120,)_loss: 3.72708845\n",
      "saved file at ./samples/recon_A2A_id000_iter304K.wav shape: (29120,)\n",
      "Epoch[305]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter305K.wav shape: (114880,)loss: 3.81179786\n",
      "saved file at ./samples/recon_A2A_id001_iter305K.wav shape: (114880,)\n",
      "Epoch[306]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter306K.wav shape: (49600,)_loss: 3.74015784\n",
      "saved file at ./samples/recon_A2A_id002_iter306K.wav shape: (49600,)\n",
      "Epoch[307]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter307K.wav shape: (35840,)_loss: 3.80807257\n",
      "saved file at ./samples/recon_A2A_id003_iter307K.wav shape: (35840,)\n",
      "Epoch[308]: Input data sampled from 128 A and 128 B audio files: train_data_A (459, 24, 128) train_data_B (459, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter308K.wav shape: (60480,)_loss: 3.72224116\n",
      "saved file at ./samples/recon_A2A_id004_iter308K.wav shape: (60480,)\n",
      "Epoch[309]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter309K.wav shape: (39680,)_loss: 3.74264145\n",
      "saved file at ./samples/recon_A2A_id005_iter309K.wav shape: (39680,)\n",
      "Epoch[310]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter310K.wav shape: (98240,)_loss: 3.87648916\n",
      "saved file at ./samples/recon_A2A_id006_iter310K.wav shape: (98240,)\n",
      "Epoch[311]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter311K.wav shape: (32640,)_loss: 3.83118248\n",
      "saved file at ./samples/recon_A2A_id007_iter311K.wav shape: (32640,)\n",
      "Epoch[312]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter312K.wav shape: (56640,)_loss: 3.62884760\n",
      "saved file at ./samples/recon_A2A_id008_iter312K.wav shape: (56640,)\n",
      "Epoch[313]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter313K.wav shape: (19840,)_loss: 3.60388374\n",
      "saved file at ./samples/recon_A2A_id009_iter313K.wav shape: (19840,)\n",
      "Epoch[314]: Input data sampled from 128 A and 128 B audio files: train_data_A (462, 24, 128) train_data_B (462, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter314K.wav shape: (40960,)_loss: 3.70237803\n",
      "saved file at ./samples/recon_A2A_id010_iter314K.wav shape: (40960,)\n",
      "Epoch[315]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter315K.wav shape: (45760,)_loss: 3.67352867\n",
      "saved file at ./samples/recon_A2A_id011_iter315K.wav shape: (45760,)\n",
      "Epoch[316]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter316K.wav shape: (80640,)_loss: 3.69597960\n",
      "saved file at ./samples/recon_A2A_id012_iter316K.wav shape: (80640,)\n",
      "Epoch[317]: Input data sampled from 128 A and 128 B audio files: train_data_A (456, 24, 128) train_data_B (456, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter317K.wav shape: (26880,)_loss: 3.85923457\n",
      "saved file at ./samples/recon_A2A_id013_iter317K.wav shape: (26880,)\n",
      "Epoch[318]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter318K.wav shape: (41920,)_loss: 3.87262964\n",
      "saved file at ./samples/recon_A2A_id014_iter318K.wav shape: (41920,)\n",
      "Epoch[319]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter319K.wav shape: (83200,)_loss: 3.85349798\n",
      "saved file at ./samples/recon_A2A_id015_iter319K.wav shape: (83200,)\n",
      "Epoch[320]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter320K.wav shape: (150400,)loss: 3.66349316\n",
      "saved file at ./samples/recon_A2A_id016_iter320K.wav shape: (150400,)\n",
      "Epoch[321]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter321K.wav shape: (78720,)_loss: 3.76726198\n",
      "saved file at ./samples/recon_A2A_id017_iter321K.wav shape: (78720,)\n",
      "Epoch[322]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter322K.wav shape: (303360,)loss: 3.86788321\n",
      "saved file at ./samples/recon_A2A_id018_iter322K.wav shape: (303360,)\n",
      "Epoch[323]: Input data sampled from 128 A and 128 B audio files: train_data_A (456, 24, 128) train_data_B (456, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter323K.wav shape: (29120,)_loss: 3.62256241\n",
      "saved file at ./samples/recon_A2A_id000_iter323K.wav shape: (29120,)\n",
      "Epoch[324]: Input data sampled from 128 A and 128 B audio files: train_data_A (440, 24, 128) train_data_B (440, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter324K.wav shape: (114880,)loss: 3.70580864\n",
      "saved file at ./samples/recon_A2A_id001_iter324K.wav shape: (114880,)\n",
      "Epoch[325]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter325K.wav shape: (49600,)_loss: 3.71193886\n",
      "saved file at ./samples/recon_A2A_id002_iter325K.wav shape: (49600,)\n",
      "Epoch[326]: Input data sampled from 128 A and 128 B audio files: train_data_A (441, 24, 128) train_data_B (441, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter326K.wav shape: (35840,)_loss: 3.66833210\n",
      "saved file at ./samples/recon_A2A_id003_iter326K.wav shape: (35840,)\n",
      "Epoch[327]: Input data sampled from 128 A and 128 B audio files: train_data_A (456, 24, 128) train_data_B (456, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter327K.wav shape: (60480,)_loss: 3.83889794\n",
      "saved file at ./samples/recon_A2A_id004_iter327K.wav shape: (60480,)\n",
      "Epoch[328]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter328K.wav shape: (39680,)_loss: 3.68614531\n",
      "saved file at ./samples/recon_A2A_id005_iter328K.wav shape: (39680,)\n",
      "Epoch[329]: Input data sampled from 128 A and 128 B audio files: train_data_A (456, 24, 128) train_data_B (456, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter329K.wav shape: (98240,)_loss: 3.69782901\n",
      "saved file at ./samples/recon_A2A_id006_iter329K.wav shape: (98240,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[330]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter330K.wav shape: (32640,)_loss: 3.68313241\n",
      "saved file at ./samples/recon_A2A_id007_iter330K.wav shape: (32640,)\n",
      "Epoch[331]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter331K.wav shape: (56640,)_loss: 3.68741965\n",
      "saved file at ./samples/recon_A2A_id008_iter331K.wav shape: (56640,)\n",
      "Epoch[332]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter332K.wav shape: (19840,)_loss: 3.75717258\n",
      "saved file at ./samples/recon_A2A_id009_iter332K.wav shape: (19840,)\n",
      "Epoch[333]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter333K.wav shape: (40960,)_loss: 3.65389585\n",
      "saved file at ./samples/recon_A2A_id010_iter333K.wav shape: (40960,)\n",
      "Epoch[334]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter334K.wav shape: (45760,)_loss: 3.75321960\n",
      "saved file at ./samples/recon_A2A_id011_iter334K.wav shape: (45760,)\n",
      "Epoch[335]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter335K.wav shape: (80640,)_loss: 3.81146526\n",
      "saved file at ./samples/recon_A2A_id012_iter335K.wav shape: (80640,)\n",
      "Epoch[336]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter336K.wav shape: (26880,)_loss: 3.70744324\n",
      "saved file at ./samples/recon_A2A_id013_iter336K.wav shape: (26880,)\n",
      "Epoch[337]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter337K.wav shape: (41920,)_loss: 3.57049322\n",
      "saved file at ./samples/recon_A2A_id014_iter337K.wav shape: (41920,)\n",
      "Epoch[338]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter338K.wav shape: (83200,)_loss: 3.62962341\n",
      "saved file at ./samples/recon_A2A_id015_iter338K.wav shape: (83200,)\n",
      "Epoch[339]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter339K.wav shape: (150400,)loss: 3.82286692\n",
      "saved file at ./samples/recon_A2A_id016_iter339K.wav shape: (150400,)\n",
      "Epoch[340]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter340K.wav shape: (78720,)_loss: 3.72527838\n",
      "saved file at ./samples/recon_A2A_id017_iter340K.wav shape: (78720,)\n",
      "Epoch[341]: Input data sampled from 128 A and 128 B audio files: train_data_A (440, 24, 128) train_data_B (440, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter341K.wav shape: (303360,)loss: 3.66631746\n",
      "saved file at ./samples/recon_A2A_id018_iter341K.wav shape: (303360,)\n",
      "Epoch[342]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter342K.wav shape: (29120,)_loss: 3.64321494\n",
      "saved file at ./samples/recon_A2A_id000_iter342K.wav shape: (29120,)\n",
      "Epoch[343]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter343K.wav shape: (114880,)loss: 3.84901094\n",
      "saved file at ./samples/recon_A2A_id001_iter343K.wav shape: (114880,)\n",
      "Epoch[344]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter344K.wav shape: (49600,)_loss: 3.67560983\n",
      "saved file at ./samples/recon_A2A_id002_iter344K.wav shape: (49600,)\n",
      "Epoch[345]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter345K.wav shape: (35840,)_loss: 3.57017827\n",
      "saved file at ./samples/recon_A2A_id003_iter345K.wav shape: (35840,)\n",
      "Epoch[346]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter346K.wav shape: (60480,)_loss: 3.75242376\n",
      "saved file at ./samples/recon_A2A_id004_iter346K.wav shape: (60480,)\n",
      "Epoch[347]: Input data sampled from 128 A and 128 B audio files: train_data_A (441, 24, 128) train_data_B (441, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter347K.wav shape: (39680,)_loss: 3.66753554\n",
      "saved file at ./samples/recon_A2A_id005_iter347K.wav shape: (39680,)\n",
      "Epoch[348]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter348K.wav shape: (98240,)_loss: 3.65024710\n",
      "saved file at ./samples/recon_A2A_id006_iter348K.wav shape: (98240,)\n",
      "Epoch[349]: Input data sampled from 128 A and 128 B audio files: train_data_A (457, 24, 128) train_data_B (457, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter349K.wav shape: (32640,)_loss: 3.82272053\n",
      "saved file at ./samples/recon_A2A_id007_iter349K.wav shape: (32640,)\n",
      "Epoch[350]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter350K.wav shape: (56640,)_loss: 3.66818476\n",
      "saved file at ./samples/recon_A2A_id008_iter350K.wav shape: (56640,)\n",
      "Epoch[351]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter351K.wav shape: (19840,)_loss: 3.60121703\n",
      "saved file at ./samples/recon_A2A_id009_iter351K.wav shape: (19840,)\n",
      "Epoch[352]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter352K.wav shape: (40960,)_loss: 3.72309256\n",
      "saved file at ./samples/recon_A2A_id010_iter352K.wav shape: (40960,)\n",
      "Epoch[353]: Input data sampled from 128 A and 128 B audio files: train_data_A (458, 24, 128) train_data_B (458, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter353K.wav shape: (45760,)_loss: 3.73535681\n",
      "saved file at ./samples/recon_A2A_id011_iter353K.wav shape: (45760,)\n",
      "Epoch[354]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter354K.wav shape: (80640,)_loss: 3.72054434\n",
      "saved file at ./samples/recon_A2A_id012_iter354K.wav shape: (80640,)\n",
      "Epoch[355]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter355K.wav shape: (26880,)_loss: 3.69961166\n",
      "saved file at ./samples/recon_A2A_id013_iter355K.wav shape: (26880,)\n",
      "Epoch[356]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter356K.wav shape: (41920,)_loss: 3.71516776\n",
      "saved file at ./samples/recon_A2A_id014_iter356K.wav shape: (41920,)\n",
      "Epoch[357]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter357K.wav shape: (83200,)_loss: 3.64859676\n",
      "saved file at ./samples/recon_A2A_id015_iter357K.wav shape: (83200,)\n",
      "Epoch[358]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter358K.wav shape: (150400,)loss: 3.54228616\n",
      "saved file at ./samples/recon_A2A_id016_iter358K.wav shape: (150400,)\n",
      "Epoch[359]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter359K.wav shape: (78720,)_loss: 3.67016959\n",
      "saved file at ./samples/recon_A2A_id017_iter359K.wav shape: (78720,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[360]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter360K.wav shape: (303360,)loss: 3.60894632\n",
      "saved file at ./samples/recon_A2A_id018_iter360K.wav shape: (303360,)\n",
      "Epoch[361]: Input data sampled from 128 A and 128 B audio files: train_data_A (458, 24, 128) train_data_B (458, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter361K.wav shape: (29120,)_loss: 3.64152670\n",
      "saved file at ./samples/recon_A2A_id000_iter361K.wav shape: (29120,)\n",
      "Epoch[362]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter362K.wav shape: (114880,)loss: 3.57594848\n",
      "saved file at ./samples/recon_A2A_id001_iter362K.wav shape: (114880,)\n",
      "Epoch[363]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter363K.wav shape: (49600,)_loss: 3.66624117\n",
      "saved file at ./samples/recon_A2A_id002_iter363K.wav shape: (49600,)\n",
      "Epoch[364]: Input data sampled from 128 A and 128 B audio files: train_data_A (442, 24, 128) train_data_B (442, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter364K.wav shape: (35840,)_loss: 3.57747960\n",
      "saved file at ./samples/recon_A2A_id003_iter364K.wav shape: (35840,)\n",
      "Epoch[365]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter365K.wav shape: (60480,)_loss: 3.64087343\n",
      "saved file at ./samples/recon_A2A_id004_iter365K.wav shape: (60480,)\n",
      "Epoch[366]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter366K.wav shape: (39680,)_loss: 3.67498446\n",
      "saved file at ./samples/recon_A2A_id005_iter366K.wav shape: (39680,)\n",
      "Epoch[367]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter367K.wav shape: (98240,)_loss: 3.73552942\n",
      "saved file at ./samples/recon_A2A_id006_iter367K.wav shape: (98240,)\n",
      "Epoch[368]: Input data sampled from 128 A and 128 B audio files: train_data_A (459, 24, 128) train_data_B (459, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter368K.wav shape: (32640,)_loss: 3.60812998\n",
      "saved file at ./samples/recon_A2A_id007_iter368K.wav shape: (32640,)\n",
      "Epoch[369]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter369K.wav shape: (56640,)_loss: 3.73667336\n",
      "saved file at ./samples/recon_A2A_id008_iter369K.wav shape: (56640,)\n",
      "Epoch[370]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter370K.wav shape: (19840,)_loss: 3.63733125\n",
      "saved file at ./samples/recon_A2A_id009_iter370K.wav shape: (19840,)\n",
      "Epoch[371]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter371K.wav shape: (40960,)_loss: 3.59067535\n",
      "saved file at ./samples/recon_A2A_id010_iter371K.wav shape: (40960,)\n",
      "Epoch[372]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter372K.wav shape: (45760,)_loss: 4.17054462\n",
      "saved file at ./samples/recon_A2A_id011_iter372K.wav shape: (45760,)\n",
      "Epoch[373]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter373K.wav shape: (80640,)_loss: 3.71257544\n",
      "saved file at ./samples/recon_A2A_id012_iter373K.wav shape: (80640,)\n",
      "Epoch[374]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter374K.wav shape: (26880,)_loss: 3.61630678\n",
      "saved file at ./samples/recon_A2A_id013_iter374K.wav shape: (26880,)\n",
      "Epoch[375]: Input data sampled from 128 A and 128 B audio files: train_data_A (457, 24, 128) train_data_B (457, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter375K.wav shape: (41920,)_loss: 3.59838676\n",
      "saved file at ./samples/recon_A2A_id014_iter375K.wav shape: (41920,)\n",
      "Epoch[376]: Input data sampled from 128 A and 128 B audio files: train_data_A (459, 24, 128) train_data_B (459, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter376K.wav shape: (83200,)_loss: 3.59449863\n",
      "saved file at ./samples/recon_A2A_id015_iter376K.wav shape: (83200,)\n",
      "Epoch[377]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter377K.wav shape: (150400,)loss: 3.55526304\n",
      "saved file at ./samples/recon_A2A_id016_iter377K.wav shape: (150400,)\n",
      "Epoch[378]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter378K.wav shape: (78720,)_loss: 3.62617254\n",
      "saved file at ./samples/recon_A2A_id017_iter378K.wav shape: (78720,)\n",
      "Epoch[379]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter379K.wav shape: (303360,)loss: 3.65806341\n",
      "saved file at ./samples/recon_A2A_id018_iter379K.wav shape: (303360,)\n",
      "Epoch[380]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter380K.wav shape: (29120,)_loss: 3.49369955\n",
      "saved file at ./samples/recon_A2A_id000_iter380K.wav shape: (29120,)\n",
      "Epoch[381]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter381K.wav shape: (114880,)loss: 3.82885385\n",
      "saved file at ./samples/recon_A2A_id001_iter381K.wav shape: (114880,)\n",
      "Epoch[382]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter382K.wav shape: (49600,)_loss: 3.77473879\n",
      "saved file at ./samples/recon_A2A_id002_iter382K.wav shape: (49600,)\n",
      "Epoch[383]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter383K.wav shape: (35840,)_loss: 3.78555012\n",
      "saved file at ./samples/recon_A2A_id003_iter383K.wav shape: (35840,)\n",
      "Epoch[384]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter384K.wav shape: (60480,)_loss: 3.47293615\n",
      "saved file at ./samples/recon_A2A_id004_iter384K.wav shape: (60480,)\n",
      "Epoch[385]: Input data sampled from 128 A and 128 B audio files: train_data_A (460, 24, 128) train_data_B (460, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter385K.wav shape: (39680,)_loss: 3.70532942\n",
      "saved file at ./samples/recon_A2A_id005_iter385K.wav shape: (39680,)\n",
      "Epoch[386]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter386K.wav shape: (98240,)_loss: 3.58130455\n",
      "saved file at ./samples/recon_A2A_id006_iter386K.wav shape: (98240,)\n",
      "Epoch[387]: Input data sampled from 128 A and 128 B audio files: train_data_A (459, 24, 128) train_data_B (459, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter387K.wav shape: (32640,)_loss: 3.68805313\n",
      "saved file at ./samples/recon_A2A_id007_iter387K.wav shape: (32640,)\n",
      "Epoch[388]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter388K.wav shape: (56640,)_loss: 3.59228945\n",
      "saved file at ./samples/recon_A2A_id008_iter388K.wav shape: (56640,)\n",
      "Epoch[389]: Input data sampled from 128 A and 128 B audio files: train_data_A (442, 24, 128) train_data_B (442, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter389K.wav shape: (19840,)_loss: 3.54303503\n",
      "saved file at ./samples/recon_A2A_id009_iter389K.wav shape: (19840,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[390]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter390K.wav shape: (40960,)_loss: 3.61870170\n",
      "saved file at ./samples/recon_A2A_id010_iter390K.wav shape: (40960,)\n",
      "Epoch[391]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter391K.wav shape: (45760,)_loss: 3.56173563\n",
      "saved file at ./samples/recon_A2A_id011_iter391K.wav shape: (45760,)\n",
      "Epoch[392]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter392K.wav shape: (80640,)_loss: 3.52098107\n",
      "saved file at ./samples/recon_A2A_id012_iter392K.wav shape: (80640,)\n",
      "Epoch[393]: Input data sampled from 128 A and 128 B audio files: train_data_A (466, 24, 128) train_data_B (466, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter393K.wav shape: (26880,)_loss: 3.80482888\n",
      "saved file at ./samples/recon_A2A_id013_iter393K.wav shape: (26880,)\n",
      "Epoch[394]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter394K.wav shape: (41920,)_loss: 3.47650433\n",
      "saved file at ./samples/recon_A2A_id014_iter394K.wav shape: (41920,)\n",
      "Epoch[395]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter395K.wav shape: (83200,)_loss: 3.52750921\n",
      "saved file at ./samples/recon_A2A_id015_iter395K.wav shape: (83200,)\n",
      "Epoch[396]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter396K.wav shape: (150400,)loss: 3.63919330\n",
      "saved file at ./samples/recon_A2A_id016_iter396K.wav shape: (150400,)\n",
      "Epoch[397]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter397K.wav shape: (78720,)_loss: 3.71215892\n",
      "saved file at ./samples/recon_A2A_id017_iter397K.wav shape: (78720,)\n",
      "Epoch[398]: Input data sampled from 128 A and 128 B audio files: train_data_A (437, 24, 128) train_data_B (437, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter398K.wav shape: (303360,)loss: 3.60400963\n",
      "saved file at ./samples/recon_A2A_id018_iter398K.wav shape: (303360,)\n",
      "Epoch[399]: Input data sampled from 128 A and 128 B audio files: train_data_A (461, 24, 128) train_data_B (461, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter399K.wav shape: (29120,)_loss: 3.46416140\n",
      "saved file at ./samples/recon_A2A_id000_iter399K.wav shape: (29120,)\n",
      "Epoch[400]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter400K.wav shape: (114880,)loss: 3.63604093\n",
      "saved file at ./samples/recon_A2A_id001_iter400K.wav shape: (114880,)\n",
      "Epoch[401]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter401K.wav shape: (49600,)_loss: 3.50152063\n",
      "saved file at ./samples/recon_A2A_id002_iter401K.wav shape: (49600,)\n",
      "Epoch[402]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter402K.wav shape: (35840,)_loss: 3.49705505\n",
      "saved file at ./samples/recon_A2A_id003_iter402K.wav shape: (35840,)\n",
      "Epoch[403]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter403K.wav shape: (60480,)_loss: 3.56067944\n",
      "saved file at ./samples/recon_A2A_id004_iter403K.wav shape: (60480,)\n",
      "Epoch[404]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter404K.wav shape: (39680,)_loss: 3.57839584\n",
      "saved file at ./samples/recon_A2A_id005_iter404K.wav shape: (39680,)\n",
      "Epoch[405]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter405K.wav shape: (98240,)_loss: 3.54935932\n",
      "saved file at ./samples/recon_A2A_id006_iter405K.wav shape: (98240,)\n",
      "Epoch[406]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter406K.wav shape: (32640,)_loss: 3.56993628\n",
      "saved file at ./samples/recon_A2A_id007_iter406K.wav shape: (32640,)\n",
      "Epoch[407]: Input data sampled from 128 A and 128 B audio files: train_data_A (456, 24, 128) train_data_B (456, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter407K.wav shape: (56640,)_loss: 3.48382568\n",
      "saved file at ./samples/recon_A2A_id008_iter407K.wav shape: (56640,)\n",
      "Epoch[408]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter408K.wav shape: (19840,)_loss: 3.51533389\n",
      "saved file at ./samples/recon_A2A_id009_iter408K.wav shape: (19840,)\n",
      "Epoch[409]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter409K.wav shape: (40960,)_loss: 3.60310745\n",
      "saved file at ./samples/recon_A2A_id010_iter409K.wav shape: (40960,)\n",
      "Epoch[410]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter410K.wav shape: (45760,)_loss: 3.69761753\n",
      "saved file at ./samples/recon_A2A_id011_iter410K.wav shape: (45760,)\n",
      "Epoch[411]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter411K.wav shape: (80640,)_loss: 3.53190255\n",
      "saved file at ./samples/recon_A2A_id012_iter411K.wav shape: (80640,)\n",
      "Epoch[412]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter412K.wav shape: (26880,)_loss: 3.58743954\n",
      "saved file at ./samples/recon_A2A_id013_iter412K.wav shape: (26880,)\n",
      "Epoch[413]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter413K.wav shape: (41920,)_loss: 3.46668816\n",
      "saved file at ./samples/recon_A2A_id014_iter413K.wav shape: (41920,)\n",
      "Epoch[414]: Input data sampled from 128 A and 128 B audio files: train_data_A (457, 24, 128) train_data_B (457, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter414K.wav shape: (83200,)_loss: 3.56843042\n",
      "saved file at ./samples/recon_A2A_id015_iter414K.wav shape: (83200,)\n",
      "Epoch[415]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter415K.wav shape: (150400,)loss: 3.50542259\n",
      "saved file at ./samples/recon_A2A_id016_iter415K.wav shape: (150400,)\n",
      "Epoch[416]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter416K.wav shape: (78720,)_loss: 3.62316704\n",
      "saved file at ./samples/recon_A2A_id017_iter416K.wav shape: (78720,)\n",
      "Epoch[417]: Input data sampled from 128 A and 128 B audio files: train_data_A (457, 24, 128) train_data_B (457, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter417K.wav shape: (303360,)loss: 3.54553199\n",
      "saved file at ./samples/recon_A2A_id018_iter417K.wav shape: (303360,)\n",
      "Epoch[418]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter418K.wav shape: (29120,)_loss: 3.53421998\n",
      "saved file at ./samples/recon_A2A_id000_iter418K.wav shape: (29120,)\n",
      "Epoch[419]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter419K.wav shape: (114880,)loss: 3.74681854\n",
      "saved file at ./samples/recon_A2A_id001_iter419K.wav shape: (114880,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[420]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter420K.wav shape: (49600,)_loss: 3.53173709\n",
      "saved file at ./samples/recon_A2A_id002_iter420K.wav shape: (49600,)\n",
      "Epoch[421]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter421K.wav shape: (35840,)_loss: 3.68037915\n",
      "saved file at ./samples/recon_A2A_id003_iter421K.wav shape: (35840,)\n",
      "Epoch[422]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter422K.wav shape: (60480,)_loss: 3.48433018\n",
      "saved file at ./samples/recon_A2A_id004_iter422K.wav shape: (60480,)\n",
      "Epoch[423]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter423K.wav shape: (39680,)_loss: 3.48093605\n",
      "saved file at ./samples/recon_A2A_id005_iter423K.wav shape: (39680,)\n",
      "Epoch[424]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter424K.wav shape: (98240,)_loss: 3.63483047\n",
      "saved file at ./samples/recon_A2A_id006_iter424K.wav shape: (98240,)\n",
      "Epoch[425]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter425K.wav shape: (32640,)_loss: 3.76537561\n",
      "saved file at ./samples/recon_A2A_id007_iter425K.wav shape: (32640,)\n",
      "Epoch[426]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter426K.wav shape: (56640,)_loss: 3.52041864\n",
      "saved file at ./samples/recon_A2A_id008_iter426K.wav shape: (56640,)\n",
      "Epoch[427]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter427K.wav shape: (19840,)_loss: 3.68546939\n",
      "saved file at ./samples/recon_A2A_id009_iter427K.wav shape: (19840,)\n",
      "Epoch[428]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter428K.wav shape: (40960,)_loss: 3.65586376\n",
      "saved file at ./samples/recon_A2A_id010_iter428K.wav shape: (40960,)\n",
      "Epoch[429]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter429K.wav shape: (45760,)_loss: 3.58151484\n",
      "saved file at ./samples/recon_A2A_id011_iter429K.wav shape: (45760,)\n",
      "Epoch[430]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter430K.wav shape: (80640,)_loss: 3.64229107\n",
      "saved file at ./samples/recon_A2A_id012_iter430K.wav shape: (80640,)\n",
      "Epoch[431]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter431K.wav shape: (26880,)_loss: 3.62490702\n",
      "saved file at ./samples/recon_A2A_id013_iter431K.wav shape: (26880,)\n",
      "Epoch[432]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter432K.wav shape: (41920,)_loss: 3.48961258\n",
      "saved file at ./samples/recon_A2A_id014_iter432K.wav shape: (41920,)\n",
      "Epoch[433]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter433K.wav shape: (83200,)_loss: 3.81187153\n",
      "saved file at ./samples/recon_A2A_id015_iter433K.wav shape: (83200,)\n",
      "Epoch[434]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter434K.wav shape: (150400,)loss: 3.69475293\n",
      "saved file at ./samples/recon_A2A_id016_iter434K.wav shape: (150400,)\n",
      "Epoch[435]: Input data sampled from 128 A and 128 B audio files: train_data_A (456, 24, 128) train_data_B (456, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter435K.wav shape: (78720,)_loss: 3.78667545\n",
      "saved file at ./samples/recon_A2A_id017_iter435K.wav shape: (78720,)\n",
      "Epoch[436]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter436K.wav shape: (303360,)loss: 3.53490520\n",
      "saved file at ./samples/recon_A2A_id018_iter436K.wav shape: (303360,)\n",
      "Epoch[437]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter437K.wav shape: (29120,)_loss: 3.61884403\n",
      "saved file at ./samples/recon_A2A_id000_iter437K.wav shape: (29120,)\n",
      "Epoch[438]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter438K.wav shape: (114880,)loss: 3.62565994\n",
      "saved file at ./samples/recon_A2A_id001_iter438K.wav shape: (114880,)\n",
      "Epoch[439]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter439K.wav shape: (49600,)_loss: 3.63829660\n",
      "saved file at ./samples/recon_A2A_id002_iter439K.wav shape: (49600,)\n",
      "Epoch[440]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter440K.wav shape: (35840,)_loss: 3.51448369\n",
      "saved file at ./samples/recon_A2A_id003_iter440K.wav shape: (35840,)\n",
      "Epoch[441]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter441K.wav shape: (60480,)_loss: 3.69238091\n",
      "saved file at ./samples/recon_A2A_id004_iter441K.wav shape: (60480,)\n",
      "Epoch[442]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter442K.wav shape: (39680,)_loss: 3.47381377\n",
      "saved file at ./samples/recon_A2A_id005_iter442K.wav shape: (39680,)\n",
      "Epoch[443]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter443K.wav shape: (98240,)_loss: 3.59014702\n",
      "saved file at ./samples/recon_A2A_id006_iter443K.wav shape: (98240,)\n",
      "Epoch[444]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter444K.wav shape: (32640,)_loss: 3.70043230\n",
      "saved file at ./samples/recon_A2A_id007_iter444K.wav shape: (32640,)\n",
      "Epoch[445]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter445K.wav shape: (56640,)_loss: 3.640620714\n",
      "saved file at ./samples/recon_A2A_id008_iter445K.wav shape: (56640,)\n",
      "Epoch[446]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter446K.wav shape: (19840,)_loss: 3.47095490\n",
      "saved file at ./samples/recon_A2A_id009_iter446K.wav shape: (19840,)\n",
      "Epoch[447]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter447K.wav shape: (40960,)_loss: 3.44904232\n",
      "saved file at ./samples/recon_A2A_id010_iter447K.wav shape: (40960,)\n",
      "Epoch[448]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter448K.wav shape: (45760,)_loss: 3.57116985\n",
      "saved file at ./samples/recon_A2A_id011_iter448K.wav shape: (45760,)\n",
      "Epoch[449]: Input data sampled from 128 A and 128 B audio files: train_data_A (436, 24, 128) train_data_B (436, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter449K.wav shape: (80640,)_loss: 3.54246855\n",
      "saved file at ./samples/recon_A2A_id012_iter449K.wav shape: (80640,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[450]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter450K.wav shape: (26880,)_loss: 3.53159189\n",
      "saved file at ./samples/recon_A2A_id013_iter450K.wav shape: (26880,)\n",
      "Epoch[451]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter451K.wav shape: (41920,)_loss: 3.60145140\n",
      "saved file at ./samples/recon_A2A_id014_iter451K.wav shape: (41920,)\n",
      "Epoch[452]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter452K.wav shape: (83200,)_loss: 3.52427769\n",
      "saved file at ./samples/recon_A2A_id015_iter452K.wav shape: (83200,)\n",
      "Epoch[453]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter453K.wav shape: (150400,)loss: 3.44579554\n",
      "saved file at ./samples/recon_A2A_id016_iter453K.wav shape: (150400,)\n",
      "Epoch[454]: Input data sampled from 128 A and 128 B audio files: train_data_A (458, 24, 128) train_data_B (458, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter454K.wav shape: (78720,)_loss: 3.66008472\n",
      "saved file at ./samples/recon_A2A_id017_iter454K.wav shape: (78720,)\n",
      "Epoch[455]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter455K.wav shape: (303360,)loss: 3.75057960\n",
      "saved file at ./samples/recon_A2A_id018_iter455K.wav shape: (303360,)\n",
      "Epoch[456]: Input data sampled from 128 A and 128 B audio files: train_data_A (442, 24, 128) train_data_B (442, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter456K.wav shape: (29120,)_loss: 3.44853735\n",
      "saved file at ./samples/recon_A2A_id000_iter456K.wav shape: (29120,)\n",
      "Epoch[457]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter457K.wav shape: (114880,)loss: 3.64775157\n",
      "saved file at ./samples/recon_A2A_id001_iter457K.wav shape: (114880,)\n",
      "Epoch[458]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter458K.wav shape: (49600,)_loss: 3.49090695\n",
      "saved file at ./samples/recon_A2A_id002_iter458K.wav shape: (49600,)\n",
      "Epoch[459]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter459K.wav shape: (35840,)_loss: 3.50139809\n",
      "saved file at ./samples/recon_A2A_id003_iter459K.wav shape: (35840,)\n",
      "Epoch[460]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter460K.wav shape: (60480,)_loss: 3.48634911\n",
      "saved file at ./samples/recon_A2A_id004_iter460K.wav shape: (60480,)\n",
      "Epoch[461]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter461K.wav shape: (39680,)_loss: 3.58858395\n",
      "saved file at ./samples/recon_A2A_id005_iter461K.wav shape: (39680,)\n",
      "Epoch[462]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter462K.wav shape: (98240,)_loss: 3.53940582\n",
      "saved file at ./samples/recon_A2A_id006_iter462K.wav shape: (98240,)\n",
      "Epoch[463]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter463K.wav shape: (32640,)_loss: 3.54823279\n",
      "saved file at ./samples/recon_A2A_id007_iter463K.wav shape: (32640,)\n",
      "Epoch[464]: Input data sampled from 128 A and 128 B audio files: train_data_A (442, 24, 128) train_data_B (442, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter464K.wav shape: (56640,)_loss: 3.57721281\n",
      "saved file at ./samples/recon_A2A_id008_iter464K.wav shape: (56640,)\n",
      "Epoch[465]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter465K.wav shape: (19840,)_loss: 3.54002929\n",
      "saved file at ./samples/recon_A2A_id009_iter465K.wav shape: (19840,)\n",
      "Epoch[466]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter466K.wav shape: (40960,)_loss: 3.40496063\n",
      "saved file at ./samples/recon_A2A_id010_iter466K.wav shape: (40960,)\n",
      "Epoch[467]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter467K.wav shape: (45760,)_loss: 3.44462419\n",
      "saved file at ./samples/recon_A2A_id011_iter467K.wav shape: (45760,)\n",
      "Epoch[468]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter468K.wav shape: (80640,)_loss: 3.53060961\n",
      "saved file at ./samples/recon_A2A_id012_iter468K.wav shape: (80640,)\n",
      "Epoch[469]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter469K.wav shape: (26880,)_loss: 3.45132756\n",
      "saved file at ./samples/recon_A2A_id013_iter469K.wav shape: (26880,)\n",
      "Epoch[470]: Input data sampled from 128 A and 128 B audio files: train_data_A (459, 24, 128) train_data_B (459, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter470K.wav shape: (41920,)_loss: 3.51402116\n",
      "saved file at ./samples/recon_A2A_id014_iter470K.wav shape: (41920,)\n",
      "Epoch[471]: Input data sampled from 128 A and 128 B audio files: train_data_A (441, 24, 128) train_data_B (441, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter471K.wav shape: (83200,)_loss: 3.44576359\n",
      "saved file at ./samples/recon_A2A_id015_iter471K.wav shape: (83200,)\n",
      "Epoch[472]: Input data sampled from 128 A and 128 B audio files: train_data_A (437, 24, 128) train_data_B (437, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter472K.wav shape: (150400,)loss: 3.54770565\n",
      "saved file at ./samples/recon_A2A_id016_iter472K.wav shape: (150400,)\n",
      "Epoch[473]: Input data sampled from 128 A and 128 B audio files: train_data_A (459, 24, 128) train_data_B (459, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter473K.wav shape: (78720,)_loss: 3.51082945\n",
      "saved file at ./samples/recon_A2A_id017_iter473K.wav shape: (78720,)\n",
      "Epoch[474]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter474K.wav shape: (303360,)loss: 3.49712801\n",
      "saved file at ./samples/recon_A2A_id018_iter474K.wav shape: (303360,)\n",
      "Epoch[475]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter475K.wav shape: (29120,)_loss: 3.55040121\n",
      "saved file at ./samples/recon_A2A_id000_iter475K.wav shape: (29120,)\n",
      "Epoch[476]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter476K.wav shape: (114880,)loss: 3.44081593\n",
      "saved file at ./samples/recon_A2A_id001_iter476K.wav shape: (114880,)\n",
      "Epoch[477]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter477K.wav shape: (49600,)_loss: 3.42405081\n",
      "saved file at ./samples/recon_A2A_id002_iter477K.wav shape: (49600,)\n",
      "Epoch[478]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter478K.wav shape: (35840,)_loss: 3.42423368\n",
      "saved file at ./samples/recon_A2A_id003_iter478K.wav shape: (35840,)\n",
      "Epoch[479]: Input data sampled from 128 A and 128 B audio files: train_data_A (439, 24, 128) train_data_B (439, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter479K.wav shape: (60480,)_loss: 3.38574743\n",
      "saved file at ./samples/recon_A2A_id004_iter479K.wav shape: (60480,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[480]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter480K.wav shape: (39680,)_loss: 3.56225586\n",
      "saved file at ./samples/recon_A2A_id005_iter480K.wav shape: (39680,)\n",
      "Epoch[481]: Input data sampled from 128 A and 128 B audio files: train_data_A (456, 24, 128) train_data_B (456, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter481K.wav shape: (98240,)_loss: 3.51054096\n",
      "saved file at ./samples/recon_A2A_id006_iter481K.wav shape: (98240,)\n",
      "Epoch[482]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter482K.wav shape: (32640,)_loss: 3.58289528\n",
      "saved file at ./samples/recon_A2A_id007_iter482K.wav shape: (32640,)\n",
      "Epoch[483]: Input data sampled from 128 A and 128 B audio files: train_data_A (457, 24, 128) train_data_B (457, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter483K.wav shape: (56640,)_loss: 3.43773127\n",
      "saved file at ./samples/recon_A2A_id008_iter483K.wav shape: (56640,)\n",
      "Epoch[484]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter484K.wav shape: (19840,)_loss: 3.35650778\n",
      "saved file at ./samples/recon_A2A_id009_iter484K.wav shape: (19840,)\n",
      "Epoch[485]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter485K.wav shape: (40960,)_loss: 3.41424274\n",
      "saved file at ./samples/recon_A2A_id010_iter485K.wav shape: (40960,)\n",
      "Epoch[486]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter486K.wav shape: (45760,)_loss: 3.48855662\n",
      "saved file at ./samples/recon_A2A_id011_iter486K.wav shape: (45760,)\n",
      "Epoch[487]: Input data sampled from 128 A and 128 B audio files: train_data_A (441, 24, 128) train_data_B (441, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter487K.wav shape: (80640,)_loss: 3.47964191\n",
      "saved file at ./samples/recon_A2A_id012_iter487K.wav shape: (80640,)\n",
      "Epoch[488]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter488K.wav shape: (26880,)_loss: 3.47702551\n",
      "saved file at ./samples/recon_A2A_id013_iter488K.wav shape: (26880,)\n",
      "Epoch[489]: Input data sampled from 128 A and 128 B audio files: train_data_A (438, 24, 128) train_data_B (438, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter489K.wav shape: (41920,)_loss: 3.54220295\n",
      "saved file at ./samples/recon_A2A_id014_iter489K.wav shape: (41920,)\n",
      "Epoch[490]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter490K.wav shape: (83200,)_loss: 3.49991226\n",
      "saved file at ./samples/recon_A2A_id015_iter490K.wav shape: (83200,)\n",
      "Epoch[491]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter491K.wav shape: (150400,)loss: 3.39245987\n",
      "saved file at ./samples/recon_A2A_id016_iter491K.wav shape: (150400,)\n",
      "Epoch[492]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter492K.wav shape: (78720,)g_loss: 3.51832652\n",
      "saved file at ./samples/recon_A2A_id017_iter492K.wav shape: (78720,)\n",
      "Epoch[493]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter493K.wav shape: (303360,)_loss: 3.46834803\n",
      "saved file at ./samples/recon_A2A_id018_iter493K.wav shape: (303360,)\n",
      "Epoch[494]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter494K.wav shape: (29120,)g_loss: 3.33430314\n",
      "saved file at ./samples/recon_A2A_id000_iter494K.wav shape: (29120,)\n",
      "Epoch[495]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter495K.wav shape: (114880,)_loss: 3.47035170\n",
      "saved file at ./samples/recon_A2A_id001_iter495K.wav shape: (114880,)\n",
      "Epoch[496]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter496K.wav shape: (49600,)g_loss: 3.38140440\n",
      "saved file at ./samples/recon_A2A_id002_iter496K.wav shape: (49600,)\n",
      "Epoch[497]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter497K.wav shape: (35840,)g_loss: 3.37417459\n",
      "saved file at ./samples/recon_A2A_id003_iter497K.wav shape: (35840,)\n",
      "Epoch[498]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter498K.wav shape: (60480,)g_loss: 3.61420584\n",
      "saved file at ./samples/recon_A2A_id004_iter498K.wav shape: (60480,)\n",
      "Epoch[499]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter499K.wav shape: (39680,)g_loss: 3.42724752\n",
      "saved file at ./samples/recon_A2A_id005_iter499K.wav shape: (39680,)\n",
      "Epoch[500]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter500K.wav shape: (98240,)g_loss: 3.50621748\n",
      "saved file at ./samples/recon_A2A_id006_iter500K.wav shape: (98240,)\n",
      "Epoch[501]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter501K.wav shape: (32640,)g_loss: 3.46875429\n",
      "saved file at ./samples/recon_A2A_id007_iter501K.wav shape: (32640,)\n",
      "Epoch[502]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter502K.wav shape: (56640,)g_loss: 3.45195150\n",
      "saved file at ./samples/recon_A2A_id008_iter502K.wav shape: (56640,)\n",
      "Epoch[503]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter503K.wav shape: (19840,)g_loss: 3.44412279\n",
      "saved file at ./samples/recon_A2A_id009_iter503K.wav shape: (19840,)\n",
      "Epoch[504]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter504K.wav shape: (40960,)g_loss: 3.39513183\n",
      "saved file at ./samples/recon_A2A_id010_iter504K.wav shape: (40960,)\n",
      "Epoch[505]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter505K.wav shape: (45760,)g_loss: 3.42922902\n",
      "saved file at ./samples/recon_A2A_id011_iter505K.wav shape: (45760,)\n",
      "Epoch[506]: Input data sampled from 128 A and 128 B audio files: train_data_A (456, 24, 128) train_data_B (456, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter506K.wav shape: (80640,)g_loss: 3.50860739\n",
      "saved file at ./samples/recon_A2A_id012_iter506K.wav shape: (80640,)\n",
      "Epoch[507]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter507K.wav shape: (26880,)g_loss: 3.46832848\n",
      "saved file at ./samples/recon_A2A_id013_iter507K.wav shape: (26880,)\n",
      "Epoch[508]: Input data sampled from 128 A and 128 B audio files: train_data_A (441, 24, 128) train_data_B (441, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter508K.wav shape: (41920,)g_loss: 3.59417343\n",
      "saved file at ./samples/recon_A2A_id014_iter508K.wav shape: (41920,)\n",
      "Epoch[509]: Input data sampled from 128 A and 128 B audio files: train_data_A (458, 24, 128) train_data_B (458, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter509K.wav shape: (83200,)g_loss: 3.35282683\n",
      "saved file at ./samples/recon_A2A_id015_iter509K.wav shape: (83200,)\n",
      "Epoch[510]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter510K.wav shape: (150400,)_loss: 3.46369648\n",
      "saved file at ./samples/recon_A2A_id016_iter510K.wav shape: (150400,)\n",
      "Epoch[511]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter511K.wav shape: (78720,)g_loss: 3.44702458\n",
      "saved file at ./samples/recon_A2A_id017_iter511K.wav shape: (78720,)\n",
      "Epoch[512]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter512K.wav shape: (303360,)_loss: 3.39562464\n",
      "saved file at ./samples/recon_A2A_id018_iter512K.wav shape: (303360,)\n",
      "Epoch[513]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter513K.wav shape: (29120,)g_loss: 3.46753049\n",
      "saved file at ./samples/recon_A2A_id000_iter513K.wav shape: (29120,)\n",
      "Epoch[514]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter514K.wav shape: (114880,)_loss: 3.47573256\n",
      "saved file at ./samples/recon_A2A_id001_iter514K.wav shape: (114880,)\n",
      "Epoch[515]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter515K.wav shape: (49600,)g_loss: 3.50881505\n",
      "saved file at ./samples/recon_A2A_id002_iter515K.wav shape: (49600,)\n",
      "Epoch[516]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter516K.wav shape: (35840,)g_loss: 3.50965023\n",
      "saved file at ./samples/recon_A2A_id003_iter516K.wav shape: (35840,)\n",
      "Epoch[517]: Input data sampled from 128 A and 128 B audio files: train_data_A (459, 24, 128) train_data_B (459, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter517K.wav shape: (60480,)g_loss: 3.35192156\n",
      "saved file at ./samples/recon_A2A_id004_iter517K.wav shape: (60480,)\n",
      "Epoch[518]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter518K.wav shape: (39680,)g_loss: 3.32257843\n",
      "saved file at ./samples/recon_A2A_id005_iter518K.wav shape: (39680,)\n",
      "Epoch[519]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter519K.wav shape: (98240,)g_loss: 3.47964835\n",
      "saved file at ./samples/recon_A2A_id006_iter519K.wav shape: (98240,)\n",
      "Epoch[520]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter520K.wav shape: (32640,)g_loss: 3.51924467\n",
      "saved file at ./samples/recon_A2A_id007_iter520K.wav shape: (32640,)\n",
      "Epoch[521]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter521K.wav shape: (56640,)g_loss: 3.36373138\n",
      "saved file at ./samples/recon_A2A_id008_iter521K.wav shape: (56640,)\n",
      "Epoch[522]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter522K.wav shape: (19840,)g_loss: 3.35095215\n",
      "saved file at ./samples/recon_A2A_id009_iter522K.wav shape: (19840,)\n",
      "Epoch[523]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter523K.wav shape: (40960,)g_loss: 3.52543879\n",
      "saved file at ./samples/recon_A2A_id010_iter523K.wav shape: (40960,)\n",
      "Epoch[524]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter524K.wav shape: (45760,)g_loss: 3.51469994\n",
      "saved file at ./samples/recon_A2A_id011_iter524K.wav shape: (45760,)\n",
      "Epoch[525]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter525K.wav shape: (80640,)g_loss: 3.37370586\n",
      "saved file at ./samples/recon_A2A_id012_iter525K.wav shape: (80640,)\n",
      "Epoch[526]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter526K.wav shape: (26880,)g_loss: 3.53331280\n",
      "saved file at ./samples/recon_A2A_id013_iter526K.wav shape: (26880,)\n",
      "Epoch[527]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter527K.wav shape: (41920,)g_loss: 3.53020382\n",
      "saved file at ./samples/recon_A2A_id014_iter527K.wav shape: (41920,)\n",
      "Epoch[528]: Input data sampled from 128 A and 128 B audio files: train_data_A (458, 24, 128) train_data_B (458, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter528K.wav shape: (83200,)g_loss: 3.49903154\n",
      "saved file at ./samples/recon_A2A_id015_iter528K.wav shape: (83200,)\n",
      "Epoch[529]: Input data sampled from 128 A and 128 B audio files: train_data_A (456, 24, 128) train_data_B (456, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter529K.wav shape: (150400,)_loss: 3.58299351\n",
      "saved file at ./samples/recon_A2A_id016_iter529K.wav shape: (150400,)\n",
      "Epoch[530]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter530K.wav shape: (78720,)g_loss: 3.46610260\n",
      "saved file at ./samples/recon_A2A_id017_iter530K.wav shape: (78720,)\n",
      "Epoch[531]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter531K.wav shape: (303360,)_loss: 3.48918438\n",
      "saved file at ./samples/recon_A2A_id018_iter531K.wav shape: (303360,)\n",
      "Epoch[532]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter532K.wav shape: (29120,)g_loss: 3.55828714\n",
      "saved file at ./samples/recon_A2A_id000_iter532K.wav shape: (29120,)\n",
      "Epoch[533]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter533K.wav shape: (114880,)_loss: 3.50086141\n",
      "saved file at ./samples/recon_A2A_id001_iter533K.wav shape: (114880,)\n",
      "Epoch[534]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter534K.wav shape: (49600,)g_loss: 3.41165590\n",
      "saved file at ./samples/recon_A2A_id002_iter534K.wav shape: (49600,)\n",
      "Epoch[535]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter535K.wav shape: (35840,)g_loss: 3.49612617\n",
      "saved file at ./samples/recon_A2A_id003_iter535K.wav shape: (35840,)\n",
      "Epoch[536]: Input data sampled from 128 A and 128 B audio files: train_data_A (460, 24, 128) train_data_B (460, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter536K.wav shape: (60480,)g_loss: 3.33368492\n",
      "saved file at ./samples/recon_A2A_id004_iter536K.wav shape: (60480,)\n",
      "Epoch[537]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter537K.wav shape: (39680,)g_loss: 3.36346292\n",
      "saved file at ./samples/recon_A2A_id005_iter537K.wav shape: (39680,)\n",
      "Epoch[538]: Input data sampled from 128 A and 128 B audio files: train_data_A (456, 24, 128) train_data_B (456, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter538K.wav shape: (98240,)g_loss: 3.41643333\n",
      "saved file at ./samples/recon_A2A_id006_iter538K.wav shape: (98240,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[539]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter539K.wav shape: (32640,)g_loss: 3.50686836\n",
      "saved file at ./samples/recon_A2A_id007_iter539K.wav shape: (32640,)\n",
      "Epoch[540]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter540K.wav shape: (56640,)g_loss: 3.43389416\n",
      "saved file at ./samples/recon_A2A_id008_iter540K.wav shape: (56640,)\n",
      "Epoch[541]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter541K.wav shape: (19840,)g_loss: 3.47064924\n",
      "saved file at ./samples/recon_A2A_id009_iter541K.wav shape: (19840,)\n",
      "Epoch[542]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter542K.wav shape: (40960,)g_loss: 3.39490366\n",
      "saved file at ./samples/recon_A2A_id010_iter542K.wav shape: (40960,)\n",
      "Epoch[543]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter543K.wav shape: (45760,)g_loss: 3.47846699\n",
      "saved file at ./samples/recon_A2A_id011_iter543K.wav shape: (45760,)\n",
      "Epoch[544]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter544K.wav shape: (80640,)g_loss: 3.40574789\n",
      "saved file at ./samples/recon_A2A_id012_iter544K.wav shape: (80640,)\n",
      "Epoch[545]: Input data sampled from 128 A and 128 B audio files: train_data_A (457, 24, 128) train_data_B (457, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter545K.wav shape: (26880,)g_loss: 3.46327662\n",
      "saved file at ./samples/recon_A2A_id013_iter545K.wav shape: (26880,)\n",
      "Epoch[546]: Input data sampled from 128 A and 128 B audio files: train_data_A (442, 24, 128) train_data_B (442, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter546K.wav shape: (41920,)g_loss: 3.41032267\n",
      "saved file at ./samples/recon_A2A_id014_iter546K.wav shape: (41920,)\n",
      "Epoch[547]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter547K.wav shape: (83200,)g_loss: 3.40466189\n",
      "saved file at ./samples/recon_A2A_id015_iter547K.wav shape: (83200,)\n",
      "Epoch[548]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter548K.wav shape: (150400,)_loss: 3.59280396\n",
      "saved file at ./samples/recon_A2A_id016_iter548K.wav shape: (150400,)\n",
      "Epoch[549]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter549K.wav shape: (78720,)g_loss: 3.38309932\n",
      "saved file at ./samples/recon_A2A_id017_iter549K.wav shape: (78720,)\n",
      "Epoch[550]: Input data sampled from 128 A and 128 B audio files: train_data_A (441, 24, 128) train_data_B (441, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter550K.wav shape: (303360,)_loss: 3.69161749\n",
      "saved file at ./samples/recon_A2A_id018_iter550K.wav shape: (303360,)\n",
      "Epoch[551]: Input data sampled from 128 A and 128 B audio files: train_data_A (460, 24, 128) train_data_B (460, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter551K.wav shape: (29120,)g_loss: 3.31399632\n",
      "saved file at ./samples/recon_A2A_id000_iter551K.wav shape: (29120,)\n",
      "Epoch[552]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter552K.wav shape: (114880,)_loss: 3.41600299\n",
      "saved file at ./samples/recon_A2A_id001_iter552K.wav shape: (114880,)\n",
      "Epoch[553]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter553K.wav shape: (49600,)g_loss: 3.36909127\n",
      "saved file at ./samples/recon_A2A_id002_iter553K.wav shape: (49600,)\n",
      "Epoch[554]: Input data sampled from 128 A and 128 B audio files: train_data_A (456, 24, 128) train_data_B (456, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter554K.wav shape: (35840,)g_loss: 3.52981758\n",
      "saved file at ./samples/recon_A2A_id003_iter554K.wav shape: (35840,)\n",
      "Epoch[555]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter555K.wav shape: (60480,)g_loss: 3.55304241\n",
      "saved file at ./samples/recon_A2A_id004_iter555K.wav shape: (60480,)\n",
      "Epoch[556]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter556K.wav shape: (39680,)g_loss: 3.52319527\n",
      "saved file at ./samples/recon_A2A_id005_iter556K.wav shape: (39680,)\n",
      "Epoch[557]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter557K.wav shape: (98240,)g_loss: 3.36443901\n",
      "saved file at ./samples/recon_A2A_id006_iter557K.wav shape: (98240,)\n",
      "Epoch[558]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter558K.wav shape: (32640,)g_loss: 3.42691326\n",
      "saved file at ./samples/recon_A2A_id007_iter558K.wav shape: (32640,)\n",
      "Epoch[559]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter559K.wav shape: (56640,)g_loss: 3.40592813\n",
      "saved file at ./samples/recon_A2A_id008_iter559K.wav shape: (56640,)\n",
      "Epoch[560]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter560K.wav shape: (19840,)g_loss: 3.52216315\n",
      "saved file at ./samples/recon_A2A_id009_iter560K.wav shape: (19840,)\n",
      "Epoch[561]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter561K.wav shape: (40960,)g_loss: 3.41951370\n",
      "saved file at ./samples/recon_A2A_id010_iter561K.wav shape: (40960,)\n",
      "Epoch[562]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter562K.wav shape: (45760,)g_loss: 3.37027001\n",
      "saved file at ./samples/recon_A2A_id011_iter562K.wav shape: (45760,)\n",
      "Epoch[563]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter563K.wav shape: (80640,)g_loss: 3.32370567\n",
      "saved file at ./samples/recon_A2A_id012_iter563K.wav shape: (80640,)\n",
      "Epoch[564]: Input data sampled from 128 A and 128 B audio files: train_data_A (440, 24, 128) train_data_B (440, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter564K.wav shape: (26880,)g_loss: 3.43541241\n",
      "saved file at ./samples/recon_A2A_id013_iter564K.wav shape: (26880,)\n",
      "Epoch[565]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter565K.wav shape: (41920,)g_loss: 3.41253757\n",
      "saved file at ./samples/recon_A2A_id014_iter565K.wav shape: (41920,)\n",
      "Epoch[566]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter566K.wav shape: (83200,)g_loss: 3.41403866\n",
      "saved file at ./samples/recon_A2A_id015_iter566K.wav shape: (83200,)\n",
      "Epoch[567]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter567K.wav shape: (150400,)_loss: 3.46293736\n",
      "saved file at ./samples/recon_A2A_id016_iter567K.wav shape: (150400,)\n",
      "Epoch[568]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter568K.wav shape: (78720,)g_loss: 3.41719055\n",
      "saved file at ./samples/recon_A2A_id017_iter568K.wav shape: (78720,)\n",
      "Epoch[569]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter569K.wav shape: (303360,)_loss: 3.48170042\n",
      "saved file at ./samples/recon_A2A_id018_iter569K.wav shape: (303360,)\n",
      "Epoch[570]: Input data sampled from 128 A and 128 B audio files: train_data_A (464, 24, 128) train_data_B (464, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter570K.wav shape: (29120,)g_loss: 3.46142864\n",
      "saved file at ./samples/recon_A2A_id000_iter570K.wav shape: (29120,)\n",
      "Epoch[571]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter571K.wav shape: (114880,)_loss: 3.52255869\n",
      "saved file at ./samples/recon_A2A_id001_iter571K.wav shape: (114880,)\n",
      "Epoch[572]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter572K.wav shape: (49600,)g_loss: 3.34480166\n",
      "saved file at ./samples/recon_A2A_id002_iter572K.wav shape: (49600,)\n",
      "Epoch[573]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter573K.wav shape: (35840,)g_loss: 3.39398527\n",
      "saved file at ./samples/recon_A2A_id003_iter573K.wav shape: (35840,)\n",
      "Epoch[574]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter574K.wav shape: (60480,)g_loss: 3.44057083\n",
      "saved file at ./samples/recon_A2A_id004_iter574K.wav shape: (60480,)\n",
      "Epoch[575]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter575K.wav shape: (39680,)g_loss: 3.47575140\n",
      "saved file at ./samples/recon_A2A_id005_iter575K.wav shape: (39680,)\n",
      "Epoch[576]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter576K.wav shape: (98240,)g_loss: 3.45839739\n",
      "saved file at ./samples/recon_A2A_id006_iter576K.wav shape: (98240,)\n",
      "Epoch[577]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter577K.wav shape: (32640,)g_loss: 3.48244333\n",
      "saved file at ./samples/recon_A2A_id007_iter577K.wav shape: (32640,)\n",
      "Epoch[578]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter578K.wav shape: (56640,)g_loss: 3.50601602\n",
      "saved file at ./samples/recon_A2A_id008_iter578K.wav shape: (56640,)\n",
      "Epoch[579]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter579K.wav shape: (19840,)g_loss: 3.45549345\n",
      "saved file at ./samples/recon_A2A_id009_iter579K.wav shape: (19840,)\n",
      "Epoch[580]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter580K.wav shape: (40960,)g_loss: 3.45380712\n",
      "saved file at ./samples/recon_A2A_id010_iter580K.wav shape: (40960,)\n",
      "Epoch[581]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter581K.wav shape: (45760,)g_loss: 3.41031122\n",
      "saved file at ./samples/recon_A2A_id011_iter581K.wav shape: (45760,)\n",
      "Epoch[582]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter582K.wav shape: (80640,)g_loss: 3.55622196\n",
      "saved file at ./samples/recon_A2A_id012_iter582K.wav shape: (80640,)\n",
      "Epoch[583]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter583K.wav shape: (26880,)g_loss: 3.35614729\n",
      "saved file at ./samples/recon_A2A_id013_iter583K.wav shape: (26880,)\n",
      "Epoch[584]: Input data sampled from 128 A and 128 B audio files: train_data_A (440, 24, 128) train_data_B (440, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter584K.wav shape: (41920,)g_loss: 3.45925379\n",
      "saved file at ./samples/recon_A2A_id014_iter584K.wav shape: (41920,)\n",
      "Epoch[585]: Input data sampled from 128 A and 128 B audio files: train_data_A (440, 24, 128) train_data_B (440, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter585K.wav shape: (83200,)g_loss: 3.42217946\n",
      "saved file at ./samples/recon_A2A_id015_iter585K.wav shape: (83200,)\n",
      "Epoch[586]: Input data sampled from 128 A and 128 B audio files: train_data_A (456, 24, 128) train_data_B (456, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter586K.wav shape: (150400,)_loss: 3.32840729\n",
      "saved file at ./samples/recon_A2A_id016_iter586K.wav shape: (150400,)\n",
      "Epoch[587]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter587K.wav shape: (78720,)g_loss: 3.36190271\n",
      "saved file at ./samples/recon_A2A_id017_iter587K.wav shape: (78720,)\n",
      "Epoch[588]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter588K.wav shape: (303360,)_loss: 3.39545774\n",
      "saved file at ./samples/recon_A2A_id018_iter588K.wav shape: (303360,)\n",
      "Epoch[589]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter589K.wav shape: (29120,)g_loss: 3.36364889\n",
      "saved file at ./samples/recon_A2A_id000_iter589K.wav shape: (29120,)\n",
      "Epoch[590]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter590K.wav shape: (114880,)_loss: 3.42899895\n",
      "saved file at ./samples/recon_A2A_id001_iter590K.wav shape: (114880,)\n",
      "Epoch[591]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter591K.wav shape: (49600,)g_loss: 3.37468386\n",
      "saved file at ./samples/recon_A2A_id002_iter591K.wav shape: (49600,)\n",
      "Epoch[592]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter592K.wav shape: (35840,)g_loss: 3.41144347\n",
      "saved file at ./samples/recon_A2A_id003_iter592K.wav shape: (35840,)\n",
      "Epoch[593]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter593K.wav shape: (60480,)g_loss: 3.37343359\n",
      "saved file at ./samples/recon_A2A_id004_iter593K.wav shape: (60480,)\n",
      "Epoch[594]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter594K.wav shape: (39680,)g_loss: 3.34924984\n",
      "saved file at ./samples/recon_A2A_id005_iter594K.wav shape: (39680,)\n",
      "Epoch[595]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter595K.wav shape: (98240,)g_loss: 3.55521774\n",
      "saved file at ./samples/recon_A2A_id006_iter595K.wav shape: (98240,)\n",
      "Epoch[596]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter596K.wav shape: (32640,)g_loss: 3.47166276\n",
      "saved file at ./samples/recon_A2A_id007_iter596K.wav shape: (32640,)\n",
      "Epoch[597]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter597K.wav shape: (56640,)g_loss: 3.38494539\n",
      "saved file at ./samples/recon_A2A_id008_iter597K.wav shape: (56640,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[598]: Input data sampled from 128 A and 128 B audio files: train_data_A (459, 24, 128) train_data_B (459, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter598K.wav shape: (19840,)g_loss: 3.39177608\n",
      "saved file at ./samples/recon_A2A_id009_iter598K.wav shape: (19840,)\n",
      "Epoch[599]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter599K.wav shape: (40960,)g_loss: 3.46534824\n",
      "saved file at ./samples/recon_A2A_id010_iter599K.wav shape: (40960,)\n",
      "Epoch[600]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter600K.wav shape: (45760,)g_loss: 3.30475831\n",
      "saved file at ./samples/recon_A2A_id011_iter600K.wav shape: (45760,)\n",
      "Epoch[601]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter601K.wav shape: (80640,)g_loss: 3.34067822\n",
      "saved file at ./samples/recon_A2A_id012_iter601K.wav shape: (80640,)\n",
      "Epoch[602]: Input data sampled from 128 A and 128 B audio files: train_data_A (456, 24, 128) train_data_B (456, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter602K.wav shape: (26880,)g_loss: 3.29291272\n",
      "saved file at ./samples/recon_A2A_id013_iter602K.wav shape: (26880,)\n",
      "Epoch[603]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter603K.wav shape: (41920,)g_loss: 3.45406055\n",
      "saved file at ./samples/recon_A2A_id014_iter603K.wav shape: (41920,)\n",
      "Epoch[604]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter604K.wav shape: (83200,)g_loss: 3.56234789\n",
      "saved file at ./samples/recon_A2A_id015_iter604K.wav shape: (83200,)\n",
      "Epoch[605]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter605K.wav shape: (150400,)_loss: 3.45268631\n",
      "saved file at ./samples/recon_A2A_id016_iter605K.wav shape: (150400,)\n",
      "Epoch[606]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter606K.wav shape: (78720,)g_loss: 3.50968838\n",
      "saved file at ./samples/recon_A2A_id017_iter606K.wav shape: (78720,)\n",
      "Epoch[607]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter607K.wav shape: (303360,)_loss: 3.53426290\n",
      "saved file at ./samples/recon_A2A_id018_iter607K.wav shape: (303360,)\n",
      "Epoch[608]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter608K.wav shape: (29120,)g_loss: 3.55959129\n",
      "saved file at ./samples/recon_A2A_id000_iter608K.wav shape: (29120,)\n",
      "Epoch[609]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter609K.wav shape: (114880,)_loss: 3.47096491\n",
      "saved file at ./samples/recon_A2A_id001_iter609K.wav shape: (114880,)\n",
      "Epoch[610]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter610K.wav shape: (49600,)g_loss: 3.32914829\n",
      "saved file at ./samples/recon_A2A_id002_iter610K.wav shape: (49600,)\n",
      "Epoch[611]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter611K.wav shape: (35840,)g_loss: 3.38987207\n",
      "saved file at ./samples/recon_A2A_id003_iter611K.wav shape: (35840,)\n",
      "Epoch[612]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter612K.wav shape: (60480,)g_loss: 3.38403654\n",
      "saved file at ./samples/recon_A2A_id004_iter612K.wav shape: (60480,)\n",
      "Epoch[613]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter613K.wav shape: (39680,)g_loss: 3.29125929\n",
      "saved file at ./samples/recon_A2A_id005_iter613K.wav shape: (39680,)\n",
      "Epoch[614]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter614K.wav shape: (98240,)g_loss: 3.42832136\n",
      "saved file at ./samples/recon_A2A_id006_iter614K.wav shape: (98240,)\n",
      "Epoch[615]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter615K.wav shape: (32640,)g_loss: 3.36703777\n",
      "saved file at ./samples/recon_A2A_id007_iter615K.wav shape: (32640,)\n",
      "Epoch[616]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter616K.wav shape: (56640,)g_loss: 3.35203838\n",
      "saved file at ./samples/recon_A2A_id008_iter616K.wav shape: (56640,)\n",
      "Epoch[617]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter617K.wav shape: (19840,)g_loss: 3.38998294\n",
      "saved file at ./samples/recon_A2A_id009_iter617K.wav shape: (19840,)\n",
      "Epoch[618]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter618K.wav shape: (40960,)g_loss: 3.51897073\n",
      "saved file at ./samples/recon_A2A_id010_iter618K.wav shape: (40960,)\n",
      "Epoch[619]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter619K.wav shape: (45760,)g_loss: 3.37862754\n",
      "saved file at ./samples/recon_A2A_id011_iter619K.wav shape: (45760,)\n",
      "Epoch[620]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter620K.wav shape: (80640,)g_loss: 3.34520006\n",
      "saved file at ./samples/recon_A2A_id012_iter620K.wav shape: (80640,)\n",
      "Epoch[621]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter621K.wav shape: (26880,)g_loss: 3.27294588\n",
      "saved file at ./samples/recon_A2A_id013_iter621K.wav shape: (26880,)\n",
      "Epoch[622]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter622K.wav shape: (41920,)g_loss: 3.42394710\n",
      "saved file at ./samples/recon_A2A_id014_iter622K.wav shape: (41920,)\n",
      "Epoch[623]: Input data sampled from 128 A and 128 B audio files: train_data_A (435, 24, 128) train_data_B (435, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter623K.wav shape: (83200,)g_loss: 3.47918272\n",
      "saved file at ./samples/recon_A2A_id015_iter623K.wav shape: (83200,)\n",
      "Epoch[624]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter624K.wav shape: (150400,)_loss: 3.49726915\n",
      "saved file at ./samples/recon_A2A_id016_iter624K.wav shape: (150400,)\n",
      "Epoch[625]: Input data sampled from 128 A and 128 B audio files: train_data_A (438, 24, 128) train_data_B (438, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter625K.wav shape: (78720,)g_loss: 3.39436483\n",
      "saved file at ./samples/recon_A2A_id017_iter625K.wav shape: (78720,)\n",
      "Epoch[626]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter626K.wav shape: (303360,)_loss: 3.42551327\n",
      "saved file at ./samples/recon_A2A_id018_iter626K.wav shape: (303360,)\n",
      "Epoch[627]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter627K.wav shape: (29120,)g_loss: 3.49085522\n",
      "saved file at ./samples/recon_A2A_id000_iter627K.wav shape: (29120,)\n",
      "Epoch[628]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter628K.wav shape: (114880,)_loss: 3.42230368\n",
      "saved file at ./samples/recon_A2A_id001_iter628K.wav shape: (114880,)\n",
      "Epoch[629]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter629K.wav shape: (49600,)g_loss: 3.40009975\n",
      "saved file at ./samples/recon_A2A_id002_iter629K.wav shape: (49600,)\n",
      "Epoch[630]: Input data sampled from 128 A and 128 B audio files: train_data_A (458, 24, 128) train_data_B (458, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter630K.wav shape: (35840,)g_loss: 3.50264454\n",
      "saved file at ./samples/recon_A2A_id003_iter630K.wav shape: (35840,)\n",
      "Epoch[631]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter631K.wav shape: (60480,)g_loss: 3.57049656\n",
      "saved file at ./samples/recon_A2A_id004_iter631K.wav shape: (60480,)\n",
      "Epoch[632]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter632K.wav shape: (39680,)g_loss: 3.36973858\n",
      "saved file at ./samples/recon_A2A_id005_iter632K.wav shape: (39680,)\n",
      "Epoch[633]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter633K.wav shape: (98240,)g_loss: 3.40661311\n",
      "saved file at ./samples/recon_A2A_id006_iter633K.wav shape: (98240,)\n",
      "Epoch[634]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter634K.wav shape: (32640,)g_loss: 3.24351120\n",
      "saved file at ./samples/recon_A2A_id007_iter634K.wav shape: (32640,)\n",
      "Epoch[635]: Input data sampled from 128 A and 128 B audio files: train_data_A (441, 24, 128) train_data_B (441, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter635K.wav shape: (56640,)g_loss: 3.49117231\n",
      "saved file at ./samples/recon_A2A_id008_iter635K.wav shape: (56640,)\n",
      "Epoch[636]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter636K.wav shape: (19840,)g_loss: 3.48968792\n",
      "saved file at ./samples/recon_A2A_id009_iter636K.wav shape: (19840,)\n",
      "Epoch[637]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter637K.wav shape: (40960,)g_loss: 3.55060053\n",
      "saved file at ./samples/recon_A2A_id010_iter637K.wav shape: (40960,)\n",
      "Epoch[638]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter638K.wav shape: (45760,)g_loss: 3.42943025\n",
      "saved file at ./samples/recon_A2A_id011_iter638K.wav shape: (45760,)\n",
      "Epoch[639]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter639K.wav shape: (80640,)g_loss: 3.44947410\n",
      "saved file at ./samples/recon_A2A_id012_iter639K.wav shape: (80640,)\n",
      "Epoch[640]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter640K.wav shape: (26880,)g_loss: 3.28579855\n",
      "saved file at ./samples/recon_A2A_id013_iter640K.wav shape: (26880,)\n",
      "Epoch[641]: Input data sampled from 128 A and 128 B audio files: train_data_A (456, 24, 128) train_data_B (456, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter641K.wav shape: (41920,)g_loss: 3.39802408\n",
      "saved file at ./samples/recon_A2A_id014_iter641K.wav shape: (41920,)\n",
      "Epoch[642]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter642K.wav shape: (83200,)g_loss: 3.39946771\n",
      "saved file at ./samples/recon_A2A_id015_iter642K.wav shape: (83200,)\n",
      "Epoch[643]: Input data sampled from 128 A and 128 B audio files: train_data_A (440, 24, 128) train_data_B (440, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter643K.wav shape: (150400,)_loss: 3.33739567\n",
      "saved file at ./samples/recon_A2A_id016_iter643K.wav shape: (150400,)\n",
      "Epoch[644]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter644K.wav shape: (78720,)g_loss: 3.44568825\n",
      "saved file at ./samples/recon_A2A_id017_iter644K.wav shape: (78720,)\n",
      "Epoch[645]: Input data sampled from 128 A and 128 B audio files: train_data_A (460, 24, 128) train_data_B (460, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter645K.wav shape: (303360,)_loss: 3.52615356\n",
      "saved file at ./samples/recon_A2A_id018_iter645K.wav shape: (303360,)\n",
      "Epoch[646]: Input data sampled from 128 A and 128 B audio files: train_data_A (459, 24, 128) train_data_B (459, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter646K.wav shape: (29120,)g_loss: 3.33727360\n",
      "saved file at ./samples/recon_A2A_id000_iter646K.wav shape: (29120,)\n",
      "Epoch[647]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter647K.wav shape: (114880,)_loss: 3.65622282\n",
      "saved file at ./samples/recon_A2A_id001_iter647K.wav shape: (114880,)\n",
      "Epoch[648]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter648K.wav shape: (49600,)g_loss: 3.43727589\n",
      "saved file at ./samples/recon_A2A_id002_iter648K.wav shape: (49600,)\n",
      "Epoch[649]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter649K.wav shape: (35840,)g_loss: 3.46656871\n",
      "saved file at ./samples/recon_A2A_id003_iter649K.wav shape: (35840,)\n",
      "Epoch[650]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter650K.wav shape: (60480,)g_loss: 3.57695556\n",
      "saved file at ./samples/recon_A2A_id004_iter650K.wav shape: (60480,)\n",
      "Epoch[651]: Input data sampled from 128 A and 128 B audio files: train_data_A (441, 24, 128) train_data_B (441, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter651K.wav shape: (39680,)g_loss: 3.36348629\n",
      "saved file at ./samples/recon_A2A_id005_iter651K.wav shape: (39680,)\n",
      "Epoch[652]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter652K.wav shape: (98240,)g_loss: 3.55839491\n",
      "saved file at ./samples/recon_A2A_id006_iter652K.wav shape: (98240,)\n",
      "Epoch[653]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter653K.wav shape: (32640,)g_loss: 3.53701067\n",
      "saved file at ./samples/recon_A2A_id007_iter653K.wav shape: (32640,)\n",
      "Epoch[654]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter654K.wav shape: (56640,)g_loss: 3.26824045\n",
      "saved file at ./samples/recon_A2A_id008_iter654K.wav shape: (56640,)\n",
      "Epoch[655]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter655K.wav shape: (19840,)g_loss: 3.32401752\n",
      "saved file at ./samples/recon_A2A_id009_iter655K.wav shape: (19840,)\n",
      "Epoch[656]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter656K.wav shape: (40960,)g_loss: 3.46122789\n",
      "saved file at ./samples/recon_A2A_id010_iter656K.wav shape: (40960,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[657]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter657K.wav shape: (45760,)g_loss: 3.37702394\n",
      "saved file at ./samples/recon_A2A_id011_iter657K.wav shape: (45760,)\n",
      "Epoch[658]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter658K.wav shape: (80640,)g_loss: 3.39157462\n",
      "saved file at ./samples/recon_A2A_id012_iter658K.wav shape: (80640,)\n",
      "Epoch[659]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter659K.wav shape: (26880,)g_loss: 3.38357592\n",
      "saved file at ./samples/recon_A2A_id013_iter659K.wav shape: (26880,)\n",
      "Epoch[660]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter660K.wav shape: (41920,)g_loss: 3.39036131\n",
      "saved file at ./samples/recon_A2A_id014_iter660K.wav shape: (41920,)\n",
      "Epoch[661]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter661K.wav shape: (83200,)g_loss: 3.42123938\n",
      "saved file at ./samples/recon_A2A_id015_iter661K.wav shape: (83200,)\n",
      "Epoch[662]: Input data sampled from 128 A and 128 B audio files: train_data_A (442, 24, 128) train_data_B (442, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter662K.wav shape: (150400,)_loss: 3.48935962\n",
      "saved file at ./samples/recon_A2A_id016_iter662K.wav shape: (150400,)\n",
      "Epoch[663]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter663K.wav shape: (78720,)g_loss: 3.41069508\n",
      "saved file at ./samples/recon_A2A_id017_iter663K.wav shape: (78720,)\n",
      "Epoch[664]: Input data sampled from 128 A and 128 B audio files: train_data_A (460, 24, 128) train_data_B (460, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter664K.wav shape: (303360,)_loss: 3.47056770\n",
      "saved file at ./samples/recon_A2A_id018_iter664K.wav shape: (303360,)\n",
      "Epoch[665]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter665K.wav shape: (29120,)g_loss: 3.49061394\n",
      "saved file at ./samples/recon_A2A_id000_iter665K.wav shape: (29120,)\n",
      "Epoch[666]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter666K.wav shape: (114880,)_loss: 3.43420076\n",
      "saved file at ./samples/recon_A2A_id001_iter666K.wav shape: (114880,)\n",
      "Epoch[667]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter667K.wav shape: (49600,)g_loss: 3.35627079\n",
      "saved file at ./samples/recon_A2A_id002_iter667K.wav shape: (49600,)\n",
      "Epoch[668]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter668K.wav shape: (35840,)g_loss: 3.42418575\n",
      "saved file at ./samples/recon_A2A_id003_iter668K.wav shape: (35840,)\n",
      "Epoch[669]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter669K.wav shape: (60480,)g_loss: 3.41765738\n",
      "saved file at ./samples/recon_A2A_id004_iter669K.wav shape: (60480,)\n",
      "Epoch[670]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter670K.wav shape: (39680,)g_loss: 3.42584705\n",
      "saved file at ./samples/recon_A2A_id005_iter670K.wav shape: (39680,)\n",
      "Epoch[671]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter671K.wav shape: (98240,)g_loss: 3.39556313\n",
      "saved file at ./samples/recon_A2A_id006_iter671K.wav shape: (98240,)\n",
      "Epoch[672]: Input data sampled from 128 A and 128 B audio files: train_data_A (457, 24, 128) train_data_B (457, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter672K.wav shape: (32640,)g_loss: 3.50076222\n",
      "saved file at ./samples/recon_A2A_id007_iter672K.wav shape: (32640,)\n",
      "Epoch[673]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter673K.wav shape: (56640,)g_loss: 3.39272070\n",
      "saved file at ./samples/recon_A2A_id008_iter673K.wav shape: (56640,)\n",
      "Epoch[674]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter674K.wav shape: (19840,)g_loss: 3.22037745\n",
      "saved file at ./samples/recon_A2A_id009_iter674K.wav shape: (19840,)\n",
      "Epoch[675]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter675K.wav shape: (40960,)g_loss: 3.41944504\n",
      "saved file at ./samples/recon_A2A_id010_iter675K.wav shape: (40960,)\n",
      "Epoch[676]: Input data sampled from 128 A and 128 B audio files: train_data_A (436, 24, 128) train_data_B (436, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter676K.wav shape: (45760,)g_loss: 3.35772085\n",
      "saved file at ./samples/recon_A2A_id011_iter676K.wav shape: (45760,)\n",
      "Epoch[677]: Input data sampled from 128 A and 128 B audio files: train_data_A (458, 24, 128) train_data_B (458, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter677K.wav shape: (80640,)g_loss: 3.37459469\n",
      "saved file at ./samples/recon_A2A_id012_iter677K.wav shape: (80640,)\n",
      "Epoch[678]: Input data sampled from 128 A and 128 B audio files: train_data_A (458, 24, 128) train_data_B (458, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter678K.wav shape: (26880,)g_loss: 3.43275976\n",
      "saved file at ./samples/recon_A2A_id013_iter678K.wav shape: (26880,)\n",
      "Epoch[679]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter679K.wav shape: (41920,)g_loss: 3.35793924\n",
      "saved file at ./samples/recon_A2A_id014_iter679K.wav shape: (41920,)\n",
      "Epoch[680]: Input data sampled from 128 A and 128 B audio files: train_data_A (458, 24, 128) train_data_B (458, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter680K.wav shape: (83200,)g_loss: 3.21593094\n",
      "saved file at ./samples/recon_A2A_id015_iter680K.wav shape: (83200,)\n",
      "Epoch[681]: Input data sampled from 128 A and 128 B audio files: train_data_A (456, 24, 128) train_data_B (456, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter681K.wav shape: (150400,)_loss: 3.53719091\n",
      "saved file at ./samples/recon_A2A_id016_iter681K.wav shape: (150400,)\n",
      "Epoch[682]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter682K.wav shape: (78720,)g_loss: 3.45179820\n",
      "saved file at ./samples/recon_A2A_id017_iter682K.wav shape: (78720,)\n",
      "Epoch[683]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter683K.wav shape: (303360,)_loss: 3.42881584\n",
      "saved file at ./samples/recon_A2A_id018_iter683K.wav shape: (303360,)\n",
      "Epoch[684]: Input data sampled from 128 A and 128 B audio files: train_data_A (458, 24, 128) train_data_B (458, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter684K.wav shape: (29120,)g_loss: 3.42178011\n",
      "saved file at ./samples/recon_A2A_id000_iter684K.wav shape: (29120,)\n",
      "Epoch[685]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter685K.wav shape: (114880,)_loss: 3.31661749\n",
      "saved file at ./samples/recon_A2A_id001_iter685K.wav shape: (114880,)\n",
      "Epoch[686]: Input data sampled from 128 A and 128 B audio files: train_data_A (442, 24, 128) train_data_B (442, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter686K.wav shape: (49600,)g_loss: 3.48487806\n",
      "saved file at ./samples/recon_A2A_id002_iter686K.wav shape: (49600,)\n",
      "Epoch[687]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter687K.wav shape: (35840,)g_loss: 3.38616991\n",
      "saved file at ./samples/recon_A2A_id003_iter687K.wav shape: (35840,)\n",
      "Epoch[688]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter688K.wav shape: (60480,)g_loss: 3.31147504\n",
      "saved file at ./samples/recon_A2A_id004_iter688K.wav shape: (60480,)\n",
      "Epoch[689]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter689K.wav shape: (39680,)g_loss: 3.35187006\n",
      "saved file at ./samples/recon_A2A_id005_iter689K.wav shape: (39680,)\n",
      "Epoch[690]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter690K.wav shape: (98240,)g_loss: 3.46248770\n",
      "saved file at ./samples/recon_A2A_id006_iter690K.wav shape: (98240,)\n",
      "Epoch[691]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter691K.wav shape: (32640,)g_loss: 3.48012543\n",
      "saved file at ./samples/recon_A2A_id007_iter691K.wav shape: (32640,)\n",
      "Epoch[692]: Input data sampled from 128 A and 128 B audio files: train_data_A (457, 24, 128) train_data_B (457, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter692K.wav shape: (56640,)g_loss: 3.33071327\n",
      "saved file at ./samples/recon_A2A_id008_iter692K.wav shape: (56640,)\n",
      "Epoch[693]: Input data sampled from 128 A and 128 B audio files: train_data_A (438, 24, 128) train_data_B (438, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter693K.wav shape: (19840,)g_loss: 3.42192984\n",
      "saved file at ./samples/recon_A2A_id009_iter693K.wav shape: (19840,)\n",
      "Epoch[694]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter694K.wav shape: (40960,)g_loss: 3.38623309\n",
      "saved file at ./samples/recon_A2A_id010_iter694K.wav shape: (40960,)\n",
      "Epoch[695]: Input data sampled from 128 A and 128 B audio files: train_data_A (457, 24, 128) train_data_B (457, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter695K.wav shape: (45760,)g_loss: 3.42538786\n",
      "saved file at ./samples/recon_A2A_id011_iter695K.wav shape: (45760,)\n",
      "Epoch[696]: Input data sampled from 128 A and 128 B audio files: train_data_A (440, 24, 128) train_data_B (440, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter696K.wav shape: (80640,)g_loss: 3.35116100\n",
      "saved file at ./samples/recon_A2A_id012_iter696K.wav shape: (80640,)\n",
      "Epoch[697]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter697K.wav shape: (26880,)g_loss: 3.46023703\n",
      "saved file at ./samples/recon_A2A_id013_iter697K.wav shape: (26880,)\n",
      "Epoch[698]: Input data sampled from 128 A and 128 B audio files: train_data_A (456, 24, 128) train_data_B (456, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter698K.wav shape: (41920,)g_loss: 3.38595819\n",
      "saved file at ./samples/recon_A2A_id014_iter698K.wav shape: (41920,)\n",
      "Epoch[699]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter699K.wav shape: (83200,)g_loss: 3.28010821\n",
      "saved file at ./samples/recon_A2A_id015_iter699K.wav shape: (83200,)\n",
      "Epoch[700]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter700K.wav shape: (150400,)_loss: 3.40907478\n",
      "saved file at ./samples/recon_A2A_id016_iter700K.wav shape: (150400,)\n",
      "Epoch[701]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter701K.wav shape: (78720,)g_loss: 3.43958902\n",
      "saved file at ./samples/recon_A2A_id017_iter701K.wav shape: (78720,)\n",
      "Epoch[702]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter702K.wav shape: (303360,)_loss: 3.45676041\n",
      "saved file at ./samples/recon_A2A_id018_iter702K.wav shape: (303360,)\n",
      "Epoch[703]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter703K.wav shape: (29120,)g_loss: 3.37187433\n",
      "saved file at ./samples/recon_A2A_id000_iter703K.wav shape: (29120,)\n",
      "Epoch[704]: Input data sampled from 128 A and 128 B audio files: train_data_A (457, 24, 128) train_data_B (457, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter704K.wav shape: (114880,)_loss: 3.35971665\n",
      "saved file at ./samples/recon_A2A_id001_iter704K.wav shape: (114880,)\n",
      "Epoch[705]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter705K.wav shape: (49600,)g_loss: 3.34970665\n",
      "saved file at ./samples/recon_A2A_id002_iter705K.wav shape: (49600,)\n",
      "Epoch[706]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter706K.wav shape: (35840,)g_loss: 3.46542358\n",
      "saved file at ./samples/recon_A2A_id003_iter706K.wav shape: (35840,)\n",
      "Epoch[707]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter707K.wav shape: (60480,)g_loss: 3.31499910\n",
      "saved file at ./samples/recon_A2A_id004_iter707K.wav shape: (60480,)\n",
      "Epoch[708]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter708K.wav shape: (39680,)g_loss: 3.55659389\n",
      "saved file at ./samples/recon_A2A_id005_iter708K.wav shape: (39680,)\n",
      "Epoch[709]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter709K.wav shape: (98240,)g_loss: 3.42026639\n",
      "saved file at ./samples/recon_A2A_id006_iter709K.wav shape: (98240,)\n",
      "Epoch[710]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter710K.wav shape: (32640,)g_loss: 3.41876268\n",
      "saved file at ./samples/recon_A2A_id007_iter710K.wav shape: (32640,)\n",
      "Epoch[711]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter711K.wav shape: (56640,)g_loss: 3.25736594\n",
      "saved file at ./samples/recon_A2A_id008_iter711K.wav shape: (56640,)\n",
      "Epoch[712]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter712K.wav shape: (19840,)g_loss: 3.49315381\n",
      "saved file at ./samples/recon_A2A_id009_iter712K.wav shape: (19840,)\n",
      "Epoch[713]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter713K.wav shape: (40960,)g_loss: 3.42074776\n",
      "saved file at ./samples/recon_A2A_id010_iter713K.wav shape: (40960,)\n",
      "Epoch[714]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter714K.wav shape: (45760,)g_loss: 3.36840200\n",
      "saved file at ./samples/recon_A2A_id011_iter714K.wav shape: (45760,)\n",
      "Epoch[715]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter715K.wav shape: (80640,)g_loss: 3.46573663\n",
      "saved file at ./samples/recon_A2A_id012_iter715K.wav shape: (80640,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[716]: Input data sampled from 128 A and 128 B audio files: train_data_A (436, 24, 128) train_data_B (436, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter716K.wav shape: (26880,)g_loss: 3.55576086\n",
      "saved file at ./samples/recon_A2A_id013_iter716K.wav shape: (26880,)\n",
      "Epoch[717]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter717K.wav shape: (41920,)g_loss: 3.27566242\n",
      "saved file at ./samples/recon_A2A_id014_iter717K.wav shape: (41920,)\n",
      "Epoch[718]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter718K.wav shape: (83200,)g_loss: 3.26813412\n",
      "saved file at ./samples/recon_A2A_id015_iter718K.wav shape: (83200,)\n",
      "Epoch[719]: Input data sampled from 128 A and 128 B audio files: train_data_A (459, 24, 128) train_data_B (459, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter719K.wav shape: (150400,)_loss: 3.48986053\n",
      "saved file at ./samples/recon_A2A_id016_iter719K.wav shape: (150400,)\n",
      "Epoch[720]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter720K.wav shape: (78720,)g_loss: 3.37506461\n",
      "saved file at ./samples/recon_A2A_id017_iter720K.wav shape: (78720,)\n",
      "Epoch[721]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter721K.wav shape: (303360,)_loss: 3.39016628\n",
      "saved file at ./samples/recon_A2A_id018_iter721K.wav shape: (303360,)\n",
      "Epoch[722]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter722K.wav shape: (29120,)g_loss: 3.32184982\n",
      "saved file at ./samples/recon_A2A_id000_iter722K.wav shape: (29120,)\n",
      "Epoch[723]: Input data sampled from 128 A and 128 B audio files: train_data_A (458, 24, 128) train_data_B (458, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter723K.wav shape: (114880,)_loss: 3.41692114\n",
      "saved file at ./samples/recon_A2A_id001_iter723K.wav shape: (114880,)\n",
      "Epoch[724]: Input data sampled from 128 A and 128 B audio files: train_data_A (446, 24, 128) train_data_B (446, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter724K.wav shape: (49600,)g_loss: 3.34318781\n",
      "saved file at ./samples/recon_A2A_id002_iter724K.wav shape: (49600,)\n",
      "Epoch[725]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter725K.wav shape: (35840,)g_loss: 3.30899239\n",
      "saved file at ./samples/recon_A2A_id003_iter725K.wav shape: (35840,)\n",
      "Epoch[726]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter726K.wav shape: (60480,)g_loss: 3.36293459\n",
      "saved file at ./samples/recon_A2A_id004_iter726K.wav shape: (60480,)\n",
      "Epoch[727]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter727K.wav shape: (39680,)g_loss: 3.34442472\n",
      "saved file at ./samples/recon_A2A_id005_iter727K.wav shape: (39680,)\n",
      "Epoch[728]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter728K.wav shape: (98240,)g_loss: 3.42974830\n",
      "saved file at ./samples/recon_A2A_id006_iter728K.wav shape: (98240,)\n",
      "Epoch[729]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter729K.wav shape: (32640,)g_loss: 3.27278137\n",
      "saved file at ./samples/recon_A2A_id007_iter729K.wav shape: (32640,)\n",
      "Epoch[730]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter730K.wav shape: (56640,)g_loss: 3.29885173\n",
      "saved file at ./samples/recon_A2A_id008_iter730K.wav shape: (56640,)\n",
      "Epoch[731]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter731K.wav shape: (19840,)g_loss: 3.35077691\n",
      "saved file at ./samples/recon_A2A_id009_iter731K.wav shape: (19840,)\n",
      "Epoch[732]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter732K.wav shape: (40960,)g_loss: 3.45097113\n",
      "saved file at ./samples/recon_A2A_id010_iter732K.wav shape: (40960,)\n",
      "Epoch[733]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter733K.wav shape: (45760,)g_loss: 3.43459535\n",
      "saved file at ./samples/recon_A2A_id011_iter733K.wav shape: (45760,)\n",
      "Epoch[734]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter734K.wav shape: (80640,)g_loss: 3.24310589\n",
      "saved file at ./samples/recon_A2A_id012_iter734K.wav shape: (80640,)\n",
      "Epoch[735]: Input data sampled from 128 A and 128 B audio files: train_data_A (442, 24, 128) train_data_B (442, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter735K.wav shape: (26880,)g_loss: 3.31015015\n",
      "saved file at ./samples/recon_A2A_id013_iter735K.wav shape: (26880,)\n",
      "Epoch[736]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter736K.wav shape: (41920,)g_loss: 3.41498470\n",
      "saved file at ./samples/recon_A2A_id014_iter736K.wav shape: (41920,)\n",
      "Epoch[737]: Input data sampled from 128 A and 128 B audio files: train_data_A (440, 24, 128) train_data_B (440, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter737K.wav shape: (83200,)g_loss: 3.35007095\n",
      "saved file at ./samples/recon_A2A_id015_iter737K.wav shape: (83200,)\n",
      "Epoch[738]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter738K.wav shape: (150400,)_loss: 3.36033273\n",
      "saved file at ./samples/recon_A2A_id016_iter738K.wav shape: (150400,)\n",
      "Epoch[739]: Input data sampled from 128 A and 128 B audio files: train_data_A (438, 24, 128) train_data_B (438, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter739K.wav shape: (78720,)g_loss: 3.39496851\n",
      "saved file at ./samples/recon_A2A_id017_iter739K.wav shape: (78720,)\n",
      "Epoch[740]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter740K.wav shape: (303360,)_loss: 3.37161541\n",
      "saved file at ./samples/recon_A2A_id018_iter740K.wav shape: (303360,)\n",
      "Epoch[741]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter741K.wav shape: (29120,)g_loss: 3.45196223\n",
      "saved file at ./samples/recon_A2A_id000_iter741K.wav shape: (29120,)\n",
      "Epoch[742]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter742K.wav shape: (114880,)_loss: 3.40926361\n",
      "saved file at ./samples/recon_A2A_id001_iter742K.wav shape: (114880,)\n",
      "Epoch[743]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter743K.wav shape: (49600,)g_loss: 3.49058390\n",
      "saved file at ./samples/recon_A2A_id002_iter743K.wav shape: (49600,)\n",
      "Epoch[744]: Input data sampled from 128 A and 128 B audio files: train_data_A (457, 24, 128) train_data_B (457, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter744K.wav shape: (35840,)g_loss: 3.42381334\n",
      "saved file at ./samples/recon_A2A_id003_iter744K.wav shape: (35840,)\n",
      "Epoch[745]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter745K.wav shape: (60480,)g_loss: 3.44984460\n",
      "saved file at ./samples/recon_A2A_id004_iter745K.wav shape: (60480,)\n",
      "Epoch[746]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter746K.wav shape: (39680,)g_loss: 3.28482246\n",
      "saved file at ./samples/recon_A2A_id005_iter746K.wav shape: (39680,)\n",
      "Epoch[747]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter747K.wav shape: (98240,)g_loss: 3.30360889\n",
      "saved file at ./samples/recon_A2A_id006_iter747K.wav shape: (98240,)\n",
      "Epoch[748]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter748K.wav shape: (32640,)g_loss: 3.28599954\n",
      "saved file at ./samples/recon_A2A_id007_iter748K.wav shape: (32640,)\n",
      "Epoch[749]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter749K.wav shape: (56640,)g_loss: 3.34309769\n",
      "saved file at ./samples/recon_A2A_id008_iter749K.wav shape: (56640,)\n",
      "Epoch[750]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter750K.wav shape: (19840,)g_loss: 3.28743339\n",
      "saved file at ./samples/recon_A2A_id009_iter750K.wav shape: (19840,)\n",
      "Epoch[751]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter751K.wav shape: (40960,)g_loss: 3.42065072\n",
      "saved file at ./samples/recon_A2A_id010_iter751K.wav shape: (40960,)\n",
      "Epoch[752]: Input data sampled from 128 A and 128 B audio files: train_data_A (436, 24, 128) train_data_B (436, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter752K.wav shape: (45760,)g_loss: 3.50064516\n",
      "saved file at ./samples/recon_A2A_id011_iter752K.wav shape: (45760,)\n",
      "Epoch[753]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter753K.wav shape: (80640,)g_loss: 3.31369567\n",
      "saved file at ./samples/recon_A2A_id012_iter753K.wav shape: (80640,)\n",
      "Epoch[754]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter754K.wav shape: (26880,)g_loss: 3.36497164\n",
      "saved file at ./samples/recon_A2A_id013_iter754K.wav shape: (26880,)\n",
      "Epoch[755]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter755K.wav shape: (41920,)g_loss: 3.45668554\n",
      "saved file at ./samples/recon_A2A_id014_iter755K.wav shape: (41920,)\n",
      "Epoch[756]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter756K.wav shape: (83200,)g_loss: 3.39010668\n",
      "saved file at ./samples/recon_A2A_id015_iter756K.wav shape: (83200,)\n",
      "Epoch[757]: Input data sampled from 128 A and 128 B audio files: train_data_A (457, 24, 128) train_data_B (457, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter757K.wav shape: (150400,)_loss: 3.34759498\n",
      "saved file at ./samples/recon_A2A_id016_iter757K.wav shape: (150400,)\n",
      "Epoch[758]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter758K.wav shape: (78720,)g_loss: 3.46608424\n",
      "saved file at ./samples/recon_A2A_id017_iter758K.wav shape: (78720,)\n",
      "Epoch[759]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter759K.wav shape: (303360,)_loss: 3.30817318\n",
      "saved file at ./samples/recon_A2A_id018_iter759K.wav shape: (303360,)\n",
      "Epoch[760]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter760K.wav shape: (29120,)g_loss: 3.38406253\n",
      "saved file at ./samples/recon_A2A_id000_iter760K.wav shape: (29120,)\n",
      "Epoch[761]: Input data sampled from 128 A and 128 B audio files: train_data_A (460, 24, 128) train_data_B (460, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter761K.wav shape: (114880,)_loss: 3.27923107\n",
      "saved file at ./samples/recon_A2A_id001_iter761K.wav shape: (114880,)\n",
      "Epoch[762]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter762K.wav shape: (49600,)g_loss: 3.50304651\n",
      "saved file at ./samples/recon_A2A_id002_iter762K.wav shape: (49600,)\n",
      "Epoch[763]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter763K.wav shape: (35840,)g_loss: 3.26384449\n",
      "saved file at ./samples/recon_A2A_id003_iter763K.wav shape: (35840,)\n",
      "Epoch[764]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter764K.wav shape: (60480,)g_loss: 3.43431282\n",
      "saved file at ./samples/recon_A2A_id004_iter764K.wav shape: (60480,)\n",
      "Epoch[765]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter765K.wav shape: (39680,)g_loss: 3.43205166\n",
      "saved file at ./samples/recon_A2A_id005_iter765K.wav shape: (39680,)\n",
      "Epoch[766]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter766K.wav shape: (98240,)g_loss: 3.45595431\n",
      "saved file at ./samples/recon_A2A_id006_iter766K.wav shape: (98240,)\n",
      "Epoch[767]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter767K.wav shape: (32640,)g_loss: 3.25685167\n",
      "saved file at ./samples/recon_A2A_id007_iter767K.wav shape: (32640,)\n",
      "Epoch[768]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter768K.wav shape: (56640,)g_loss: 3.30605054\n",
      "saved file at ./samples/recon_A2A_id008_iter768K.wav shape: (56640,)\n",
      "Epoch[769]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter769K.wav shape: (19840,)g_loss: 3.31256151\n",
      "saved file at ./samples/recon_A2A_id009_iter769K.wav shape: (19840,)\n",
      "Epoch[770]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter770K.wav shape: (40960,)g_loss: 3.28116560\n",
      "saved file at ./samples/recon_A2A_id010_iter770K.wav shape: (40960,)\n",
      "Epoch[771]: Input data sampled from 128 A and 128 B audio files: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter771K.wav shape: (45760,)g_loss: 3.48691106\n",
      "saved file at ./samples/recon_A2A_id011_iter771K.wav shape: (45760,)\n",
      "Epoch[772]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter772K.wav shape: (80640,)g_loss: 3.44768763\n",
      "saved file at ./samples/recon_A2A_id012_iter772K.wav shape: (80640,)\n",
      "Epoch[773]: Input data sampled from 128 A and 128 B audio files: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter773K.wav shape: (26880,)g_loss: 3.32192755\n",
      "saved file at ./samples/recon_A2A_id013_iter773K.wav shape: (26880,)\n",
      "Epoch[774]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter774K.wav shape: (41920,)g_loss: 3.40228748\n",
      "saved file at ./samples/recon_A2A_id014_iter774K.wav shape: (41920,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[775]: Input data sampled from 128 A and 128 B audio files: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter775K.wav shape: (83200,)g_loss: 3.54113674\n",
      "saved file at ./samples/recon_A2A_id015_iter775K.wav shape: (83200,)\n",
      "Epoch[776]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id016_iter776K.wav shape: (150400,)_loss: 3.32058191\n",
      "saved file at ./samples/recon_A2A_id016_iter776K.wav shape: (150400,)\n",
      "Epoch[777]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id017_iter777K.wav shape: (78720,)g_loss: 3.48669958\n",
      "saved file at ./samples/recon_A2A_id017_iter777K.wav shape: (78720,)\n",
      "Epoch[778]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id018_iter778K.wav shape: (303360,)_loss: 3.44839334\n",
      "saved file at ./samples/recon_A2A_id018_iter778K.wav shape: (303360,)\n",
      "Epoch[779]: Input data sampled from 128 A and 128 B audio files: train_data_A (451, 24, 128) train_data_B (451, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id000_iter779K.wav shape: (29120,)g_loss: 3.43901062\n",
      "saved file at ./samples/recon_A2A_id000_iter779K.wav shape: (29120,)\n",
      "Epoch[780]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id001_iter780K.wav shape: (114880,)_loss: 3.39958000\n",
      "saved file at ./samples/recon_A2A_id001_iter780K.wav shape: (114880,)\n",
      "Epoch[781]: Input data sampled from 128 A and 128 B audio files: train_data_A (439, 24, 128) train_data_B (439, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id002_iter781K.wav shape: (49600,)g_loss: 3.39322090\n",
      "saved file at ./samples/recon_A2A_id002_iter781K.wav shape: (49600,)\n",
      "Epoch[782]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id003_iter782K.wav shape: (35840,)g_loss: 3.36265182\n",
      "saved file at ./samples/recon_A2A_id003_iter782K.wav shape: (35840,)\n",
      "Epoch[783]: Input data sampled from 128 A and 128 B audio files: train_data_A (441, 24, 128) train_data_B (441, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id004_iter783K.wav shape: (60480,)g_loss: 3.52438307\n",
      "saved file at ./samples/recon_A2A_id004_iter783K.wav shape: (60480,)\n",
      "Epoch[784]: Input data sampled from 128 A and 128 B audio files: train_data_A (458, 24, 128) train_data_B (458, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id005_iter784K.wav shape: (39680,)g_loss: 3.28575611\n",
      "saved file at ./samples/recon_A2A_id005_iter784K.wav shape: (39680,)\n",
      "Epoch[785]: Input data sampled from 128 A and 128 B audio files: train_data_A (447, 24, 128) train_data_B (447, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id006_iter785K.wav shape: (98240,)g_loss: 3.39503336\n",
      "saved file at ./samples/recon_A2A_id006_iter785K.wav shape: (98240,)\n",
      "Epoch[786]: Input data sampled from 128 A and 128 B audio files: train_data_A (445, 24, 128) train_data_B (445, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id007_iter786K.wav shape: (32640,)g_loss: 3.44320202\n",
      "saved file at ./samples/recon_A2A_id007_iter786K.wav shape: (32640,)\n",
      "Epoch[787]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id008_iter787K.wav shape: (56640,)g_loss: 3.35019207\n",
      "saved file at ./samples/recon_A2A_id008_iter787K.wav shape: (56640,)\n",
      "Epoch[788]: Input data sampled from 128 A and 128 B audio files: train_data_A (435, 24, 128) train_data_B (435, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id009_iter788K.wav shape: (19840,)g_loss: 3.32579517\n",
      "saved file at ./samples/recon_A2A_id009_iter788K.wav shape: (19840,)\n",
      "Epoch[789]: Input data sampled from 128 A and 128 B audio files: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id010_iter789K.wav shape: (40960,)g_loss: 3.47005272\n",
      "saved file at ./samples/recon_A2A_id010_iter789K.wav shape: (40960,)\n",
      "Epoch[790]: Input data sampled from 128 A and 128 B audio files: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id011_iter790K.wav shape: (45760,)g_loss: 3.39765716\n",
      "saved file at ./samples/recon_A2A_id011_iter790K.wav shape: (45760,)\n",
      "Epoch[791]: Input data sampled from 128 A and 128 B audio files: train_data_A (455, 24, 128) train_data_B (455, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id012_iter791K.wav shape: (80640,)g_loss: 3.40997696\n",
      "saved file at ./samples/recon_A2A_id012_iter791K.wav shape: (80640,)\n",
      "Epoch[792]: Input data sampled from 128 A and 128 B audio files: train_data_A (458, 24, 128) train_data_B (458, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id013_iter792K.wav shape: (26880,)g_loss: 3.23949289\n",
      "saved file at ./samples/recon_A2A_id013_iter792K.wav shape: (26880,)\n",
      "Epoch[793]: Input data sampled from 128 A and 128 B audio files: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id014_iter793K.wav shape: (41920,)g_loss: 3.36542249\n",
      "saved file at ./samples/recon_A2A_id014_iter793K.wav shape: (41920,)\n",
      "Epoch[794]: Input data sampled from 128 A and 128 B audio files: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "saved file at ./samples/fake_A2B_id015_iter794K.wav shape: (83200,)g_loss: 3.36865926\n",
      "saved file at ./samples/recon_A2A_id015_iter794K.wav shape: (83200,)\n",
      "Epoch[795]: Input data sampled from 128 A and 128 B audio files: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "Epoch: [795] [   232/  1000] time: 161365.9896 d_loss: 0.00004911, g_loss: 3.36444688\r"
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "    gan = EmoMUNIT(sess)\n",
    "    gan.build_model()\n",
    "    gan.train()\n",
    "    gan.test()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf18_p35)",
   "language": "python",
   "name": "tf18_p35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
