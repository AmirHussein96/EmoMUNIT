{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Data: .wav -> Pitch contour (f0s), Harmonic spectral envelope (sps), Aperiodic spectral envelope (aps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from ops import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "from IPython.display import Audio\n",
    "# import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# matplotlib.rcParams['figure.figsize'] = (16, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 0\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder: Style_Encoder, Content_Encoder, MLP, Decoder, Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Style_Encoder(inputs, style_dim=16, reuse=False, scope='style_encoder'):                                                            # [1, 24, 128] = [batch_size, feature_channel, time]\n",
    "\n",
    "    inputs = tf.transpose(inputs, perm=[0, 2, 1], name='input_transpose')                                                               # [1, 128, 24] = [batch_size, time, feature_channel]\n",
    "\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "\n",
    "        h1 = conv1d_layer(inputs=inputs, filters=128, kernel_size=15, strides=1, name='h1_conv')                                        # [1, 128, 128]\n",
    "        h1_gates = conv1d_layer(inputs=inputs, filters=128, kernel_size=15, strides=1, name='h1_conv_gates')\n",
    "        h1_glu = gated_linear_layer(inputs=h1, gates=h1_gates, name='h1_glu')\n",
    "\n",
    "        # Downsample\n",
    "        d1 = downsample1d_block_withoutIN(inputs=h1_glu, filters=256, kernel_size=5, strides=2, name_prefix='downsample1d_block1')      # [1, 64, 256]\n",
    "        d2 = downsample1d_block_withoutIN(inputs=d1, filters=512, kernel_size=5, strides=2, name_prefix='downsample1d_block2')          # [1, 32, 512]\n",
    "\n",
    "        d3 = downsample1d_block_withoutIN(inputs=d2, filters=512, kernel_size=3, strides=2, name_prefix='downsample1d_block3')          # [1, 16, 512]\n",
    "        d4 = downsample1d_block_withoutIN(inputs=d3, filters=512, kernel_size=3, strides=2, name_prefix='downsample1d_block4')          # [1, 8, 512]\n",
    "\n",
    "        # Global Average Pooling\n",
    "        p1 = adaptive_avg_pooling(d4)                                                                                                   # [1, 1, 512]\n",
    "        style = conv1d_layer(inputs=p1, filters=style_dim, kernel_size=1, strides=1, name='SE_logit')                                   # [1, 1, 16]\n",
    "\n",
    "        return style                                                                                                                    # [1, 1, 16]\n",
    "\n",
    "\n",
    "def Content_Encoder(inputs, reuse=False, scope='content_encoder'):\n",
    "    # IN removes the original feature mean and variance that represent important style information\n",
    "    inputs = tf.transpose(inputs, perm=[0, 2, 1], name='input_transpose')                                                               # [1, 24, 128] = [batch_size, time, feature_channel]\n",
    "\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "\n",
    "        h1 = conv1d_layer(inputs=inputs, filters=128, kernel_size=15, strides=1, name='h1_conv')                                        # [1, 128, 128]\n",
    "        h1_norm = instance_norm_layer(inputs=h1, name='h1_norm')\n",
    "        h1_gates = conv1d_layer(inputs=inputs, filters=128, kernel_size=15, strides=1, name='h1_gates')\n",
    "        h1_norm_gates = instance_norm_layer(inputs=h1_gates, name='h1_norm_gates')\n",
    "        h1_glu = gated_linear_layer(inputs=h1_norm, gates=h1_norm_gates, name='h1_glu')\n",
    "\n",
    "        # downsample\n",
    "        d1 = downsample1d_block(inputs=h1_glu, filters=256, kernel_size=5, strides=2, name_prefix='downsample1d_block1')                # [1, 64, 256]\n",
    "        d2 = downsample1d_block(inputs=d1, filters=512, kernel_size=5, strides=2, name_prefix='downsample1d_block2')                    # [1, 32, 512]\n",
    "               \n",
    "        # Residual blocks\n",
    "        r1 = residual1d_block(inputs=d2, filters = 512, kernel_size=3, strides=1, name_prefix='residual1d_block1')                      # [1, 32, 512]\n",
    "        r2 = residual1d_block(inputs=r1, filters = 512, kernel_size=3, strides=1, name_prefix='residual1d_block2')\n",
    "        r3 = residual1d_block(inputs=r2, filters = 512, kernel_size=3, strides=1, name_prefix='residual1d_block3')\n",
    "        content = residual1d_block(inputs=r3, filters=512, kernel_size=3, strides=1, name_prefix='residual1d_block4')\n",
    "\n",
    "        return content                                                                                                                  # [1, 32, 512]\n",
    "\n",
    "\n",
    "def MLP(style, reuse=False, scope='MLP'):                                                                                               # [1, 1, 16]\n",
    "\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "\n",
    "        x1 = linear(style, 512, scope='linear_1')                                                                                       # [1, 1, 512]\n",
    "        x1_gates = linear(x1, 512, scope='linear_1_gates')\n",
    "        x1_glu = gated_linear_layer(inputs=x1, gates=x1_gates, name='x1_glu')\n",
    "\n",
    "        x2 = linear(x1_glu, 512, scope='linear_2')\n",
    "        x2_gates = linear(x2, 512, scope='linear_2_gates')\n",
    "        x2_glu = gated_linear_layer(inputs=x2, gates=x2_gates, name='x2_glu')\n",
    "\n",
    "        mu = linear(x2_glu, 512, scope='mu')\n",
    "        sigma = linear(x2_glu, 512, scope='sigma')\n",
    "\n",
    "        mu = tf.reshape(mu, shape=[-1, 1, 512])                                                                                         # [1, 1, 512]\n",
    "        sigma = tf.reshape(sigma, shape=[-1, 1, 512])                                                                                   # [1, 1, 512]\n",
    "\n",
    "        return mu, sigma                                                                                                                # [1, 1, 512]\n",
    "\n",
    "\n",
    "def Decoder(content, style, reuse=False, scope=\"decoder\"):\n",
    "\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "\n",
    "        mu, sigma = MLP(style, reuse)                                                                                                   # [1, 1, 512]\n",
    "        x = content                                                                                                                     # [1, 32, 512]\n",
    "\n",
    "        # Adaptive Residual blocks\n",
    "        r1 = residual1d_block_adaptive(inputs=x, filters=512, mu=mu, sigma=sigma, kernel_size=3, strides=1, name_prefix='residual1d_block1')        # [1, 32, 512]\n",
    "        r2 = residual1d_block_adaptive(inputs=r1, filters=512, mu=mu, sigma=sigma, kernel_size=3, strides=1, name_prefix='residual1d_block2')\n",
    "        r3 = residual1d_block_adaptive(inputs=r2, filters=512, mu=mu, sigma=sigma, kernel_size=3, strides=1, name_prefix='residual1d_block3')\n",
    "\n",
    "        # Upsample\n",
    "        u1 = upsample1d_block(inputs=r3, filters=512, kernel_size=5, strides=1, shuffle_size=2, name_prefix='upsample1d_block1')        # [1, 64, 512]\n",
    "        u2 = upsample1d_block(inputs=u1, filters=256, kernel_size=5, strides=1, shuffle_size=2, name_prefix='upsample1d_block2')        # [1, 128, 256]\n",
    "\n",
    "        # Output\n",
    "        o1 = conv1d_layer(inputs=u2, filters=24, kernel_size=15, strides=1, name='o1_conv')                                             # [1, 128, 24]\n",
    "        o2 = tf.transpose(o1, perm=[0, 2, 1], name='output_transpose')                                                                  # [1, 24, 128]\n",
    "\n",
    "        return o2                                                                                                                       # [1, 24, 128] = [batch_size, feature_channel, time]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Discriminator(inputs, reuse=False, scope='discriminator'):\n",
    "\n",
    "    # inputs = [batch_size, num_features, time]\n",
    "    # add channel for 2D convolution [batch_size, num_features, time, 1]\n",
    "    inputs = tf.expand_dims(inputs, -1)                                                                                                 # [1, 24, 128, 1]\n",
    "\n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "\n",
    "        h1 = conv2d_layer(inputs=inputs, filters=128, kernel_size=[3, 3], strides=[1, 2], name='h1_conv')                               # [1, 24, 64, 128]\n",
    "        h1_gates = conv2d_layer(inputs=inputs, filters=128, kernel_size=[3, 3], strides=[1, 2], name='h1_conv_gates')\n",
    "        h1_glu = gated_linear_layer(inputs=h1, gates=h1_gates, name='h1_glu')\n",
    "\n",
    "        # Downsample\n",
    "        d1 = downsample2d_block(inputs=h1_glu, filters=256, kernel_size=[3, 3], strides=[2, 2], name_prefix='downsample2d_block1')      # [1, 12, 32, 256]\n",
    "        d2 = downsample2d_block(inputs=d1, filters=512, kernel_size=[3, 3], strides=[2, 2], name_prefix='downsample2d_block2')          # [1, 6, 16, 512]\n",
    "        d3 = downsample2d_block(inputs=d2, filters=1024, kernel_size=[6, 3], strides=[1, 2], name_prefix='downsample2d_block3')         # [1, 6, 8, 1024]\n",
    "\n",
    "        # Output\n",
    "        o1 = tf.layers.dense(inputs=d3, units=1, activation=tf.nn.sigmoid)\n",
    "\n",
    "        return [o1]                                                                                                                       # [1, 6, 8, 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# Model\n",
    "##################################################################################\n",
    "\n",
    "def Encoder_A(x_A, reuse=False):\n",
    "    style_A = Style_Encoder(x_A, reuse=reuse, scope='style_encoder_A')\n",
    "    content_A = Content_Encoder(x_A, reuse=reuse, scope='content_encoder_A')\n",
    "\n",
    "    return content_A, style_A\n",
    "\n",
    "def Encoder_B(x_B, reuse=False):\n",
    "    style_B = Style_Encoder(x_B, reuse=reuse, scope='style_encoder_B')\n",
    "    content_B = Content_Encoder(x_B, reuse=reuse, scope='content_encoder_B')\n",
    "\n",
    "    return content_B, style_B\n",
    "\n",
    "def Decoder_A(content_B, style_A, reuse=False):\n",
    "    x_ba = Decoder(content=content_B, style=style_A, reuse=reuse, scope='decoder_A')\n",
    "\n",
    "    return x_ba\n",
    "\n",
    "def Decoder_B(content_A, style_B, reuse=False):\n",
    "    x_ab = Decoder(content=content_A, style=style_B, reuse=reuse, scope='decoder_B')\n",
    "\n",
    "    return x_ab\n",
    "\n",
    "def discriminate_real(x_A, x_B):\n",
    "    real_A_logit = Discriminator(x_A, scope=\"discriminator_A\")\n",
    "    real_B_logit = Discriminator(x_B, scope=\"discriminator_B\")\n",
    "\n",
    "    return real_A_logit, real_B_logit\n",
    "\n",
    "def discriminate_fake(x_ba, x_ab):\n",
    "    fake_A_logit = Discriminator(x_ba, reuse=True, scope=\"discriminator_A\")\n",
    "    fake_B_logit = Discriminator(x_ab, reuse=True, scope=\"discriminator_B\")\n",
    "\n",
    "    return fake_A_logit, fake_B_logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module: EmoMUNIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmoMUNIT(object):\n",
    "    def __init__(self, sess):\n",
    "        \n",
    "        self.train_A_dir = './../../../Database/Emotion/hap_neu/hap'\n",
    "        self.train_B_dir = './../../../Database/Emotion/hap_neu/neu'\n",
    "        self.validation_A_dir = './../../../Database/Emotion/hap_neu/val_hap'\n",
    "        self.validation_B_dir = './../../../Database/Emotion/hap_neu/val_neu'\n",
    "#         self.max_samples = 1000\n",
    "        \n",
    "        self.batch_size = 1\n",
    "        self.style_dim = 16\n",
    "        \n",
    "        self.Encoder_A = Encoder_A\n",
    "        self.Encoder_B = Encoder_B\n",
    "        self.Decoder_A = Decoder_A\n",
    "        self.Decoder_B = Decoder_B\n",
    "        self.discriminate_real = discriminate_real\n",
    "        self.discriminate_fake = discriminate_fake\n",
    "        \n",
    "        self.recon_x_cyc_w = 0.0\n",
    "        self.gan_type = 'lsgan'\n",
    "        \n",
    "        self.gan_w = 1.0\n",
    "        \n",
    "        self.recon_x_w = 10.0\n",
    "        self.recon_s_w = 1.0\n",
    "        self.recon_c_w = 1.0\n",
    "        self.recon_x_cyc_w = 0.0\n",
    "               \n",
    "        self.audio_len = 128    # = n_frames, time_length\n",
    "        self.audio_ch = 24      # = num_mcep, num_features\n",
    "        \n",
    "        self.direction = 'A2B'\n",
    "        \n",
    "        self.model_name = 'EmoMUNIT'\n",
    "        self.gan_type = 'lsgan'\n",
    "        self.dataset_name = 'hap2neu'\n",
    "        self.log_dir = 'logs'\n",
    "        self.sample_dir = 'samples'\n",
    "        self.checkpoint_dir = 'checkpoint'\n",
    "        self.iteration = 20000\n",
    "        \n",
    "        self.sess = sess\n",
    "        self.epoch = 50\n",
    "        self.init_lr_D = 0.00005\n",
    "        self.init_lr_G = 0.0001\n",
    "        \n",
    "        self.print_freq = 1000\n",
    "        self.save_freq = 1000\n",
    "        \n",
    "    \n",
    "    def build_model(self):\n",
    "        self.lr_D = tf.placeholder(tf.float32, name='learning_rate_D')\n",
    "        self.lr_G = tf.placeholder(tf.float32, name='learning_rate_G')\n",
    "        \n",
    "        # Iterate from train_data_A and train_data_A\n",
    "        self.domain_A = tf.placeholder(tf.float32, shape=[self.batch_size, self.audio_ch, self.audio_len], name='domain_a')\n",
    "        self.domain_B = tf.placeholder(tf.float32, shape=[self.batch_size, self.audio_ch, self.audio_len], name='domain_b')\n",
    "    \n",
    "        self.style_a = tf.placeholder(tf.float32, shape=[self.batch_size, 1, self.style_dim], name='style_a')\n",
    "        self.style_b = tf.placeholder(tf.float32, shape=[self.batch_size, 1, self.style_dim], name='style_b')  \n",
    "    \n",
    "        # encode\n",
    "        content_a, style_a_prime = self.Encoder_A(self.domain_A)\n",
    "        content_b, style_b_prime = self.Encoder_B(self.domain_B)\n",
    "\n",
    "        # decode (within domain)\n",
    "        x_aa = self.Decoder_A(content_B=content_a, style_A=style_a_prime)\n",
    "        x_bb = self.Decoder_B(content_A=content_b, style_B=style_b_prime)\n",
    "    \n",
    "        # decode (cross domain)\n",
    "        x_ba = self.Decoder_A(content_B=content_b, style_A=self.style_a, reuse=True)\n",
    "        x_ab = self.Decoder_B(content_A=content_a, style_B=self.style_b, reuse=True)   \n",
    "    \n",
    "        # encode again\n",
    "        content_b_, style_a_ = self.Encoder_A(x_ba, reuse=True)\n",
    "        content_a_, style_b_ = self.Encoder_B(x_ab, reuse=True)    \n",
    "    \n",
    "        # decode again (if needed)\n",
    "        if self.recon_x_cyc_w > 0 :\n",
    "            x_aba = self.Decoder_A(content_B=content_a_, style_A=style_a_prime, reuse=True)\n",
    "            x_bab = self.Decoder_B(content_A=content_b_, style_B=style_b_prime, reuse=True)\n",
    "\n",
    "            cyc_recon_A = L1_loss(x_aba, self.domain_A)\n",
    "            cyc_recon_B = L1_loss(x_bab, self.domain_B)\n",
    "\n",
    "        else :\n",
    "            cyc_recon_A = 0.0\n",
    "            cyc_recon_B = 0.0    \n",
    "      \n",
    "        real_A_logit, real_B_logit = self.discriminate_real(self.domain_A, self.domain_B)\n",
    "        fake_A_logit, fake_B_logit = self.discriminate_fake(x_ba, x_ab)   \n",
    "    \n",
    "    \n",
    "        \"\"\" Define Loss \"\"\"\n",
    "        # Adversarial Loss\n",
    "        G_ad_loss_a = generator_loss(self.gan_type, fake_A_logit)\n",
    "        G_ad_loss_b = generator_loss(self.gan_type, fake_B_logit)\n",
    "    \n",
    "        # Discrimination Loss (real/fake)\n",
    "        D_ad_loss_a = discriminator_loss(self.gan_type, real_A_logit, fake_A_logit)\n",
    "        D_ad_loss_b = discriminator_loss(self.gan_type, real_B_logit, fake_B_logit)\n",
    "    \n",
    "        # Reconstruction Loss\n",
    "        recon_A = L1_loss(x_aa, self.domain_A) # reconstruction\n",
    "        recon_B = L1_loss(x_bb, self.domain_B) # reconstruction   \n",
    "    \n",
    "        # Semi-CycleGAN Loss\n",
    "        # For style, encourages diverse outputs given different style codes\n",
    "        recon_style_A = L1_loss(style_a_, self.style_a)\n",
    "        recon_style_B = L1_loss(style_b_, self.style_b)\n",
    "    \n",
    "        # For content, encourages the translated image to preserve semantic content of the input image\n",
    "        recon_content_A = L1_loss(content_a_, content_a)\n",
    "        recon_content_B = L1_loss(content_b_, content_b)   \n",
    "    \n",
    "        # Attacker Loss\n",
    "        Generator_A_loss = self.gan_w * G_ad_loss_a + \\\n",
    "                                   self.recon_x_w * recon_A + \\\n",
    "                                   self.recon_s_w * recon_style_A + \\\n",
    "                                   self.recon_c_w * recon_content_A + \\\n",
    "                                   self.recon_x_cyc_w * cyc_recon_A\n",
    "\n",
    "        Generator_B_loss = self.gan_w * G_ad_loss_b + \\\n",
    "                           self.recon_x_w * recon_B + \\\n",
    "                           self.recon_s_w * recon_style_B + \\\n",
    "                           self.recon_c_w * recon_content_B + \\\n",
    "                           self.recon_x_cyc_w * cyc_recon_B   \n",
    "    \n",
    "        # Defender Loss\n",
    "        Discriminator_A_loss = self.gan_w * D_ad_loss_a\n",
    "        Discriminator_B_loss = self.gan_w * D_ad_loss_b\n",
    "    \n",
    "        # Total Loss\n",
    "        self.Generator_loss = Generator_A_loss + Generator_B_loss\n",
    "        self.Discriminator_loss = Discriminator_A_loss + Discriminator_B_loss\n",
    "    \n",
    "    \n",
    "        \"\"\" Training Variables \"\"\"\n",
    "        t_vars = tf.trainable_variables()\n",
    "        G_vars = [var for var in t_vars if 'decoder' in var.name or 'encoder' in var.name]\n",
    "        D_vars = [var for var in t_vars if 'discriminator' in var.name]\n",
    "    \n",
    "        self.G_optim = tf.train.AdamOptimizer(self.lr_G, beta1=0.5, beta2=0.999).minimize(self.Generator_loss, var_list=G_vars)\n",
    "        self.D_optim = tf.train.AdamOptimizer(self.lr_D, beta1=0.5, beta2=0.999).minimize(self.Discriminator_loss, var_list=D_vars)\n",
    "    \n",
    "        \"\"\"\" Summary \"\"\"\n",
    "        self.all_G_loss = tf.summary.scalar(\"Generator_loss\", self.Generator_loss)\n",
    "        self.all_D_loss = tf.summary.scalar(\"Discriminator_loss\", self.Discriminator_loss)\n",
    "        self.R_A_loss = tf.summary.scalar(\"Reconstruction_A_loss\", recon_A)\n",
    "        self.R_B_loss = tf.summary.scalar(\"Reconstruction_B_loss\", recon_B)\n",
    "        self.G_A_loss = tf.summary.scalar(\"G_A_loss\", Generator_A_loss)\n",
    "        self.G_B_loss = tf.summary.scalar(\"G_B_loss\", Generator_B_loss)\n",
    "        self.D_A_loss = tf.summary.scalar(\"D_A_loss\", Discriminator_A_loss)\n",
    "        self.D_B_loss = tf.summary.scalar(\"D_B_loss\", Discriminator_B_loss)\n",
    "\n",
    "        self.G_loss = tf.summary.merge([self.R_A_loss, self.R_B_loss, self.G_A_loss, self.G_B_loss, self.all_G_loss])\n",
    "        self.D_loss = tf.summary.merge([self.D_A_loss, self.D_B_loss, self.all_D_loss])\n",
    "    \n",
    "    \n",
    "        \"\"\" Speech: real and fake \"\"\"\n",
    "        self.real_A = self.domain_A\n",
    "        self.real_B = self.domain_B\n",
    "\n",
    "        self.fake_A = x_ba\n",
    "        self.fake_B = x_ab \n",
    "    \n",
    "        \"\"\" Test Variables \"\"\"\n",
    "        self.test_audio = tf.placeholder(tf.float32, [1, self.audio_ch, self.audio_len], name='test_audio') # [1 24 128]\n",
    "        self.test_style = tf.placeholder(tf.float32, [1, 1, self.style_dim], name='test_style')             # [1 1 16]\n",
    "\n",
    "        test_content_a, _ = self.Encoder_A(self.test_audio, reuse=True)\n",
    "        test_content_b, _ = self.Encoder_B(self.test_audio, reuse=True)\n",
    "\n",
    "        self.test_fake_A = self.Decoder_A(content_B=test_content_b, style_A=self.test_style, reuse=True)\n",
    "        self.test_fake_B = self.Decoder_B(content_A=test_content_a, style_B=self.test_style, reuse=True)\n",
    "\n",
    "        \"\"\" Guided Speech Translation \"\"\"\n",
    "        self.content_audio = tf.placeholder(tf.float32, [1, self.audio_ch, self.audio_len], name='content_audio')\n",
    "        self.style_audio = tf.placeholder(tf.float32, [1, self.audio_ch, self.audio_len], name='guide_style_audio_ch')\n",
    "\n",
    "        if self.direction == 'A2B' :\n",
    "            guide_content_A, guide_style_A = self.Encoder_A(self.content_audio, reuse=True)\n",
    "            guide_content_B, guide_style_B = self.Encoder_B(self.style_audio, reuse=True)\n",
    "\n",
    "        else :\n",
    "            guide_content_B, guide_style_B = self.Encoder_B(self.content_audio, reuse=True)\n",
    "            guide_content_A, guide_style_A = self.Encoder_A(self.style_audio, reuse=True)\n",
    "\n",
    "        self.guide_fake_A = self.Decoder_A(content_B=guide_content_B, style_A=guide_style_A, reuse=True)\n",
    "        self.guide_fake_B = self.Decoder_B(content_A=guide_content_A, style_B=guide_style_B, reuse=True)\n",
    "    \n",
    "    \n",
    "    def data_prepare(self, f0s_A, f0s_B, coded_sps_norm_A, coded_sps_norm_B):\n",
    "        \n",
    "        train_data_A = sample_train_data03(sps=list(coded_sps_norm_A), f0s=list(f0s_A), n_frames=self.audio_len)\n",
    "        train_data_B = sample_train_data03(sps=list(coded_sps_norm_B), f0s=list(f0s_B), n_frames=self.audio_len)\n",
    "\n",
    "        minlen = min(len(train_data_A), len(train_data_B))\n",
    "        np.random.shuffle(train_data_A)\n",
    "        np.random.shuffle(train_data_B)\n",
    "        train_data_A = np.array(train_data_A[0:minlen])\n",
    "        train_data_B = np.array(train_data_B[0:minlen])\n",
    "\n",
    "        return train_data_A, train_data_B\n",
    "    \n",
    "    \n",
    "    def train(self):\n",
    "        # initialize all variables\n",
    "        tf.global_variables_initializer().run()\n",
    "        \n",
    "        # saver to save model\n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "        # summary writer\n",
    "        self.writer = tf.summary.FileWriter(self.log_dir + '/' + self.model_dir, self.sess.graph)\n",
    "        \n",
    "        # restore check-point if it exits\n",
    "        could_load, checkpoint_counter = self.load(self.checkpoint_dir)\n",
    "        if could_load:\n",
    "            start_epoch = (int)(checkpoint_counter / self.iteration)\n",
    "            start_batch_id = checkpoint_counter - start_epoch * self.iteration\n",
    "            counter = checkpoint_counter\n",
    "            print(\" [*] Load SUCCESS\")\n",
    "        else:\n",
    "            start_epoch = 0\n",
    "            start_batch_id = 0\n",
    "            counter = 1\n",
    "            print(\" [!] Load FAILED...\")\n",
    "            \n",
    "        # Training loop for epoch\n",
    "        \n",
    "        # load data and extract features\n",
    "        f0s_A, coded_sps_norm_A, _, _ = vocoder_extract(self.train_A_dir)\n",
    "        f0s_B, coded_sps_norm_B, _, _ = vocoder_extract(self.train_B_dir)\n",
    "\n",
    "        start_time = time.time()\n",
    "        for epoch in range(start_epoch, self.epoch):\n",
    "            \n",
    "            train_data_A, train_data_B = self.data_prepare(f0s_A, f0s_B, coded_sps_norm_A, coded_sps_norm_B)\n",
    "            print('Epoch[%d]: Input data sampled: train_data_A' %epoch, np.shape(train_data_A), 'train_data_B', np.shape(train_data_B))\n",
    "\n",
    "            lr_D, lr_G = self.init_lr_D * pow(0.9, epoch), self.init_lr_G * pow(0.9, epoch)\n",
    "            for idx in range(start_batch_id, self.iteration):\n",
    "                style_a = np.random.normal(loc=0.0, scale=1.0, size=[self.batch_size, 1, self.style_dim])\n",
    "                style_b = np.random.normal(loc=0.0, scale=1.0, size=[self.batch_size, 1, self.style_dim])\n",
    "                \n",
    "                idx_A = idx%len(train_data_A)\n",
    "                idx_B = idx%len(train_data_B)\n",
    "                domain_A = train_data_A[idx_A:idx_A+1].astype('float32')\n",
    "                domain_B = train_data_B[idx_B:idx_B+1].astype('float32')\n",
    "                \n",
    "                train_feed_dict = {\n",
    "                    self.style_a : style_a,\n",
    "                    self.style_b : style_b,\n",
    "                    self.lr_D : lr_D,\n",
    "                    self.lr_G : lr_G,\n",
    "                    self.domain_A : domain_A,\n",
    "                    self.domain_B : domain_B\n",
    "                }\n",
    "                \n",
    "                # Update D\n",
    "                _, d_loss, summary_str = self.sess.run([self.D_optim, self.Discriminator_loss, self.D_loss], feed_dict = train_feed_dict)\n",
    "                self.writer.add_summary(summary_str, counter)\n",
    "            \n",
    "                # Update G\n",
    "                batch_A_audios, batch_B_audios, fake_A, fake_B, _, g_loss, summary_str = \\\n",
    "                self.sess.run([self.real_A, self.real_B, self.fake_A, self.fake_B, self.G_optim, \\\n",
    "                               self.Generator_loss, self.G_loss], feed_dict = train_feed_dict)\n",
    "                self.writer.add_summary(summary_str, counter)           \n",
    "            \n",
    "                # display training status\n",
    "                counter += 1\n",
    "                print(\"Epoch: [%2d] [%6d/%6d] time: %4.4f d_loss: %.8f, g_loss: %.8f\" \\\n",
    "                      % (epoch, idx, self.iteration, time.time() - start_time, d_loss, g_loss), end='\\r')\n",
    "            \n",
    "                # save test samples\n",
    "                if np.mod(idx+1, self.print_freq) == 0 :\n",
    "                    save_audios(batch_A_audios, self.batch_size,\n",
    "                                './{}/real_A_{:02d}_{:06d}.npy'.format(self.sample_dir, epoch, idx+1))\n",
    "                    # save_audios(batch_B_audios, self.batch_size,\n",
    "                    #             './{}/real_B_{}_{:02d}_{:06d}.jpg'.format(self.sample_dir, gpu_id, epoch, idx+1))\n",
    "\n",
    "                    # save_audios(fake_A, self.batch_size,\n",
    "                    #             './{}/fake_A_{}_{:02d}_{:06d}.jpg'.format(self.sample_dir, gpu_id, epoch, idx+1))\n",
    "                    save_audios(fake_B, self.batch_size,\n",
    "                                './{}/fake_B_{:02d}_{:06d}.npy'.format(self.sample_dir, epoch, idx+1))          \n",
    "                \n",
    "                # save checkpoints\n",
    "                if np.mod(idx+1, self.save_freq) == 0 :\n",
    "                    self.save(self.checkpoint_dir, counter)\n",
    "        \n",
    "            # After an epoch, start_batch_id reset to zero\n",
    "            # non-zero value is only for the first epoch after loading pre-trained model\n",
    "            start_batch_id = 0\n",
    "\n",
    "            # save model for final step\n",
    "            self.save(self.checkpoint_dir, counter)     \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def model_dir(self):\n",
    "        return \"{}_{}_{}\".format(self.model_name, self.dataset_name, self.gan_type)\n",
    "    \n",
    "    \n",
    "    def load(self, checkpoint_dir):\n",
    "        import re\n",
    "        print(\" [*] Reading checkpoints...\")\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir)\n",
    "\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            ckpt_name = os.path.basename(ckpt.model_checkpoint_path)\n",
    "            self.saver.restore(self.sess, os.path.join(checkpoint_dir, ckpt_name))\n",
    "            counter = int(next(re.finditer(\"(\\d+)(?!.*\\d)\", ckpt_name)).group(0))\n",
    "            print(\" [*] Success to read {}\".format(ckpt_name))\n",
    "            return True, counter\n",
    "        else:\n",
    "            print(\" [*] Failed to find a checkpoint\")\n",
    "            return False, 0\n",
    "        \n",
    "        \n",
    "    def save(self, checkpoint_dir, step):\n",
    "        checkpoint_dir = os.path.join(checkpoint_dir, self.model_dir)\n",
    "\n",
    "        if not os.path.exists(checkpoint_dir):\n",
    "            os.makedirs(checkpoint_dir)\n",
    "\n",
    "        self.saver.save(self.sess, os.path.join(checkpoint_dir, self.model_name + '.model'), global_step=step)        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Reading checkpoints...\n",
      " [*] Failed to find a checkpoint\n",
      " [!] Load FAILED...\n",
      "Epoch[0]: Input data sampled: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "(1, 24, 128) 1 ./samples/real_A_00_001000.npyloss: 0.52079773, g_loss: 17.05785370\n",
      "(1, 24, 128) 1 ./samples/fake_B_00_001000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_00_002000.npyloss: 0.43401369, g_loss: 12.97855186\n",
      "(1, 24, 128) 1 ./samples/fake_B_00_002000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_00_003000.npyloss: 0.41837150, g_loss: 10.11990547\n",
      "(1, 24, 128) 1 ./samples/fake_B_00_003000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_00_004000.npyloss: 0.30584782, g_loss: 11.65747643\n",
      "(1, 24, 128) 1 ./samples/fake_B_00_004000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_00_005000.npyloss: 0.22571598, g_loss: 9.112387662\n",
      "(1, 24, 128) 1 ./samples/fake_B_00_005000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_00_006000.npy_loss: 0.13693696, g_loss: 8.819551479\n",
      "(1, 24, 128) 1 ./samples/fake_B_00_006000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_00_007000.npy_loss: 0.16873707, g_loss: 8.972522740\n",
      "(1, 24, 128) 1 ./samples/fake_B_00_007000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_00_008000.npy_loss: 0.13301921, g_loss: 7.865802762\n",
      "(1, 24, 128) 1 ./samples/fake_B_00_008000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_00_009000.npy_loss: 0.07975115, g_loss: 7.74781609\n",
      "(1, 24, 128) 1 ./samples/fake_B_00_009000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_00_010000.npy_loss: 0.07694603, g_loss: 8.379035008\n",
      "(1, 24, 128) 1 ./samples/fake_B_00_010000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_00_011000.npy_loss: 0.07078064, g_loss: 7.61085796\n",
      "(1, 24, 128) 1 ./samples/fake_B_00_011000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_00_012000.npy_loss: 0.04137114, g_loss: 7.31811333\n",
      "(1, 24, 128) 1 ./samples/fake_B_00_012000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_00_013000.npy_loss: 0.01783944, g_loss: 7.07983971\n",
      "(1, 24, 128) 1 ./samples/fake_B_00_013000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_00_014000.npy_loss: 0.01740277, g_loss: 7.08687925\n",
      "(1, 24, 128) 1 ./samples/fake_B_00_014000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_00_015000.npy_loss: 0.02123396, g_loss: 7.01799583\n",
      "(1, 24, 128) 1 ./samples/fake_B_00_015000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_00_016000.npy_loss: 0.01517509, g_loss: 6.44270182\n",
      "(1, 24, 128) 1 ./samples/fake_B_00_016000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_00_017000.npy_loss: 0.03139056, g_loss: 6.09214067\n",
      "(1, 24, 128) 1 ./samples/fake_B_00_017000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_00_018000.npy_loss: 0.01559275, g_loss: 5.86846638\n",
      "(1, 24, 128) 1 ./samples/fake_B_00_018000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_00_019000.npy_loss: 0.01093465, g_loss: 6.31752253\n",
      "(1, 24, 128) 1 ./samples/fake_B_00_019000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_00_020000.npy_loss: 0.00986418, g_loss: 5.59329605\n",
      "(1, 24, 128) 1 ./samples/fake_B_00_020000.npy\n",
      "Epoch[1]: Input data sampled: train_data_A (453, 24, 128) train_data_B (453, 24, 128)\n",
      "(1, 24, 128) 1 ./samples/real_A_01_001000.npy_loss: 0.60293478, g_loss: 5.908000475\n",
      "(1, 24, 128) 1 ./samples/fake_B_01_001000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_01_002000.npy_loss: 0.56354022, g_loss: 6.40517998\n",
      "(1, 24, 128) 1 ./samples/fake_B_01_002000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_01_003000.npy_loss: 0.53843158, g_loss: 6.78990984\n",
      "(1, 24, 128) 1 ./samples/fake_B_01_003000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_01_004000.npy_loss: 0.33578908, g_loss: 6.09122753\n",
      "(1, 24, 128) 1 ./samples/fake_B_01_004000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_01_005000.npy_loss: 0.18849269, g_loss: 5.29790306\n",
      "(1, 24, 128) 1 ./samples/fake_B_01_005000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_01_006000.npy_loss: 0.18416859, g_loss: 5.58707905\n",
      "(1, 24, 128) 1 ./samples/fake_B_01_006000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_01_007000.npy_loss: 0.24735084, g_loss: 5.46380997\n",
      "(1, 24, 128) 1 ./samples/fake_B_01_007000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_01_008000.npy_loss: 0.22051473, g_loss: 5.39709568\n",
      "(1, 24, 128) 1 ./samples/fake_B_01_008000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_01_009000.npy_loss: 0.13402927, g_loss: 5.04689026\n",
      "(1, 24, 128) 1 ./samples/fake_B_01_009000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_01_010000.npy_loss: 0.12301916, g_loss: 5.17489958\n",
      "(1, 24, 128) 1 ./samples/fake_B_01_010000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_01_011000.npy_loss: 0.07079190, g_loss: 5.01319313\n",
      "(1, 24, 128) 1 ./samples/fake_B_01_011000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_01_012000.npy_loss: 0.07496884, g_loss: 5.48658562\n",
      "(1, 24, 128) 1 ./samples/fake_B_01_012000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_01_013000.npy_loss: 0.07006849, g_loss: 4.99714661\n",
      "(1, 24, 128) 1 ./samples/fake_B_01_013000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_01_014000.npy_loss: 0.03021265, g_loss: 4.87882710\n",
      "(1, 24, 128) 1 ./samples/fake_B_01_014000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_01_015000.npy_loss: 0.04190471, g_loss: 4.72789621\n",
      "(1, 24, 128) 1 ./samples/fake_B_01_015000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_01_016000.npy_loss: 0.17418098, g_loss: 4.22200108\n",
      "(1, 24, 128) 1 ./samples/fake_B_01_016000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_01_017000.npy_loss: 0.02284873, g_loss: 5.02084494\n",
      "(1, 24, 128) 1 ./samples/fake_B_01_017000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_01_018000.npy_loss: 0.03251602, g_loss: 5.07378292\n",
      "(1, 24, 128) 1 ./samples/fake_B_01_018000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_01_019000.npy_loss: 0.02033841, g_loss: 4.74643707\n",
      "(1, 24, 128) 1 ./samples/fake_B_01_019000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_01_020000.npy_loss: 0.05269423, g_loss: 4.55781364\n",
      "(1, 24, 128) 1 ./samples/fake_B_01_020000.npy\n",
      "Epoch[2]: Input data sampled: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "(1, 24, 128) 1 ./samples/real_A_02_001000.npy_loss: 0.71473527, g_loss: 5.75604916\n",
      "(1, 24, 128) 1 ./samples/fake_B_02_001000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_02_002000.npy_loss: 0.64684451, g_loss: 5.04221630\n",
      "(1, 24, 128) 1 ./samples/fake_B_02_002000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_02_003000.npy_loss: 0.68186826, g_loss: 5.37750340\n",
      "(1, 24, 128) 1 ./samples/fake_B_02_003000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_02_004000.npy_loss: 0.56026214, g_loss: 5.17641640\n",
      "(1, 24, 128) 1 ./samples/fake_B_02_004000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_02_005000.npy_loss: 0.45681724, g_loss: 4.72113514\n",
      "(1, 24, 128) 1 ./samples/fake_B_02_005000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_02_006000.npy_loss: 0.43996960, g_loss: 4.99873924\n",
      "(1, 24, 128) 1 ./samples/fake_B_02_006000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_02_007000.npy_loss: 0.32292956, g_loss: 4.89523840\n",
      "(1, 24, 128) 1 ./samples/fake_B_02_007000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_02_008000.npy_loss: 0.33530751, g_loss: 4.53274918\n",
      "(1, 24, 128) 1 ./samples/fake_B_02_008000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_02_009000.npy_loss: 0.18957207, g_loss: 4.80877876\n",
      "(1, 24, 128) 1 ./samples/fake_B_02_009000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_02_010000.npy_loss: 0.28935838, g_loss: 4.31713200\n",
      "(1, 24, 128) 1 ./samples/fake_B_02_010000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_02_011000.npy_loss: 0.22078706, g_loss: 4.50697279\n",
      "(1, 24, 128) 1 ./samples/fake_B_02_011000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_02_012000.npyd_loss: 0.16656305, g_loss: 4.73962402\n",
      "(1, 24, 128) 1 ./samples/fake_B_02_012000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_02_013000.npyd_loss: 0.34639025, g_loss: 4.33053684\n",
      "(1, 24, 128) 1 ./samples/fake_B_02_013000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_02_014000.npyd_loss: 0.16894513, g_loss: 4.37311220\n",
      "(1, 24, 128) 1 ./samples/fake_B_02_014000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_02_015000.npyd_loss: 0.20364110, g_loss: 4.54364681\n",
      "(1, 24, 128) 1 ./samples/fake_B_02_015000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_02_016000.npyd_loss: 0.23190436, g_loss: 4.45688677\n",
      "(1, 24, 128) 1 ./samples/fake_B_02_016000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_02_017000.npyd_loss: 0.17751887, g_loss: 4.26159382\n",
      "(1, 24, 128) 1 ./samples/fake_B_02_017000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_02_018000.npyd_loss: 0.14660181, g_loss: 4.31232595\n",
      "(1, 24, 128) 1 ./samples/fake_B_02_018000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_02_019000.npyd_loss: 0.14803371, g_loss: 4.25331974\n",
      "(1, 24, 128) 1 ./samples/fake_B_02_019000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_02_020000.npyd_loss: 0.16760956, g_loss: 4.19295168\n",
      "(1, 24, 128) 1 ./samples/fake_B_02_020000.npy\n",
      "Epoch[3]: Input data sampled: train_data_A (454, 24, 128) train_data_B (454, 24, 128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 128) 1 ./samples/real_A_03_001000.npyd_loss: 0.81016952, g_loss: 4.37146807\n",
      "(1, 24, 128) 1 ./samples/fake_B_03_001000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_03_002000.npyd_loss: 0.73499191, g_loss: 5.28807449\n",
      "(1, 24, 128) 1 ./samples/fake_B_03_002000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_03_003000.npyd_loss: 0.74210644, g_loss: 4.08297920\n",
      "(1, 24, 128) 1 ./samples/fake_B_03_003000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_03_004000.npyd_loss: 0.59223449, g_loss: 4.62502193\n",
      "(1, 24, 128) 1 ./samples/fake_B_03_004000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_03_005000.npyd_loss: 0.40071756, g_loss: 4.60881662\n",
      "(1, 24, 128) 1 ./samples/fake_B_03_005000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_03_006000.npyd_loss: 0.60530007, g_loss: 4.81195784\n",
      "(1, 24, 128) 1 ./samples/fake_B_03_006000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_03_007000.npyd_loss: 0.47903386, g_loss: 4.67255020\n",
      "(1, 24, 128) 1 ./samples/fake_B_03_007000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_03_008000.npyd_loss: 0.34854239, g_loss: 4.34105921\n",
      "(1, 24, 128) 1 ./samples/fake_B_03_008000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_03_009000.npyd_loss: 0.47933948, g_loss: 4.17853832\n",
      "(1, 24, 128) 1 ./samples/fake_B_03_009000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_03_010000.npyd_loss: 0.31826490, g_loss: 4.13229275\n",
      "(1, 24, 128) 1 ./samples/fake_B_03_010000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_03_011000.npyd_loss: 0.42205232, g_loss: 4.20055294\n",
      "(1, 24, 128) 1 ./samples/fake_B_03_011000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_03_012000.npyd_loss: 0.28258967, g_loss: 4.21130514\n",
      "(1, 24, 128) 1 ./samples/fake_B_03_012000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_03_013000.npyd_loss: 0.25749162, g_loss: 4.67160130\n",
      "(1, 24, 128) 1 ./samples/fake_B_03_013000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_03_014000.npyd_loss: 0.50433034, g_loss: 4.03635454\n",
      "(1, 24, 128) 1 ./samples/fake_B_03_014000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_03_015000.npyd_loss: 0.34681332, g_loss: 4.56088161\n",
      "(1, 24, 128) 1 ./samples/fake_B_03_015000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_03_016000.npyd_loss: 0.32117349, g_loss: 4.45800686\n",
      "(1, 24, 128) 1 ./samples/fake_B_03_016000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_03_017000.npyd_loss: 0.33443666, g_loss: 4.06682777\n",
      "(1, 24, 128) 1 ./samples/fake_B_03_017000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_03_018000.npyd_loss: 0.22777006, g_loss: 4.01534033\n",
      "(1, 24, 128) 1 ./samples/fake_B_03_018000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_03_019000.npyd_loss: 0.32746160, g_loss: 3.69009519\n",
      "(1, 24, 128) 1 ./samples/fake_B_03_019000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_03_020000.npyd_loss: 0.27619693, g_loss: 3.83502722\n",
      "(1, 24, 128) 1 ./samples/fake_B_03_020000.npy\n",
      "Epoch[4]: Input data sampled: train_data_A (450, 24, 128) train_data_B (450, 24, 128)\n",
      "(1, 24, 128) 1 ./samples/real_A_04_001000.npyd_loss: 0.75643814, g_loss: 4.31927204\n",
      "(1, 24, 128) 1 ./samples/fake_B_04_001000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_04_002000.npyd_loss: 0.84099752, g_loss: 4.91464138\n",
      "(1, 24, 128) 1 ./samples/fake_B_04_002000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_04_003000.npyd_loss: 0.77257264, g_loss: 5.13749599\n",
      "(1, 24, 128) 1 ./samples/fake_B_04_003000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_04_004000.npyd_loss: 1.14298248, g_loss: 4.78309488\n",
      "(1, 24, 128) 1 ./samples/fake_B_04_004000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_04_005000.npyd_loss: 0.47782606, g_loss: 4.91832924\n",
      "(1, 24, 128) 1 ./samples/fake_B_04_005000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_04_006000.npyd_loss: 0.29942411, g_loss: 4.21014738\n",
      "(1, 24, 128) 1 ./samples/fake_B_04_006000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_04_007000.npyd_loss: 0.59216738, g_loss: 4.73270130\n",
      "(1, 24, 128) 1 ./samples/fake_B_04_007000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_04_008000.npyd_loss: 0.54282832, g_loss: 4.62710094\n",
      "(1, 24, 128) 1 ./samples/fake_B_04_008000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_04_009000.npyd_loss: 0.36248392, g_loss: 4.09590435\n",
      "(1, 24, 128) 1 ./samples/fake_B_04_009000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_04_010000.npyd_loss: 0.60235202, g_loss: 3.71233845\n",
      "(1, 24, 128) 1 ./samples/fake_B_04_010000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_04_011000.npyd_loss: 0.64165074, g_loss: 4.18571949\n",
      "(1, 24, 128) 1 ./samples/fake_B_04_011000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_04_012000.npyd_loss: 0.87941539, g_loss: 3.98948002\n",
      "(1, 24, 128) 1 ./samples/fake_B_04_012000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_04_013000.npyd_loss: 0.65747195, g_loss: 4.50305367\n",
      "(1, 24, 128) 1 ./samples/fake_B_04_013000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_04_014000.npyd_loss: 0.48309696, g_loss: 4.34996700\n",
      "(1, 24, 128) 1 ./samples/fake_B_04_014000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_04_015000.npyd_loss: 0.27470866, g_loss: 3.91231203\n",
      "(1, 24, 128) 1 ./samples/fake_B_04_015000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_04_016000.npyd_loss: 0.58464694, g_loss: 4.13901711\n",
      "(1, 24, 128) 1 ./samples/fake_B_04_016000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_04_017000.npyd_loss: 0.40854639, g_loss: 4.21777821\n",
      "(1, 24, 128) 1 ./samples/fake_B_04_017000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_04_018000.npyd_loss: 0.28696972, g_loss: 3.90501523\n",
      "(1, 24, 128) 1 ./samples/fake_B_04_018000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_04_019000.npyd_loss: 0.34913480, g_loss: 3.65536666\n",
      "(1, 24, 128) 1 ./samples/fake_B_04_019000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_04_020000.npyd_loss: 0.32214421, g_loss: 4.27618885\n",
      "(1, 24, 128) 1 ./samples/fake_B_04_020000.npy\n",
      "Epoch[5]: Input data sampled: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "(1, 24, 128) 1 ./samples/real_A_05_001000.npyd_loss: 0.93409109, g_loss: 5.05298853\n",
      "(1, 24, 128) 1 ./samples/fake_B_05_001000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_05_002000.npyd_loss: 0.68434787, g_loss: 5.17778254\n",
      "(1, 24, 128) 1 ./samples/fake_B_05_002000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_05_003000.npyd_loss: 0.51725799, g_loss: 4.68662500\n",
      "(1, 24, 128) 1 ./samples/fake_B_05_003000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_05_004000.npyd_loss: 0.66827202, g_loss: 4.99320555\n",
      "(1, 24, 128) 1 ./samples/fake_B_05_004000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_05_005000.npyd_loss: 0.55831945, g_loss: 4.28680372\n",
      "(1, 24, 128) 1 ./samples/fake_B_05_005000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_05_006000.npyd_loss: 0.66337836, g_loss: 4.93793583\n",
      "(1, 24, 128) 1 ./samples/fake_B_05_006000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_05_007000.npyd_loss: 0.66172117, g_loss: 4.18099451\n",
      "(1, 24, 128) 1 ./samples/fake_B_05_007000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_05_008000.npyd_loss: 0.32626677, g_loss: 4.10180378\n",
      "(1, 24, 128) 1 ./samples/fake_B_05_008000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_05_009000.npyd_loss: 1.05646062, g_loss: 4.43154669\n",
      "(1, 24, 128) 1 ./samples/fake_B_05_009000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_05_010000.npyd_loss: 0.71882093, g_loss: 4.80651140\n",
      "(1, 24, 128) 1 ./samples/fake_B_05_010000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_05_011000.npyd_loss: 0.78156364, g_loss: 4.12259436\n",
      "(1, 24, 128) 1 ./samples/fake_B_05_011000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_05_012000.npyd_loss: 0.49114755, g_loss: 3.79335880\n",
      "(1, 24, 128) 1 ./samples/fake_B_05_012000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_05_013000.npyd_loss: 0.62854588, g_loss: 3.89376736\n",
      "(1, 24, 128) 1 ./samples/fake_B_05_013000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_05_014000.npyd_loss: 0.60045755, g_loss: 4.20704174\n",
      "(1, 24, 128) 1 ./samples/fake_B_05_014000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_05_015000.npyd_loss: 0.53003347, g_loss: 3.98966312\n",
      "(1, 24, 128) 1 ./samples/fake_B_05_015000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_05_016000.npyd_loss: 0.41815901, g_loss: 4.43075848\n",
      "(1, 24, 128) 1 ./samples/fake_B_05_016000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_05_017000.npyd_loss: 0.66205633, g_loss: 3.89100671\n",
      "(1, 24, 128) 1 ./samples/fake_B_05_017000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_05_018000.npyd_loss: 0.67000115, g_loss: 4.01049328\n",
      "(1, 24, 128) 1 ./samples/fake_B_05_018000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_05_019000.npyd_loss: 0.47119826, g_loss: 4.16724110\n",
      "(1, 24, 128) 1 ./samples/fake_B_05_019000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_05_020000.npyd_loss: 0.52721739, g_loss: 4.05560493\n",
      "(1, 24, 128) 1 ./samples/fake_B_05_020000.npy\n",
      "Epoch[6]: Input data sampled: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "(1, 24, 128) 1 ./samples/real_A_06_001000.npyd_loss: 0.61080325, g_loss: 4.37907171\n",
      "(1, 24, 128) 1 ./samples/fake_B_06_001000.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 128) 1 ./samples/real_A_06_002000.npyd_loss: 0.70816231, g_loss: 4.56623745\n",
      "(1, 24, 128) 1 ./samples/fake_B_06_002000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_06_003000.npyd_loss: 1.09156299, g_loss: 4.41684151\n",
      "(1, 24, 128) 1 ./samples/fake_B_06_003000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_06_004000.npyd_loss: 0.74101049, g_loss: 4.69026852\n",
      "(1, 24, 128) 1 ./samples/fake_B_06_004000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_06_005000.npyd_loss: 0.48429415, g_loss: 5.01209307\n",
      "(1, 24, 128) 1 ./samples/fake_B_06_005000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_06_006000.npyd_loss: 0.90947151, g_loss: 3.89224315\n",
      "(1, 24, 128) 1 ./samples/fake_B_06_006000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_06_007000.npyd_loss: 0.49961156, g_loss: 4.23371649\n",
      "(1, 24, 128) 1 ./samples/fake_B_06_007000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_06_008000.npyd_loss: 0.89028382, g_loss: 4.35349607\n",
      "(1, 24, 128) 1 ./samples/fake_B_06_008000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_06_009000.npyd_loss: 0.53472537, g_loss: 3.81067944\n",
      "(1, 24, 128) 1 ./samples/fake_B_06_009000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_06_010000.npyd_loss: 0.66273415, g_loss: 4.59162426\n",
      "(1, 24, 128) 1 ./samples/fake_B_06_010000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_06_011000.npyd_loss: 0.68209469, g_loss: 4.65177345\n",
      "(1, 24, 128) 1 ./samples/fake_B_06_011000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_06_012000.npyd_loss: 0.72904038, g_loss: 4.21564388\n",
      "(1, 24, 128) 1 ./samples/fake_B_06_012000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_06_013000.npyd_loss: 0.40293807, g_loss: 3.96561575\n",
      "(1, 24, 128) 1 ./samples/fake_B_06_013000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_06_014000.npyd_loss: 0.76322109, g_loss: 4.17025566\n",
      "(1, 24, 128) 1 ./samples/fake_B_06_014000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_06_015000.npyd_loss: 0.57052714, g_loss: 4.49265003\n",
      "(1, 24, 128) 1 ./samples/fake_B_06_015000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_06_016000.npyd_loss: 0.73979527, g_loss: 4.27544975\n",
      "(1, 24, 128) 1 ./samples/fake_B_06_016000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_06_017000.npyd_loss: 0.47816905, g_loss: 4.18566465\n",
      "(1, 24, 128) 1 ./samples/fake_B_06_017000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_06_018000.npyd_loss: 0.66946030, g_loss: 4.16569090\n",
      "(1, 24, 128) 1 ./samples/fake_B_06_018000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_06_019000.npyd_loss: 0.85937059, g_loss: 3.90262437\n",
      "(1, 24, 128) 1 ./samples/fake_B_06_019000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_06_020000.npyd_loss: 0.66806972, g_loss: 4.31847668\n",
      "(1, 24, 128) 1 ./samples/fake_B_06_020000.npy\n",
      "Epoch[7]: Input data sampled: train_data_A (449, 24, 128) train_data_B (449, 24, 128)\n",
      "(1, 24, 128) 1 ./samples/real_A_07_001000.npyd_loss: 0.53401530, g_loss: 5.13483906\n",
      "(1, 24, 128) 1 ./samples/fake_B_07_001000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_07_002000.npyd_loss: 0.61961317, g_loss: 4.59123802\n",
      "(1, 24, 128) 1 ./samples/fake_B_07_002000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_07_003000.npyd_loss: 0.84614259, g_loss: 4.36828375\n",
      "(1, 24, 128) 1 ./samples/fake_B_07_003000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_07_004000.npyd_loss: 0.85585672, g_loss: 4.71339512\n",
      "(1, 24, 128) 1 ./samples/fake_B_07_004000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_07_005000.npyd_loss: 0.89100790, g_loss: 4.14862490\n",
      "(1, 24, 128) 1 ./samples/fake_B_07_005000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_07_006000.npyd_loss: 0.72101152, g_loss: 4.50866556\n",
      "(1, 24, 128) 1 ./samples/fake_B_07_006000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_07_007000.npyd_loss: 0.71958387, g_loss: 4.50591993\n",
      "(1, 24, 128) 1 ./samples/fake_B_07_007000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_07_008000.npyd_loss: 0.51982796, g_loss: 4.46913576\n",
      "(1, 24, 128) 1 ./samples/fake_B_07_008000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_07_009000.npyd_loss: 0.44129252, g_loss: 4.69552422\n",
      "(1, 24, 128) 1 ./samples/fake_B_07_009000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_07_010000.npyd_loss: 0.44727600, g_loss: 4.67485142\n",
      "(1, 24, 128) 1 ./samples/fake_B_07_010000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_07_011000.npyd_loss: 0.65616179, g_loss: 4.44407558\n",
      "(1, 24, 128) 1 ./samples/fake_B_07_011000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_07_012000.npyd_loss: 0.44556528, g_loss: 4.20129681\n",
      "(1, 24, 128) 1 ./samples/fake_B_07_012000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_07_013000.npyd_loss: 0.70113182, g_loss: 4.40010357\n",
      "(1, 24, 128) 1 ./samples/fake_B_07_013000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_07_014000.npyd_loss: 0.39901286, g_loss: 4.54139519\n",
      "(1, 24, 128) 1 ./samples/fake_B_07_014000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_07_015000.npyd_loss: 0.45334855, g_loss: 4.04778385\n",
      "(1, 24, 128) 1 ./samples/fake_B_07_015000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_07_016000.npyd_loss: 0.79084361, g_loss: 4.20995522\n",
      "(1, 24, 128) 1 ./samples/fake_B_07_016000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_07_017000.npyd_loss: 0.51732278, g_loss: 4.52102327\n",
      "(1, 24, 128) 1 ./samples/fake_B_07_017000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_07_018000.npyd_loss: 1.06015015, g_loss: 4.15255737\n",
      "(1, 24, 128) 1 ./samples/fake_B_07_018000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_07_019000.npyd_loss: 0.54637223, g_loss: 4.21752739\n",
      "(1, 24, 128) 1 ./samples/fake_B_07_019000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_07_020000.npyd_loss: 0.85744750, g_loss: 4.56393623\n",
      "(1, 24, 128) 1 ./samples/fake_B_07_020000.npy\n",
      "Epoch[8]: Input data sampled: train_data_A (444, 24, 128) train_data_B (444, 24, 128)\n",
      "(1, 24, 128) 1 ./samples/real_A_08_001000.npyd_loss: 0.57771033, g_loss: 4.78842163\n",
      "(1, 24, 128) 1 ./samples/fake_B_08_001000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_08_002000.npyd_loss: 0.71402097, g_loss: 4.69692898\n",
      "(1, 24, 128) 1 ./samples/fake_B_08_002000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_08_003000.npyd_loss: 0.60823536, g_loss: 4.43128490\n",
      "(1, 24, 128) 1 ./samples/fake_B_08_003000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_08_004000.npyd_loss: 0.79026109, g_loss: 4.25507593\n",
      "(1, 24, 128) 1 ./samples/fake_B_08_004000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_08_005000.npyd_loss: 0.67646217, g_loss: 4.52925968\n",
      "(1, 24, 128) 1 ./samples/fake_B_08_005000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_08_006000.npyd_loss: 0.48559406, g_loss: 4.41166925\n",
      "(1, 24, 128) 1 ./samples/fake_B_08_006000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_08_007000.npyd_loss: 0.75967181, g_loss: 4.20661879\n",
      "(1, 24, 128) 1 ./samples/fake_B_08_007000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_08_008000.npyd_loss: 0.84671152, g_loss: 4.54377556\n",
      "(1, 24, 128) 1 ./samples/fake_B_08_008000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_08_009000.npyd_loss: 0.64731324, g_loss: 4.42598248\n",
      "(1, 24, 128) 1 ./samples/fake_B_08_009000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_08_010000.npyd_loss: 0.90264285, g_loss: 4.45950079\n",
      "(1, 24, 128) 1 ./samples/fake_B_08_010000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_08_011000.npyd_loss: 0.84869015, g_loss: 4.95199919\n",
      "(1, 24, 128) 1 ./samples/fake_B_08_011000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_08_012000.npyd_loss: 0.73898071, g_loss: 4.70528984\n",
      "(1, 24, 128) 1 ./samples/fake_B_08_012000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_08_013000.npyd_loss: 0.78102511, g_loss: 4.41094160\n",
      "(1, 24, 128) 1 ./samples/fake_B_08_013000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_08_014000.npyd_loss: 0.67112184, g_loss: 4.05665207\n",
      "(1, 24, 128) 1 ./samples/fake_B_08_014000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_08_015000.npyd_loss: 0.65904003, g_loss: 4.37668180\n",
      "(1, 24, 128) 1 ./samples/fake_B_08_015000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_08_016000.npyd_loss: 0.66691124, g_loss: 4.42362690\n",
      "(1, 24, 128) 1 ./samples/fake_B_08_016000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_08_017000.npyd_loss: 0.59694177, g_loss: 3.88504410\n",
      "(1, 24, 128) 1 ./samples/fake_B_08_017000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_08_018000.npyd_loss: 0.74094349, g_loss: 4.53534794\n",
      "(1, 24, 128) 1 ./samples/fake_B_08_018000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_08_019000.npyd_loss: 0.73082328, g_loss: 4.31762743\n",
      "(1, 24, 128) 1 ./samples/fake_B_08_019000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_08_020000.npyd_loss: 0.49428427, g_loss: 4.57417583\n",
      "(1, 24, 128) 1 ./samples/fake_B_08_020000.npy\n",
      "Epoch[9]: Input data sampled: train_data_A (437, 24, 128) train_data_B (437, 24, 128)\n",
      "(1, 24, 128) 1 ./samples/real_A_09_001000.npyd_loss: 0.92808634, g_loss: 5.14559937\n",
      "(1, 24, 128) 1 ./samples/fake_B_09_001000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_09_002000.npyd_loss: 0.89821893, g_loss: 4.36497974\n",
      "(1, 24, 128) 1 ./samples/fake_B_09_002000.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 128) 1 ./samples/real_A_09_003000.npyd_loss: 0.33200669, g_loss: 4.90212727\n",
      "(1, 24, 128) 1 ./samples/fake_B_09_003000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_09_004000.npyd_loss: 0.74011099, g_loss: 4.47733498\n",
      "(1, 24, 128) 1 ./samples/fake_B_09_004000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_09_005000.npyd_loss: 0.76509756, g_loss: 4.49784470\n",
      "(1, 24, 128) 1 ./samples/fake_B_09_005000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_09_006000.npyd_loss: 0.93313712, g_loss: 3.90850973\n",
      "(1, 24, 128) 1 ./samples/fake_B_09_006000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_09_007000.npyd_loss: 0.68338019, g_loss: 4.73191214\n",
      "(1, 24, 128) 1 ./samples/fake_B_09_007000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_09_008000.npyd_loss: 1.05923367, g_loss: 3.88090420\n",
      "(1, 24, 128) 1 ./samples/fake_B_09_008000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_09_009000.npyd_loss: 0.58971238, g_loss: 4.62314415\n",
      "(1, 24, 128) 1 ./samples/fake_B_09_009000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_09_010000.npyd_loss: 0.60957474, g_loss: 4.77718544\n",
      "(1, 24, 128) 1 ./samples/fake_B_09_010000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_09_011000.npyd_loss: 0.46177402, g_loss: 4.37691593\n",
      "(1, 24, 128) 1 ./samples/fake_B_09_011000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_09_012000.npyd_loss: 0.50090683, g_loss: 4.89103746\n",
      "(1, 24, 128) 1 ./samples/fake_B_09_012000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_09_013000.npyd_loss: 0.85160679, g_loss: 4.36560965\n",
      "(1, 24, 128) 1 ./samples/fake_B_09_013000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_09_014000.npyd_loss: 0.73442650, g_loss: 4.55023289\n",
      "(1, 24, 128) 1 ./samples/fake_B_09_014000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_09_015000.npyd_loss: 0.97205204, g_loss: 4.40356064\n",
      "(1, 24, 128) 1 ./samples/fake_B_09_015000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_09_016000.npyd_loss: 0.73399878, g_loss: 4.26690865\n",
      "(1, 24, 128) 1 ./samples/fake_B_09_016000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_09_017000.npyd_loss: 0.71233869, g_loss: 4.65983677\n",
      "(1, 24, 128) 1 ./samples/fake_B_09_017000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_09_018000.npyd_loss: 0.98978555, g_loss: 4.71346855\n",
      "(1, 24, 128) 1 ./samples/fake_B_09_018000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_09_019000.npyd_loss: 0.67646158, g_loss: 4.58781242\n",
      "(1, 24, 128) 1 ./samples/fake_B_09_019000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_09_020000.npyd_loss: 0.96181244, g_loss: 4.48113108\n",
      "(1, 24, 128) 1 ./samples/fake_B_09_020000.npy\n",
      "Epoch[10]: Input data sampled: train_data_A (459, 24, 128) train_data_B (459, 24, 128)\n",
      "(1, 24, 128) 1 ./samples/real_A_10_001000.npyd_loss: 0.86509544, g_loss: 5.07292366\n",
      "(1, 24, 128) 1 ./samples/fake_B_10_001000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_10_002000.npyd_loss: 0.49402460, g_loss: 4.13036060\n",
      "(1, 24, 128) 1 ./samples/fake_B_10_002000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_10_003000.npyd_loss: 0.57345545, g_loss: 4.78984404\n",
      "(1, 24, 128) 1 ./samples/fake_B_10_003000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_10_004000.npyd_loss: 0.52434152, g_loss: 4.21693039\n",
      "(1, 24, 128) 1 ./samples/fake_B_10_004000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_10_005000.npyd_loss: 0.83030325, g_loss: 4.93459988\n",
      "(1, 24, 128) 1 ./samples/fake_B_10_005000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_10_006000.npyd_loss: 0.51418662, g_loss: 4.46376228\n",
      "(1, 24, 128) 1 ./samples/fake_B_10_006000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_10_007000.npyd_loss: 1.12176299, g_loss: 4.33277988\n",
      "(1, 24, 128) 1 ./samples/fake_B_10_007000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_10_008000.npyd_loss: 0.96262407, g_loss: 4.69703150\n",
      "(1, 24, 128) 1 ./samples/fake_B_10_008000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_10_009000.npyd_loss: 0.48027909, g_loss: 4.91496468\n",
      "(1, 24, 128) 1 ./samples/fake_B_10_009000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_10_010000.npyd_loss: 1.12719488, g_loss: 4.47461224\n",
      "(1, 24, 128) 1 ./samples/fake_B_10_010000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_10_011000.npyd_loss: 0.85419095, g_loss: 4.39838886\n",
      "(1, 24, 128) 1 ./samples/fake_B_10_011000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_10_012000.npyd_loss: 0.93652064, g_loss: 4.07141876\n",
      "(1, 24, 128) 1 ./samples/fake_B_10_012000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_10_013000.npyd_loss: 0.80136633, g_loss: 3.62698174\n",
      "(1, 24, 128) 1 ./samples/fake_B_10_013000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_10_014000.npyd_loss: 0.48009878, g_loss: 4.52332306\n",
      "(1, 24, 128) 1 ./samples/fake_B_10_014000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_10_015000.npyd_loss: 1.14076936, g_loss: 4.44452715\n",
      "(1, 24, 128) 1 ./samples/fake_B_10_015000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_10_016000.npyd_loss: 0.67386723, g_loss: 4.29064083\n",
      "(1, 24, 128) 1 ./samples/fake_B_10_016000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_10_017000.npyd_loss: 0.67628491, g_loss: 4.55321980\n",
      "(1, 24, 128) 1 ./samples/fake_B_10_017000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_10_018000.npyd_loss: 0.91903055, g_loss: 4.59378910\n",
      "(1, 24, 128) 1 ./samples/fake_B_10_018000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_10_019000.npyd_loss: 0.52957463, g_loss: 4.76104307\n",
      "(1, 24, 128) 1 ./samples/fake_B_10_019000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_10_020000.npyd_loss: 0.51560575, g_loss: 4.90769339\n",
      "(1, 24, 128) 1 ./samples/fake_B_10_020000.npy\n",
      "Epoch[11]: Input data sampled: train_data_A (448, 24, 128) train_data_B (448, 24, 128)\n",
      "(1, 24, 128) 1 ./samples/real_A_11_001000.npyd_loss: 0.74247772, g_loss: 4.91957664\n",
      "(1, 24, 128) 1 ./samples/fake_B_11_001000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_11_002000.npyd_loss: 0.90581709, g_loss: 4.29636002\n",
      "(1, 24, 128) 1 ./samples/fake_B_11_002000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_11_003000.npyd_loss: 0.56142461, g_loss: 5.04430103\n",
      "(1, 24, 128) 1 ./samples/fake_B_11_003000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_11_004000.npyd_loss: 0.55241615, g_loss: 4.70407200\n",
      "(1, 24, 128) 1 ./samples/fake_B_11_004000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_11_005000.npyd_loss: 0.92497146, g_loss: 4.03941917\n",
      "(1, 24, 128) 1 ./samples/fake_B_11_005000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_11_006000.npyd_loss: 0.94874990, g_loss: 4.15876675\n",
      "(1, 24, 128) 1 ./samples/fake_B_11_006000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_11_007000.npyd_loss: 0.74362153, g_loss: 4.89078236\n",
      "(1, 24, 128) 1 ./samples/fake_B_11_007000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_11_008000.npyd_loss: 0.58254176, g_loss: 4.83221197\n",
      "(1, 24, 128) 1 ./samples/fake_B_11_008000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_11_009000.npyd_loss: 0.65122694, g_loss: 4.39640856\n",
      "(1, 24, 128) 1 ./samples/fake_B_11_009000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_11_010000.npyd_loss: 0.74831736, g_loss: 4.69552612\n",
      "(1, 24, 128) 1 ./samples/fake_B_11_010000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_11_011000.npyd_loss: 0.72416341, g_loss: 4.53218365\n",
      "(1, 24, 128) 1 ./samples/fake_B_11_011000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_11_012000.npyd_loss: 0.56671214, g_loss: 4.28519726\n",
      "(1, 24, 128) 1 ./samples/fake_B_11_012000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_11_013000.npyd_loss: 0.30811533, g_loss: 4.67226887\n",
      "(1, 24, 128) 1 ./samples/fake_B_11_013000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_11_014000.npyd_loss: 0.52794564, g_loss: 4.45179701\n",
      "(1, 24, 128) 1 ./samples/fake_B_11_014000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_11_015000.npyd_loss: 0.63674921, g_loss: 3.68249607\n",
      "(1, 24, 128) 1 ./samples/fake_B_11_015000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_11_016000.npyd_loss: 0.72653091, g_loss: 4.60679054\n",
      "(1, 24, 128) 1 ./samples/fake_B_11_016000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_11_017000.npyd_loss: 1.19662070, g_loss: 4.59594297\n",
      "(1, 24, 128) 1 ./samples/fake_B_11_017000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_11_018000.npyd_loss: 0.73366523, g_loss: 4.87005186\n",
      "(1, 24, 128) 1 ./samples/fake_B_11_018000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_11_019000.npyd_loss: 0.51614523, g_loss: 4.45460701\n",
      "(1, 24, 128) 1 ./samples/fake_B_11_019000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_11_020000.npyd_loss: 0.59161901, g_loss: 4.38005638\n",
      "(1, 24, 128) 1 ./samples/fake_B_11_020000.npy\n",
      "Epoch[12]: Input data sampled: train_data_A (452, 24, 128) train_data_B (452, 24, 128)\n",
      "(1, 24, 128) 1 ./samples/real_A_12_001000.npyd_loss: 0.82091916, g_loss: 4.26435328\n",
      "(1, 24, 128) 1 ./samples/fake_B_12_001000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_12_002000.npyd_loss: 0.63972127, g_loss: 4.65101242\n",
      "(1, 24, 128) 1 ./samples/fake_B_12_002000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_12_003000.npyd_loss: 0.60669601, g_loss: 3.87326860\n",
      "(1, 24, 128) 1 ./samples/fake_B_12_003000.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 24, 128) 1 ./samples/real_A_12_004000.npyd_loss: 0.63804847, g_loss: 4.62069559\n",
      "(1, 24, 128) 1 ./samples/fake_B_12_004000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_12_005000.npyd_loss: 0.55871606, g_loss: 4.26672602\n",
      "(1, 24, 128) 1 ./samples/fake_B_12_005000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_12_006000.npyd_loss: 1.30936933, g_loss: 3.97422314\n",
      "(1, 24, 128) 1 ./samples/fake_B_12_006000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_12_007000.npyd_loss: 0.58008742, g_loss: 4.67681551\n",
      "(1, 24, 128) 1 ./samples/fake_B_12_007000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_12_008000.npyd_loss: 0.71625465, g_loss: 4.38376236\n",
      "(1, 24, 128) 1 ./samples/fake_B_12_008000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_12_009000.npyd_loss: 0.80946183, g_loss: 4.78103352\n",
      "(1, 24, 128) 1 ./samples/fake_B_12_009000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_12_010000.npyd_loss: 0.56689703, g_loss: 4.55551338\n",
      "(1, 24, 128) 1 ./samples/fake_B_12_010000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_12_011000.npyd_loss: 0.45075929, g_loss: 4.80636215\n",
      "(1, 24, 128) 1 ./samples/fake_B_12_011000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_12_012000.npyd_loss: 0.44960850, g_loss: 4.55739927\n",
      "(1, 24, 128) 1 ./samples/fake_B_12_012000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_12_013000.npyd_loss: 0.59833407, g_loss: 4.14882946\n",
      "(1, 24, 128) 1 ./samples/fake_B_12_013000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_12_014000.npyd_loss: 0.95205963, g_loss: 4.79663372\n",
      "(1, 24, 128) 1 ./samples/fake_B_12_014000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_12_015000.npyd_loss: 0.43744546, g_loss: 4.49350643\n",
      "(1, 24, 128) 1 ./samples/fake_B_12_015000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_12_016000.npyd_loss: 0.59549713, g_loss: 4.75493383\n",
      "(1, 24, 128) 1 ./samples/fake_B_12_016000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_12_017000.npyd_loss: 0.87165523, g_loss: 4.64632177\n",
      "(1, 24, 128) 1 ./samples/fake_B_12_017000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_12_018000.npyd_loss: 0.93087965, g_loss: 4.10243130\n",
      "(1, 24, 128) 1 ./samples/fake_B_12_018000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_12_019000.npyd_loss: 0.57058877, g_loss: 4.32742643\n",
      "(1, 24, 128) 1 ./samples/fake_B_12_019000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_12_020000.npyd_loss: 0.58666599, g_loss: 4.60135412\n",
      "(1, 24, 128) 1 ./samples/fake_B_12_020000.npy\n",
      "Epoch[13]: Input data sampled: train_data_A (443, 24, 128) train_data_B (443, 24, 128)\n",
      "(1, 24, 128) 1 ./samples/real_A_13_001000.npyd_loss: 0.38010803, g_loss: 3.96860027\n",
      "(1, 24, 128) 1 ./samples/fake_B_13_001000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_13_002000.npyd_loss: 0.67501950, g_loss: 4.29534960\n",
      "(1, 24, 128) 1 ./samples/fake_B_13_002000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_13_003000.npyd_loss: 0.70076716, g_loss: 4.98935223\n",
      "(1, 24, 128) 1 ./samples/fake_B_13_003000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_13_004000.npyd_loss: 0.72032255, g_loss: 4.57342815\n",
      "(1, 24, 128) 1 ./samples/fake_B_13_004000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_13_005000.npyd_loss: 0.95758253, g_loss: 4.62582397\n",
      "(1, 24, 128) 1 ./samples/fake_B_13_005000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_13_006000.npyd_loss: 0.63103116, g_loss: 4.95865726\n",
      "(1, 24, 128) 1 ./samples/fake_B_13_006000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_13_007000.npyd_loss: 0.78754866, g_loss: 5.32845879\n",
      "(1, 24, 128) 1 ./samples/fake_B_13_007000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_13_008000.npyd_loss: 0.49530685, g_loss: 4.22300529\n",
      "(1, 24, 128) 1 ./samples/fake_B_13_008000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_13_009000.npyd_loss: 1.12400138, g_loss: 4.48001623\n",
      "(1, 24, 128) 1 ./samples/fake_B_13_009000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_13_010000.npyd_loss: 0.60917103, g_loss: 4.83734131\n",
      "(1, 24, 128) 1 ./samples/fake_B_13_010000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_13_011000.npyd_loss: 0.86290550, g_loss: 4.48685932\n",
      "(1, 24, 128) 1 ./samples/fake_B_13_011000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_13_012000.npyd_loss: 0.62033999, g_loss: 4.31855297\n",
      "(1, 24, 128) 1 ./samples/fake_B_13_012000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_13_013000.npyd_loss: 0.46594316, g_loss: 4.02058983\n",
      "(1, 24, 128) 1 ./samples/fake_B_13_013000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_13_014000.npyd_loss: 0.70153725, g_loss: 4.75507212\n",
      "(1, 24, 128) 1 ./samples/fake_B_13_014000.npy\n",
      "(1, 24, 128) 1 ./samples/real_A_13_015000.npyd_loss: 0.79697597, g_loss: 4.48621750\n",
      "(1, 24, 128) 1 ./samples/fake_B_13_015000.npy\n",
      "Epoch: [13] [ 15966/ 20000] time: 53207.5413 d_loss: 0.76733828, g_loss: 4.58919048\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b5a56369c6e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mgan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" [*] Training finished!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-143a9cd39080>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0;31m# Update G\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m                 \u001b[0mbatch_A_audios\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_B_audios\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_str\u001b[0m \u001b[0;34m=\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_optim\u001b[0m\u001b[0;34m,\u001b[0m                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mG_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_feed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "    gan = EmoMUNIT(sess)\n",
    "    gan.build_model()\n",
    "    \n",
    "    gan.train()\n",
    "    print(\" [*] Training finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf18_p35)",
   "language": "python",
   "name": "tf18_p35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
